{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"About","text":"MOUHIHA Mohamed Morocco, Eljadida Data Engineer | Data Analyst  | Data Scientist | Full-stack developer @Angular, @Java &amp; @Python  Buy Me a Coffee Export Resume  About <p>Hey! I\u2019m MOUHIHA Mohamed,I'm a 23-year-old Moroccan with a strong interest in the fields of data science, data analysis and full-stack development. I recently graduated with a Master's degree in Big Data and Decision Support from the National School of Applied Sciences of Khouribga.</p> <p> My passion for data science, data analysis and full-stack development comes from my firm belief in the transformative power of technology to bring about positive change. I find it incredibly captivating how data can be harnessed to solve intricate problems and enhance the quality of people's lives.</p> <p> In addition to my academic pursuits, I am inspired by the wise words of the renowned author, Stephen King, who once said, \"Talent is cheaper than table salt. What separates the talented individual from the successful one is a lot of hard work.\" I strongly resonate with this sentiment and firmly believe that hard work and dedication are indispensable ingredients for achieving success in any endeavor.</p> <p> By combining my expertise in data science, data analysis with full-stack development skills, I aspire to create innovative and impactful solutions that contribute positively to society. My ultimate goal is to be at the forefront of technological advancements, bridging the gap between data-driven insights and user-friendly applications.\"</p>  Experience - <p>Research StudentJan 2023 - Jun 2023Laboratory of Process Engineering, Computer Science and Mathematics at ENSA-Kh  - Internship</p> Master's thesis project: Analysis and comparison of deep learning recommender systems.       <ul> <li>Discover recommendation systems and the recommendation process; <li>Discover the 3 filtering approaches; <li>Evaluation of recommendation systems; <li>Conduct a literature review on the different classes of deep learning methods used in recommendation systems (MLP, AE, CNN, and RNN); <li>Convert explicit feedback data into an implicit feedback dataset; <li>Propose an MLP architecture; <li>  Compare our proposed approach with existing methods;  <li>  Our method surpasses the state-of-the-art method.        <p>Full stack developer Apr 2021 -Jun 2021Ziryab Tec  - Internship <p>Design and development of a web application for managing recruitment files online using laravel/Angular/MySql</p> <p>Full stack developerApr 2020 - Jun 2020Higher School of Technology - Internship <p>        Design and development of a trainee management web applica- tion with Php5/html/css/Bootsrap/Jquery/JavaScript/MySql       </p> <p>Full stack developerJul 2019-Aug 2019Atlanta Insurance  - Internship <p>      Design and development of a trainee management desktop application using C#/MySql       </p>  Education - <p>Research Master in Big Data and Decision SupportSep 2021 - Jun 2023Khouribga National School of Applied Sciences Morocco, Khouribga</p><p> </p> <p>Bachelor Degree in Computer Science and Applied Mathematics option Computer ScienceSep 2020 - Apr 2021Sidi Bennour Polydisciplinary Faculty  Morocco, El Jadida</p> <p>University Diploma of Technology (DUT) in Computer EngineeringSep 2018 - Apr 2020Sidi Bennour Higher School of Technology   Morocco, El Jadida</p>  Honors &amp; Awards - <p>Coursera,  Python for Data Science, AI Development (Certification)Jul 2023 </p><p> </p> <p>Coursera,  Introduction to Java (Certification)Jul 2023 </p><p> </p> <p>Coursera,  Getting Started with Data Warehousing and BI Analytics (Certification)Jun 2023 </p><p> </p> <p>Huawei ICT Academy,  HCIA - Big Data (Certification)Mar 2020 UCD Universit\u00e9 Chouaib Doukkali Morocco, El Jadida</p><p> </p> <p>Hackathon - ENSA El Jadida, 2nd Place Apr 2019 ENSA El Jadida Morocco, El Jadida</p><p> </p>  Where I'm Located -  Community Involvement - <p>Rotaract Association, Active memberAug 2020 - July 2021Khouribga National School of Applied Sciences Morocco, Khouribga</p><p> </p> <p>Enactus Association, Active memberSep 2021 - Jan 2023Khouribga National School of Applied Sciences Morocco, Khouribga</p><p> </p> <p>  What I'm Listening To - <p>"},{"location":"Documentations/Computer%20Vision%20Algorithms/","title":"Computer Vision Algorithms","text":"<ul> <li> <p> YOLO-NAS</p> <p>Get started  Getting started</p> </li> </ul>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/","title":"YOLO-NAS","text":""},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#introduction","title":"Introduction","text":"<p>A Next-Generation, Object Detection Foundational Model generated by Deci\u2019s Neural Architecture Search Technology.</p> <p>Deci is thrilled to announce the release of a new object detection model, YOLO-NAS - a game-changer in the world of object detection, providing superior real-time object detection capabilities and production-ready performance. Deci's mission is to provide AI teams with tools to remove development barriers and attain efficient inference performance more quickly.</p> <p> <p></p> <p></p> <p>The new YOLO-NAS delivers state-of-the-art (SOTA) performance with the unparalleled accuracy-speed performance, outperforming other models such as YOLOv5, YOLOv6, YOLOv7 and YOLOv8.</p> <p>Deci's proprietary Neural Architecture Search technology, AutoNAC\u2122, generated the YOLO-NAS model. The AutoNAC\u2122 engine lets you input any task, data characteristics (access to data is not required), inference environment and performance targets, and then guides you to find the optimal architecture that delivers the best balance between accuracy and inference speed for your specific application. In addition to being data and hardware aware, the AutoNAC engine considers other components in the inference stack, including compilers and quantization.</p> <p>In terms of pure numbers, YOLO-NAS is ~0.5 mAP point more accurate and 10-20% faster than equivalent variants of YOLOv8 and YOLOv7.</p> Model mAP Latency (ms) YOLO-NAS S 47.5 3.21 YOLO-NAS M 51.55 5.85 YOLO-NAS L 52.22 7.87 YOLO-NAS S INT-8 47.03 2.36 YOLO-NAS M INT-8 51.0 3.78 YOLO-NAS L INT-8 52.1 4.78 <p>mAP numbers in table reported for Coco 2017 Val dataset and latency benchmarked for 640x640 images on Nvidia T4 GPU.</p> <p>YOLO-NAS's architecture employs quantization-aware blocks and selective quantization for optimized performance. When converted to its INT8 quantized version, YOLO-NAS experiences a smaller precision drop (0.51, 0.65, and 0.45 points of mAP for S, M, and L variants) compared to other models that lose 1-2 mAP points during quantization. These techniques culminate in innovative architecture with superior object detection capabilities and top-notch performance.</p>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#configuration","title":"Configuration","text":"<p>Note</p> <p>After installation is complete (it make take a few minutes), you'll need to restart the runtime after installation completes.</p> <pre><code>%%capture\n!pip install super-gradients==3.1.0\n!pip install imutils\n!pip install roboflow\n!pip install pytube --upgrade\n</code></pre>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#supergradients","title":"SuperGradients","text":"<p>SuperGradients is a PyTorch based training library.</p> <p>It provides a uniform interface for the most common computer vision use cases: </p> <ul> <li> <p>Classification</p> </li> <li> <p>Detection</p> </li> <li> <p>Segmentation</p> </li> <li> <p>Pose estimation</p> </li> </ul> <p>There are nearly 40 pretrained models in our model zoo. You can see the pretrained models available to you by following this link.</p> <p>This notebook will focus on using SuperGradients with YOLO-NAS. If you're interested in seeing how SG is used for image classification, you can check out this templated notebook that will make it easy to get started.</p>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#inference-with-yolonas-pretrained-model","title":"Inference with YOLONAS Pretrained Model","text":"<p>Before jumping into the section on fine-tuning, I wanted to show you the power of YOLONAS out of the box. </p> <p>Start by instantiating a pretrained model. YOLONAS comes in three flavors: <code>yolo_nas_s</code>, <code>yolo_nas_m</code>, and <code>yolo_nas_l</code>.</p> <p>You'll use <code>yolo_nas_l</code> throughout this notebook. Because you should always go big, or go home. </p> <p>It's a good life philosophy.</p> <p><pre><code>from super_gradients.training import models\n\nyolo_nas_l = models.get(\"yolo_nas_l\", pretrained_weights=\"coco\")\n</code></pre> You can run the following cell if you're interested in the architecture:</p> <pre><code>!pip install torchinfo\nfrom torchinfo import summary\n\nsummary(model=yolo_nas_l, \n        input_size=(16, 3, 640, 640),\n        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n        col_width=20,\n        row_settings=[\"var_names\"]\n)\n</code></pre>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#inference-on-an-image","title":"Inference on an image","text":"<p>Once the model has been instantiated all you have to do is call the <code>predict</code> method. </p> <p>This method operates on: * PIL Image * Numpy Image * A path to image file  * A path to video file  * A path to folder with images * URL (Image only)</p> <p>Allowing you to perform inference with ease.</p> <p>Note predict also has an argument called <code>conf</code>, which is the threshold for a detection. You change this value as you like, for example <code>model.predict(\"path/to/asset\",conf=0.25)</code></p> <p>Let's perform inference on the following image:</p> <p></p> <pre><code>url = \"https://previews.123rf.com/images/freeograph/freeograph2011/freeograph201100150/158301822-group-of-friends-gathering-around-table-at-home.jpg\"\nyolo_nas_l.predict(url, conf=0.25).show()\n</code></pre> Output <p></p>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#inference-on-video","title":"Inference on video","text":"<p>The following code will display and download stock footage video from YouTube. Here's a link to a playlist that has a lot of stock video clips which are 2mins in length or less.</p> <p>Find a video you like and use YOLONAS to perform some inference on it!</p> <p>All you have to do is get the <code>video_id</code>, and replace the line <code>video_id = 'aE8I7bDf62M'</code> in the cell below with your chosen video's id.</p> <p>The <code>video_id</code> is everything that comes after <code>https://www.youtube.com/watch?v=</code>. For the video below, the full url was <code>https://www.youtube.com/watch?v=aE8I7bDf62M</code>, and thus the video id is <code>aE8I7bDf62M</code>.</p> <pre><code># Import the YouTubeVideo class from IPython.display\nfrom IPython.display import YouTubeVideo\n\n# Define the YouTube video ID\nvideo_id = 'aE8I7bDf62M'  # Replace YOUR_VIDEO_ID with the actual video ID\n\n# Create a YouTubeVideo object with the specified video ID\nvideo = YouTubeVideo(video_id)\n\n# Display the video\ndisplay(video)\n</code></pre> <p><pre><code>%%capture\n# Define the URL of the YouTube video\nvideo_url = f'https://www.youtube.com/watch?v={video_id}'  \n\n# Download the video in mp4 format\n!pip install -U \"git+https://github.com/ytdl-org/youtube-dl.git\"\n!python -m youtube_dl -f 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4' \"$video_url\"\n\n# Print a success message\nprint('Video downloaded successfully')\n\ninput_video_path = f\"/content/EXTREME SPORTS X DIVERSE-{video_id}.mp4\"\noutput_video_path = \"detections.mp4\"\n</code></pre> Now, you'll peform inference on the video</p> <pre><code>import torch\ndevice = 'cuda' if torch.cuda.is_available() else \"cpu\"\n</code></pre> <pre><code>yolo_nas_l.to(device).predict(input_video_path).save(output_video_path)\n</code></pre> <p>Inference via webcam</p> <p>Check the documentation for inference via webcam.</p>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#fine-tuning-yolonas-on-custom-dataset","title":"Fine-tuning YOLONAS on custom dataset","text":"<p>The trainer The first thing you need to define in SuperGradients is the Trainer.</p> <p>The trainer is in charge of training, evaluation, saving checkpoints, etc. If you're interested in seeing the source code for the trainer, you can do so here.</p> <p>There's two important arguments to the trainer: 1. <code>ckpt_root_dir</code> - this is the directory where results from all your experiments will be saved</p> <ol> <li><code>experiment_name</code> - all checkpoints, logs, and tensorboards will be saved in a directory with the name you specify here. </li> </ol> <p>In the code below, you'll instantiate the trainer with just a single GPU (since that's what Google Colab provides).</p> <pre><code>from super_gradients.training import Trainer\n\nCHECKPOINT_DIR = '/content/drive/MyDrive/YOLO-NAS/checkpoints'\ntrainer = Trainer(experiment_name='my_first_yolonas_run', ckpt_root_dir=CHECKPOINT_DIR)\n</code></pre>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#fine-tuning-yolonas-on-custom-dataset_1","title":"Fine-tuning YOLONAS on custom dataset","text":"<p>SuperGradients is fully compatible with PyTorch Datasets and Dataloaders, so you can use your dataloaders as is. </p> <p>There are several well-known datasets for object detection, for example: </p> <ul> <li>COCO</li> <li>Pascal</li> <li>YOLODarkNet</li> <li>YOLOv5</li> </ul> <p>SuperGradients provides ready-to-use dataloaders for these datasets. If you're interested in learning more about working with <code>COCOFormatDetectionDataset</code> and the more general <code>DetectionDataset</code> check out the SuperGradients documentation on this topic</p> <p>You can learn more about working with SuperGradients datasets, dataloaders, and configuration files here.</p> <p>SuperGradients supports a number of dataset formats, you can learn more about that here.</p> <p>For this example you'll use the the U.S. Coins Dataset from RoboFlow with the dataset in YOLOv5 format.</p> <p>Some datasets you might want to try: - HuggingFace competition: Ship detection</p> <ul> <li> <p>Aquarium dataset on RoboFlow</p> </li> <li> <p>Vehicles-OpenImages Dataset on RoboFlow</p> </li> <li> <p>Winegrape detection</p> </li> <li> <p>Low light object detection</p> </li> <li> <p>Infrafred person detection</p> </li> <li> <p>Pothole detection</p> </li> <li> <p>100k Labeled Road Images | Day, Night</p> </li> <li> <p>Deep Fashion dataset</p> </li> <li> <p>Playing card detection</p> </li> <li> <p>Anaomoly detection in videos</p> </li> <li> <p>Underwater fish recognition</p> </li> <li> <p>Document layout detection</p> </li> <li> <p>Trash Annotations in Context</p> </li> </ul> <p><pre><code>from roboflow import Roboflow\nrf = Roboflow(api_key=\"&lt;your-roboflow-key-here&gt;\")\nproject = rf.workspace(\"atathamuscoinsdataset\").project(\"u.s.-coins-dataset-a.tatham\")\ndataset = project.version(5).download(\"yolov5\")\n</code></pre> Start by importing the required modules, which will help you create SuperGradients dataloaders.</p> <p><pre><code>from super_gradients.training import dataloaders\nfrom super_gradients.training.dataloaders.dataloaders import coco_detection_yolo_format_train, coco_detection_yolo_format_val\n</code></pre> You'll need to load your dataset parameters into a dictionary, specifically defining:</p> <ul> <li>path to the parent directory where your data lives</li> <li>the child directory names for training, validation, and test (if you have testing set) images and labels</li> <li>class names</li> </ul> <p><pre><code>dataset_params = {\n    'data_dir':'/content/U.S.-Coins-Dataset---A.Tatham-5',\n    'train_images_dir':'train/images',\n    'train_labels_dir':'train/labels',\n    'val_images_dir':'valid/images',\n    'val_labels_dir':'valid/labels',\n    'test_images_dir':'test/images',\n    'test_labels_dir':'test/labels',\n    'classes': ['Dime', 'Nickel', 'Penny', 'Quarter']\n}\n</code></pre> You pass the values for <code>dataset_params</code> into the <code>dataset_params</code> argument as shown below.</p> <p>You can also pass PyTorch DataLoaders arguments when instantiating your dataset. Here you'll set <code>batch_size=16</code> and <code>num_workers=2</code>.</p> <p>Repeat this for the validation and testing datasets, note that for training and testing data we use <code>coco_detection_yolo_format_val</code> to instantiate the dataloader.</p> <p>The dataloaders will print warnings when an annotation does not conform to the expected format. This particular dataset has many such annotations, thus the warnings will be muted.</p> <p><pre><code>from IPython.display import clear_output\n\ntrain_data = coco_detection_yolo_format_train(\n    dataset_params={\n        'data_dir': dataset_params['data_dir'],\n        'images_dir': dataset_params['train_images_dir'],\n        'labels_dir': dataset_params['train_labels_dir'],\n        'classes': dataset_params['classes']\n    },\n    dataloader_params={\n        'batch_size':16,\n        'num_workers':2\n    }\n)\n\nval_data = coco_detection_yolo_format_val(\n    dataset_params={\n        'data_dir': dataset_params['data_dir'],\n        'images_dir': dataset_params['val_images_dir'],\n        'labels_dir': dataset_params['val_labels_dir'],\n        'classes': dataset_params['classes']\n    },\n    dataloader_params={\n        'batch_size':16,\n        'num_workers':2\n    }\n)\n\ntest_data = coco_detection_yolo_format_val(\n    dataset_params={\n        'data_dir': dataset_params['data_dir'],\n        'images_dir': dataset_params['test_images_dir'],\n        'labels_dir': dataset_params['test_labels_dir'],\n        'classes': dataset_params['classes']\n    },\n    dataloader_params={\n        'batch_size':16,\n        'num_workers':2\n    }\n)\n\nclear_output()\n</code></pre> Now inspect the dataset defined earlier. SuperGradients added <code>transforms</code> for you. You're free to experiment with these transformations as you please. You can also add in your own transformations from <code>torchvision.transforms</code>, <code>albumentations</code> or a custom tranformaton.</p> <pre><code>train_data.dataset.transforms\n</code></pre> <p>The transforms are in a dictionary, so you'll need to slice it to modify.</p> <p>For example...</p> <pre><code>train_data.dataset.dataset_params['transforms'][1]\n</code></pre> <pre><code>train_data.dataset.dataset_params['transforms'][1]['DetectionRandomAffine']['degrees'] = 10.42\n</code></pre> <p>You can plot a batch of training data with their augmentations applied to see what they look like:</p> <pre><code>train_data.dataset.plot()\n</code></pre> Output <p></p>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#fine-tuning-yolonas-on-custom-dataset_2","title":"Fine-tuning YOLONAS on custom dataset","text":"<p>You saw how to instantiate the model for inference earlier. </p> <p>Below is how to instantiate the model for finetuning. Note you need to add the <code>num_classes</code> argument here.</p> <p>Note, for this tutorial you're using <code>yolo_nas_l</code>, but SuperGradients has two other flavors of YOLONAS available to you: <code>yolo_nas_s</code> and <code>yolo_nas_m</code>.</p> <pre><code>from super_gradients.training import models\nmodel = models.get('yolo_nas_l', \n                   num_classes=len(dataset_params['classes']), \n                   pretrained_weights=\"coco\"\n                   )\n</code></pre>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#define-metrics-and-training-parameters","title":"Define metrics and training parameters","text":"<p>You need to define the training parameters for your training run. </p> <p>Full details about the training parameters can be found here.</p> <p>There are a few ***mandatory* arguments that you must define for training params**</p> <ul> <li> <p><code>max_epochs</code> - Max number of training epochs</p> </li> <li> <p><code>loss</code> - the loss function you want to use</p> </li> <li> <p><code>optimizer</code> - Optimizer you will be using</p> </li> <li> <p><code>train_metrics_list</code> - Metrics to log during training</p> </li> <li> <p><code>valid_metrics_list</code> - Metrics to log during training</p> </li> <li> <p><code>metric_to_watch</code> - metric which the model checkpoint will be saved according to</p> </li> </ul> <p>You can choose from a variety of <code>optimizer</code>'s such as: Adam, AdamW, SGD, Lion, or RMSProps. If you choose to change the defualt parameters of these optimizrs you pass them into <code>optimizer_params</code>. </p> <p>Integrations with experiment monitoring tools SuperGradients has native integrations with Tensorboard, Weights and Biases, ClearML, and DagsHub. </p> <p>If your favorite monitoring tool is not supported by SuperGradients, you can simply implement a class inheriting from BaseSGLogger that you will then pass to the training parameters.</p> <p>If you're interested in monitoring experiments, you can learn more in the docs.</p> <p>SuperGradients offers a number of training tricks right out of the box, such as:</p> <ul> <li>Exponential moving average</li> <li>Zero weight decay on bias and batch normalizatiom</li> <li>Weight averaging</li> <li>Batch accumulation</li> <li>Precise BatchNorm</li> </ul> <p>You can read more details about these training tricks here.</p> <p>If you're interested in building a using a custom metric with SuperGradients you can learn how here.</p> <p>Note you will have to set number of classes in two places below: <code>PPYoloELoss</code> and <code>DetectionMetrics_050</code>.</p> <p>You probably noticed that we make use of a post prediction callback, for details on how phase callbacks work in SuperGradients check out our documentation.</p> <p>Note</p> <p>I've enabled <code>silent_mode</code> so the notebook doesn't get longer than it already is. You should disable it so you can see what SuperGradients outputs during training.</p> <pre><code>from super_gradients.training.losses import PPYoloELoss\nfrom super_gradients.training.metrics import DetectionMetrics_050\nfrom super_gradients.training.models.detection_models.pp_yolo_e import PPYoloEPostPredictionCallback\n\ntrain_params = {\n    # ENABLING SILENT MODE\n    'silent_mode': True,\n    \"average_best_models\":True,\n    \"warmup_mode\": \"linear_epoch_step\",\n    \"warmup_initial_lr\": 1e-6,\n    \"lr_warmup_epochs\": 3,\n    \"initial_lr\": 5e-4,\n    \"lr_mode\": \"cosine\",\n    \"cosine_final_lr_ratio\": 0.1,\n    \"optimizer\": \"Adam\",\n    \"optimizer_params\": {\"weight_decay\": 0.0001},\n    \"zero_weight_decay_on_bias_and_bn\": True,\n    \"ema\": True,\n    \"ema_params\": {\"decay\": 0.9, \"decay_type\": \"threshold\"},\n    # ONLY TRAINING FOR 10 EPOCHS FOR THIS EXAMPLE NOTEBOOK\n    \"max_epochs\": 10,\n    \"mixed_precision\": True,\n    \"loss\": PPYoloELoss(\n        use_static_assigner=False,\n        # NOTE: num_classes needs to be defined here\n        num_classes=len(dataset_params['classes']),\n        reg_max=16\n    ),\n    \"valid_metrics_list\": [\n        DetectionMetrics_050(\n            score_thres=0.1,\n            top_k_predictions=300,\n            # NOTE: num_classes needs to be defined here\n            num_cls=len(dataset_params['classes']),\n            normalize_targets=True,\n            post_prediction_callback=PPYoloEPostPredictionCallback(\n                score_threshold=0.01,\n                nms_top_k=1000,\n                max_predictions=300,\n                nms_threshold=0.7\n            )\n        )\n    ],\n    \"metric_to_watch\": 'mAP@0.50'\n}\n</code></pre>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#training-the-model","title":"Training the model","text":"<p>You've covered a lot of ground so far:</p> <ul> <li> <p> Instantiated the trainer</p> </li> <li> <p> Defined your dataset parameters and dataloaders</p> </li> <li> <p> Instantiated a model</p> </li> <li> <p> Set up your training parameters</p> </li> </ul> <p>Now, its time to train a model</p> <p>Training a model using a SuperGradients is done using the <code>trainer</code>.</p> <p>It's as easy as...</p> <p>trainer.train(model=model,                training_params=train_params,                train_loader=train_data,                valid_loader=val_data)</p>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#get-the-best-trained-model","title":"Get the best trained model","text":"<p>Now that training is complete, you need to get the best trained model.</p> <p>You used checkpoint averaging so the following code will use weights averaged across training runs. </p> <p>If you want to use the best weights, or weights from the last epoch you'd use one of the following in the code below:</p> <ul> <li> <p>best weights: <code>checkpoint_path = checkpoints/my_first_yolonas_run/ckpt_best.pth</code></p> </li> <li> <p>last weights: <code>checkpoint_path = checkpoints/my_first_yolonas_run/ckpt_latest.pth</code></p> </li> </ul> <pre><code>best_model = models.get('yolo_nas_l',\n                        num_classes=len(dataset_params['classes']),\n                        checkpoint_path=\"checkpoints/my_first_yolonas_run/average_model.pth\")\n</code></pre>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#evaluating-the-best-trained-model-on-the-test-set","title":"Evaluating the best trained model on the test set","text":"<pre><code>trainer.test(model=best_model,\n            test_loader=test_data,\n            test_metrics_list=DetectionMetrics_050(score_thres=0.1, \n                                                   top_k_predictions=300, \n                                                   num_cls=len(dataset_params['classes']), \n                                                   normalize_targets=True, \n                                                   post_prediction_callback=PPYoloEPostPredictionCallback(score_threshold=0.01, \n                                                                                                          nms_top_k=1000, \n                                                                                                          max_predictions=300,                                                                              \n                                                                                                          nms_threshold=0.7)\n                                                  ))\n</code></pre>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#predicting-with-the-best-model","title":"Predicting with the best model","text":"<p>The next line will perform detection on the following image. Note, we didn't have a class for the half dollar coin. So it will likely get classified as something else.</p> <p></p> <p>The results aren't too bad after just a few epochs!</p> <pre><code>img_url = 'https://www.mynumi.net/media/catalog/product/cache/2/image/9df78eab33525d08d6e5fb8d27136e95/s/e/serietta_usa_2_1/www.mynumi.net-USASE5AD160-31.jpg'\nbest_model.predict(img_url).show()\n</code></pre>"},{"location":"Documentations/Computer%20Vision%20Algorithms/yolonas/#post-training-quantization-ptq-and-quantization-aware-training-qat","title":"Post training quantization (PTQ) and quantization aware training (QAT)","text":"<p>SuperGradients offers PTQ and QAT out of the box. That's beyond the scope of this introductory tutorial. It is, in my opinion, a truly awesome feature. </p> <p>Not many training libaries offer this out of the box.  You can learn more about PTQ and QAT here.</p> <p>An example specific to YOLONAS can be found here.</p>"},{"location":"Documentations/Libraries/","title":"Libraries","text":"<ul> <li> <p> NumPy</p> <p>Install <code>NumPy</code> with <code>pip</code> and get up  Getting started</p> </li> </ul> <ul> <li> <p> Pandas</p> <p>Install <code>Pandas</code> with <code>pip</code> and get up  Getting started</p> </li> </ul>"},{"location":"Documentations/Libraries/numpy/","title":"NumPy","text":"<p>NumPy is the fundamental library for scientific computing with Python. NumPy is centered around a powerful N-dimensional array object, and it also contains useful linear algebra, Fourier transform, and random number functions.</p>"},{"location":"Documentations/Libraries/numpy/#creating-arrays","title":"Creating Arrays","text":"<p>Now let's import <code>numpy</code>. Most people import it as <code>np</code>:</p> <pre><code>import numpy as np\n</code></pre>"},{"location":"Documentations/Libraries/numpy/#npzeros","title":"np.zeros","text":"<p>The <code>zeros</code> function creates an array containing any number of zeros:</p> <pre><code>np.zeros(5)\n</code></pre> Output <p>array([0., 0., 0., 0., 0.])</p> <p>It's just as easy to create a 2D array (ie. a matrix) by providing a tuple with the desired number of rows and columns. For example, here's a 3x4 matrix:</p> <pre><code>np.zeros((3,4))\n</code></pre> Output <p>array([[0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.]])</p>"},{"location":"Documentations/Libraries/numpy/#some-vocabulary","title":"Some vocabulary","text":"<ul> <li> <p>In NumPy, each dimension is called an axis.</p> </li> <li> <p>The number of axes is called the rank.</p> <ul> <li> <p>For example, the above 3x4 matrix is an array of rank 2 (it is 2-dimensional).</p> </li> <li> <p>The first axis has length 3, the second has length 4.</p> </li> </ul> </li> <li> <p>An array's list of axis lengths is called the shape of the array.</p> <ul> <li> <p>For example, the above matrix's shape is <code>(3, 4)</code>.</p> </li> <li> <p>The rank is equal to the shape's length.</p> </li> </ul> </li> <li> <p>The size of an array is the total number of elements, which is the product of all axis lengths (eg. 3*4=12)</p> </li> </ul> <pre><code>a = np.zeros((3,4))\na\n</code></pre> Output <p>array([[0., 0., 0., 0.],        [0., 0., 0., 0.],        [0., 0., 0., 0.]])</p> <pre><code>a.shape\n</code></pre> Output <p>(3, 4)</p> <pre><code>a.ndim  # equal to len(a.shape)\n</code></pre> Output <p>2</p> <pre><code>a.size\n</code></pre> Output <p>12</p>"},{"location":"Documentations/Libraries/numpy/#n-dimensional-arrays","title":"N-dimensional arrays","text":"<p>You can also create an N-dimensional array of arbitrary rank. For example, here's a 3D array (rank=3), with shape <code>(2,3,4)</code>:</p> <pre><code>np.zeros((2,3,4))\n</code></pre> Output <p>array([[[0., 0., 0., 0.],         [0., 0., 0., 0.],         [0., 0., 0., 0.]],</p> <pre><code>   [[0., 0., 0., 0.],\n    [0., 0., 0., 0.],\n    [0., 0., 0., 0.]]])\n</code></pre>"},{"location":"Documentations/Libraries/numpy/#array-type","title":"Array type","text":"<p>NumPy arrays have the type <code>ndarrays</code>:</p> <pre><code>type(np.zeros((3,4)))\n</code></pre> Output <p>numpy.ndarray</p>"},{"location":"Documentations/Libraries/numpy/#npones","title":"np.ones","text":"<p>Many other NumPy functions create ndarrays.</p> <p>Here's a 3x4 matrix full of ones:</p> <pre><code>np.ones((3,4))\n</code></pre> Output <p>array([[1., 1., 1., 1.],        [1., 1., 1., 1.],        [1., 1., 1., 1.]])</p>"},{"location":"Documentations/Libraries/numpy/#npfull","title":"np.full","text":"<p>Creates an array of the given shape initialized with the given value. Here's a 3x4 matrix full of <code>\u03c0</code>.</p> <pre><code>np.full((3,4), np.pi)\n</code></pre> Output <p>array([[3.14159265, 3.14159265, 3.14159265, 3.14159265],        [3.14159265, 3.14159265, 3.14159265, 3.14159265],        [3.14159265, 3.14159265, 3.14159265, 3.14159265]])</p>"},{"location":"Documentations/Libraries/numpy/#npempty","title":"np.empty","text":"<p>An uninitialized 2x3 array (its content is not predictable, as it is whatever is in memory at that point):</p> <pre><code>np.empty((2,3))\n</code></pre> Output <p>array([[0., 0., 0.],        [0., 0., 0.]])</p>"},{"location":"Documentations/Libraries/numpy/#nparray","title":"np.array","text":"<p>Of course you can initialize an <code>ndarray</code> using a regular python array. Just call the <code>array</code> function:</p> <pre><code>np.array([[1,2,3,4], [10, 20, 30, 40]])\n</code></pre> Output <p>array([[ 1,  2,  3,  4],        [10, 20, 30, 40]])</p>"},{"location":"Documentations/Libraries/numpy/#nparange","title":"np.arange","text":"<p>You can create an <code>ndarray</code> using NumPy's <code>arange</code> function, which is similar to python's built-in <code>range</code> function:</p> <pre><code>np.arange(1, 5)\n</code></pre> Output <p>array([1, 2, 3, 4])</p> <p>It also works with floats:</p> <pre><code>np.arange(1.0, 5.0)\n</code></pre> Output <p>array([1., 2., 3., 4.])</p> <p>Of course you can provide a step parameter:</p> <pre><code>np.arange(1, 5, 0.5)\n</code></pre> Output <p>array([1. , 1.5, 2. , 2.5, 3. , 3.5, 4. , 4.5])</p> <p>However, when dealing with floats, the exact number of elements in the array is not always predictible. For example, consider this:</p> <pre><code>print(np.arange(0, 5/3, 1/3)) # depending on floating point errors, the max value is 4/3 or 5/3.\nprint(np.arange(0, 5/3, 0.333333333))\nprint(np.arange(0, 5/3, 0.333333334))\n</code></pre> Output <p>[0.         0.33333333 0.66666667 1.         1.33333333 1.66666667] [0.         0.33333333 0.66666667 1.         1.33333333 1.66666667] [0.         0.33333333 0.66666667 1.         1.33333334]</p>"},{"location":"Documentations/Libraries/numpy/#nplinspace","title":"np.linspace","text":"<p>For this reason, it is generally preferable to use the <code>linspace</code> function instead of <code>arange</code> when working with floats. The <code>linspace</code> function returns an array containing a specific number of points evenly distributed between two values (note that the maximum value is included, contrary to <code>arange</code>):</p> <pre><code>print(np.linspace(0, 5/3, 6))\n</code></pre> Output <p>[0.         0.33333333 0.66666667 1.         1.33333333 1.66666667]</p>"},{"location":"Documentations/Libraries/numpy/#nprand-and-nprandn","title":"np.rand and np.randn","text":"<p>A number of functions are available in NumPy's <code>random</code> module to create <code>ndarray</code>s initialized with random values. For example, here is a 3x4 matrix initialized with random floats between 0 and 1 (uniform distribution):</p> <pre><code>np.random.rand(3,4)\n</code></pre> Output <p>array([[0.07951522, 0.82516403, 0.54524215, 0.46662691],        [0.12016334, 0.74912183, 0.183234  , 0.105027  ],        [0.22051959, 0.26931151, 0.02739192, 0.4721405 ]])</p> <p>Here's a 3x4 matrix containing random floats sampled from a univariate normal distribution (Gaussian distribution) of mean 0 and variance 1:</p> <pre><code>np.random.randn(3,4)\n</code></pre> Output <p>array([[ 0.09545957,  0.14828368, -0.91504156, -0.36224068],        [ 0.55434999,  0.41143633,  0.84385243, -0.3652369 ],        [ 1.48071803, -1.45297797,  1.24551713,  0.4508626 ]])</p> <p>To give you a feel of what these distributions look like, let's use matplotlib (see the matplotlib tutorial for more details):</p> <pre><code>%matplotlib inline\nimport matplotlib.pyplot as plt\n</code></pre> <pre><code>plt.hist(np.random.rand(100000), density=True, bins=100, histtype=\"step\", color=\"blue\", label=\"rand\")\nplt.hist(np.random.randn(100000), density=True, bins=100, histtype=\"step\", color=\"red\", label=\"randn\")\nplt.axis([-2.5, 2.5, 0, 1.1])\nplt.legend(loc = \"upper left\")\nplt.title(\"Random distributions\")\nplt.xlabel(\"Value\")\nplt.ylabel(\"Density\")\nplt.show()\n</code></pre> Output <p></p>"},{"location":"Documentations/Libraries/numpy/#npfromfunction","title":"np.fromfunction","text":"<p>You can also initialize an <code>ndarray</code> using a function:</p> <pre><code>def my_function(z, y, x):\n    return x + 10 * y + 100 * z\n\nnp.fromfunction(my_function, (3, 2, 10))\n</code></pre> Output <p>array([[[  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.],         [ 10.,  11.,  12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.]],</p> <pre><code>   [[100., 101., 102., 103., 104., 105., 106., 107., 108., 109.],\n    [110., 111., 112., 113., 114., 115., 116., 117., 118., 119.]],\n\n   [[200., 201., 202., 203., 204., 205., 206., 207., 208., 209.],\n    [210., 211., 212., 213., 214., 215., 216., 217., 218., 219.]]])\n</code></pre> <p>NumPy first creates three <code>ndarrays</code> (one per dimension), each of shape <code>(3, 2, 10)</code>. Each array has values equal to the coordinate along a specific axis. For example, all elements in the <code>z</code> array are equal to their z-coordinate:</p> <pre><code>[[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n  [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n\n [[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n  [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]]\n\n [[ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n  [ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]]]\n</code></pre> <p>So the terms <code>x</code>, <code>y</code> and <code>z</code> in the expression <code>x + 10 * y + 100 * z</code> above are in fact <code>ndarrays</code> (we will discuss arithmetic operations on arrays below). The point is that the function <code>my_function</code> is only called once, instead of once per element. This makes initialization very efficient.</p>"},{"location":"Documentations/Libraries/numpy/#array-data","title":"Array data","text":""},{"location":"Documentations/Libraries/numpy/#dtype","title":"dtype","text":"<p>NumPy's <code>ndarrays</code> are also efficient in part because all their elements must have the same type (usually numbers). You can check what the data type is by looking at the <code>dtype</code> attribute:</p> <pre><code>c = np.arange(1, 5)\nprint(c.dtype, c)\n</code></pre> Output <p>int64 [1 2 3 4]</p> <pre><code>c = np.arange(1.0, 5.0)\nprint(c.dtype, c)\n</code></pre> Output <p>float64 [ 1.  2.  3.  4.]</p> <p>Instead of letting NumPy guess what data type to use, you can set it explicitly when creating an array by setting the <code>dtype</code> parameter:</p> Output <p>complex64 [ 1.+0.j  2.+0.j  3.+0.j  4.+0.j]</p> <p>Available data types include <code>int8</code>, <code>int16</code>, <code>int32</code>, <code>int64</code>, <code>uint8</code>|<code>16</code>|<code>32</code>|<code>64</code>, <code>float16</code>|<code>32</code>|<code>64</code> and <code>complex64</code>|<code>128</code>. Check out the documentation for the full list.</p>"},{"location":"Documentations/Libraries/numpy/#itemsize","title":"itemsize","text":"<p>The <code>itemsize</code> attribute returns the size (in bytes) of each item:</p> <pre><code>e = np.arange(1, 5, dtype=np.complex64)\ne.itemsize\n</code></pre> Output <p>8</p>"},{"location":"Documentations/Libraries/numpy/#data-buffer","title":"data buffer","text":"<p>An array's data is actually stored in memory as a flat (one dimensional) byte buffer. It is available via the <code>data</code> attribute (you will rarely need it, though).</p> <pre><code>f = np.array([[1,2],[1000, 2000]], dtype=np.int32)\nf.data\n</code></pre> Output <p> <p>In python 2, <code>f.data</code> is a buffer. In python 3, it is a memoryview.</p> <pre><code>if (hasattr(f.data, \"tobytes\")):\n    data_bytes = f.data.tobytes() # python 3\nelse:\n    data_bytes = memoryview(f.data).tobytes() # python 2\n\ndata_bytes\n</code></pre> Output <p>'\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\xe8\\x03\\x00\\x00\\xd0\\x07\\x00\\x00'</p> <p>Several <code>ndarrays</code> can share the same data buffer, meaning that modifying one will also modify the others. We will see an example in a minute.</p>"},{"location":"Documentations/Libraries/numpy/#reshaping-an-array","title":"Reshaping an array","text":""},{"location":"Documentations/Libraries/numpy/#in-place","title":"In place","text":"<p>Changing the shape of an <code>ndarray</code> is as simple as setting its <code>shape</code> attribute. However, the array's size must remain the same.</p> <pre><code>g = np.arange(24)\nprint(g)\nprint(\"Rank:\", g.ndim)\n</code></pre> Output <p>[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23] Rank: 1</p> <pre><code>g.shape = (6, 4)\nprint(g)\nprint(\"Rank:\", g.ndim)\n</code></pre> Output <p>[[ 0  1  2  3]  [ 4  5  6  7]  [ 8  9 10 11]  [12 13 14 15]  [16 17 18 19]  [20 21 22 23]] Rank: 2</p> <pre><code>g.shape = (2, 3, 4)\nprint(g)\nprint(\"Rank:\", g.ndim)\n</code></pre> Output <p>[[[ 0  1  2  3]   [ 4  5  6  7]   [ 8  9 10 11]]</p> <p>[[12 13 14 15]   [16 17 18 19]   [20 21 22 23]]] Rank: 3</p>"},{"location":"Documentations/Libraries/numpy/#reshape","title":"reshape","text":"<p>The <code>reshape</code> function returns a new <code>ndarray</code> object pointing at the same data. This means that modifying one array will also modify the other.</p> <pre><code>g2 = g.reshape(4,6)\nprint(g2)\nprint(\"Rank:\", g2.ndim)\n</code></pre> Output <p>[[ 0  1  2  3  4  5]  [ 6  7  8  9 10 11]  [12 13 14 15 16 17]  [18 19 20 21 22 23]] Rank: 2</p> <p>Set item at row 1, col 2 to 999 (more about indexing below).</p> <pre><code>g2[1, 2] = 999\ng2\n</code></pre> Output <p>array([[  0,   1,   2,   3,   4,   5],        [  6,   7, 999,   9,  10,  11],        [ 12,  13,  14,  15,  16,  17],        [ 18,  19,  20,  21,  22,  23]])</p> <p>The corresponding element in <code>g</code> has been modified.</p> Output <p>array([[[  0,   1,   2,   3],         [  4,   5,   6,   7],         [999,   9,  10,  11]],</p> <pre><code>   [[ 12,  13,  14,  15],\n    [ 16,  17,  18,  19],\n    [ 20,  21,  22,  23]]])\n</code></pre>"},{"location":"Documentations/Libraries/numpy/#ravel","title":"ravel","text":"<p>Finally, the <code>ravel</code> function returns a new one-dimensional <code>ndarray</code> that also points to the same data:</p> <pre><code>g.ravel()\n</code></pre> Output <p>array([  0,   1,   2,   3,   4,   5,   6,   7, 999,   9,  10,  11,  12,         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23])</p>"},{"location":"Documentations/Libraries/numpy/#arithmetic-operations","title":"Arithmetic operations","text":"<p>All the usual arithmetic operators (<code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>//</code>, <code>**</code>, etc.) can be used with <code>ndarray</code>s. They apply elementwise:</p> <pre><code>a = np.array([14, 23, 32, 41])\nb = np.array([5,  4,  3,  2])\nprint(\"a + b  =\", a + b)\nprint(\"a - b  =\", a - b)\nprint(\"a * b  =\", a * b)\nprint(\"a / b  =\", a / b)\nprint(\"a // b  =\", a // b)\nprint(\"a % b  =\", a % b)\nprint(\"a ** b =\", a ** b)\n</code></pre> Output <p>a + b  = [19 27 35 43] a - b  = [ 9 19 29 39] a * b  = [70 92 96 82] a / b  = [  2.8          5.75        10.66666667  20.5       ] a // b  = [ 2  5 10 20] a % b  = [4 3 2 1] a ** b = [537824 279841  32768   1681]</p> <p>Note that the multiplication is not a matrix multiplication. We will discuss matrix operations below.</p> <p>The arrays must have the same shape. If they do not, NumPy will apply the broadcasting rules.</p>"},{"location":"Documentations/Libraries/numpy/#broadcasting","title":"Broadcasting","text":"<p>In general, when NumPy expects arrays of the same shape but finds that this is not the case, it applies the so-called broadcasting rules:</p>"},{"location":"Documentations/Libraries/numpy/#first-rule","title":"First rule","text":"<p>If the arrays do not have the same rank, then a 1 will be prepended to the smaller ranking arrays until their ranks match.</p> <pre><code>h = np.arange(5).reshape(1, 1, 5)\nh\n</code></pre> Output <p>array([[[0, 1, 2, 3, 4]]])</p> <p>Now let's try to add a 1D array of shape <code>(5,)</code> to this 3D array of shape <code>(1,1,5)</code>. Applying the first rule of broadcasting!</p> <pre><code>h + [10, 20, 30, 40, 50]  # same as: h + [[[10, 20, 30, 40, 50]]]\n</code></pre> Output <p>array([[[10, 21, 32, 43, 54]]])</p>"},{"location":"Documentations/Libraries/numpy/#second-rule","title":"Second rule","text":"<p>Arrays with a 1 along a particular dimension act as if they had the size of the array with the largest shape along that dimension. The value of the array element is repeated along that dimension.</p> <pre><code>k = np.arange(6).reshape(2, 3)\nk\n</code></pre> Output <p>array([[0, 1, 2],        [3, 4, 5]])</p> <p>Let's try to add a 2D array of shape <code>(2,1)</code> to this 2D <code>ndarray</code> of shape <code>(2, 3)</code>. NumPy will apply the second rule of broadcasting:</p> <pre><code>k + [[100], [200]]  # same as: k + [[100, 100, 100], [200, 200, 200]]\n</code></pre> Output <p>array([[100, 101, 102],        [203, 204, 205]])</p> <p>Combining rules 1 &amp; 2, we can do this:</p> <pre><code>k + [100, 200, 300]  # after rule 1: [[100, 200, 300]], and after rule 2: [[100, 200, 300], [100, 200, 300]]\n</code></pre> Output <p>array([[100, 201, 302],        [103, 204, 305]])</p> <p>And also, very simply:</p> <pre><code>k + 1000  # same as: k + [[1000, 1000, 1000], [1000, 1000, 1000]]\n</code></pre> Output <p>array([[1000, 1001, 1002],        [1003, 1004, 1005]])</p>"},{"location":"Documentations/Libraries/numpy/#third-rule","title":"Third rule","text":"<p>After rules 1 &amp; 2, the sizes of all arrays must match.</p> <pre><code>try:\n    k + [33, 44]\nexcept ValueError as e:\n    print(e)\n</code></pre> Output <p>operands could not be broadcast together with shapes (2,3) (2,) </p> <p>Broadcasting rules are used in many NumPy operations, not just arithmetic operations, as we will see below. For more details about broadcasting, check out the documentation.</p>"},{"location":"Documentations/Libraries/numpy/#upcasting","title":"Upcasting","text":"<p>When trying to combine arrays with different <code>dtype</code>s, NumPy will upcast to a type capable of handling all possible values (regardless of what the actual values are).</p> <pre><code>k1 = np.arange(0, 5, dtype=np.uint8)\nprint(k1.dtype, k1)\n</code></pre> Output <p>uint8 [0 1 2 3 4]</p> <pre><code>k2 = k1 + np.array([5, 6, 7, 8, 9], dtype=np.int8)\nprint(k2.dtype, k2)\n</code></pre> Output <p>int16 [ 5  7  9 11 13]</p> <p>Note that <code>int16</code> is required to represent all possible <code>int8</code> and <code>uint8</code> values (from -128 to 255), even though in this case a uint8 would have sufficed.</p> <pre><code>k3 = k1 + 1.5\nprint(k3.dtype, k3)\n</code></pre> Output <p>float64 [ 1.5  2.5  3.5  4.5  5.5]</p>"},{"location":"Documentations/Libraries/numpy/#conditional-operators","title":"Conditional operators","text":"<p>The conditional operators also apply elementwise:</p> <pre><code>m = np.array([20, -5, 30, 40])\nm &lt; [15, 16, 35, 36]\n</code></pre> Output <p>array([False,  True,  True, False], dtype=bool)</p> <p>And using broadcasting:</p> <pre><code>m &lt; 25  # equivalent to m &lt; [25, 25, 25, 25]\n</code></pre> Output <p>array([ True,  True, False, False], dtype=bool)</p> <p>This is most useful in conjunction with boolean indexing (discussed below).</p> <pre><code>m[m &lt; 25]\n</code></pre> Output <p>array([20, -5])</p>"},{"location":"Documentations/Libraries/numpy/#mathematical-and-statistical-functions","title":"Mathematical and statistical functions","text":"<p>Many mathematical and statistical functions are available for <code>ndarray</code>s.</p>"},{"location":"Documentations/Libraries/numpy/#ndarray-methods","title":"ndarray methods","text":"<p>Some functions are simply <code>ndarray</code> methods, for example:</p> <pre><code>a = np.array([[-2.5, 3.1, 7], [10, 11, 12]])\nprint(a)\nprint(\"mean =\", a.mean())\n</code></pre> Output <p>[[ -2.5   3.1   7. ]  [ 10.   11.   12. ]] mean = 6.76666666667</p> <p>Note that this computes the mean of all elements in the <code>ndarray</code>, regardless of its shape.</p> <p>Here are a few more useful <code>ndarray</code> methods:</p> <pre><code>for func in (a.min, a.max, a.sum, a.prod, a.std, a.var):\n    print(func.__name__, \"=\", func())\n</code></pre> Output <p>min = -2.5 max = 12.0 sum = 40.6 prod = -71610.0 std = 5.08483584352 var = 25.8555555556</p> <p>These functions accept an optional argument <code>axis</code> which lets you ask for the operation to be performed on elements along the given axis. For example:</p> <pre><code>c=np.arange(24).reshape(2,3,4)\nc\n</code></pre> Output <p>array([[[ 0,  1,  2,  3],         [ 4,  5,  6,  7],         [ 8,  9, 10, 11]],</p> <pre><code>   [[12, 13, 14, 15],\n    [16, 17, 18, 19],\n    [20, 21, 22, 23]]])\n</code></pre> <pre><code>c.sum(axis=0)  # sum across matrices\n</code></pre> Output <p>array([[12, 14, 16, 18],        [20, 22, 24, 26],        [28, 30, 32, 34]])</p> <pre><code>c.sum(axis=1)  # sum across rows\n</code></pre> Output <p>array([[12, 15, 18, 21],        [48, 51, 54, 57]])</p> <p>You can also sum over multiple axes:</p> <pre><code>c.sum(axis=(0,2))  # sum across matrices and columns\n</code></pre> Output <p>array([ 60,  92, 124])</p> <pre><code>0+1+2+3 + 12+13+14+15, 4+5+6+7 + 16+17+18+19, 8+9+10+11 + 20+21+22+23\n</code></pre> Output <p>(60, 92, 124)</p>"},{"location":"Documentations/Libraries/numpy/#universal-functions","title":"Universal functions","text":"<p>NumPy also provides fast elementwise functions called universal functions, or ufunc. They are vectorized wrappers of simple functions. For example <code>square</code> returns a new <code>ndarray</code> which is a copy of the original <code>ndarray</code> except that each element is squared:</p> <pre><code>a = np.array([[-2.5, 3.1, 7], [10, 11, 12]])\nnp.square(a)\n</code></pre> Output <p>array([[   6.25,    9.61,   49.  ],        [ 100.  ,  121.  ,  144.  ]])</p> <p>Here are a few more useful unary ufuncs:</p> <pre><code>print(\"Original ndarray\")\nprint(a)\nfor func in (np.abs, np.sqrt, np.exp, np.log, np.sign, np.ceil, np.modf, np.isnan, np.cos):\n    print(\"\\n\", func.__name__)\n    print(func(a))\n</code></pre> Output <p>Original ndarray [[ -2.5   3.1   7. ]  [ 10.   11.   12. ]]</p> <p>absolute [[  2.5   3.1   7. ]  [ 10.   11.   12. ]]</p> <p>sqrt [[        nan  1.76068169  2.64575131]  [ 3.16227766  3.31662479  3.46410162]]</p> <p>exp [[  8.20849986e-02   2.21979513e+01   1.09663316e+03]  [  2.20264658e+04   5.98741417e+04   1.62754791e+05]]</p> <p>log [[        nan  1.13140211  1.94591015]  [ 2.30258509  2.39789527  2.48490665]]</p> <p>sign [[-1.  1.  1.]  [ 1.  1.  1.]]</p> <p>ceil [[ -2.   4.   7.]  [ 10.  11.  12.]]</p> <p>modf (array([[-0.5,  0.1,  0. ],        [ 0. ,  0. ,  0. ]]), array([[ -2.,   3.,   7.],        [ 10.,  11.,  12.]]))</p> <p>isnan [[False False False]  [False False False]]</p> <p>cos [[-0.80114362 -0.99913515  0.75390225]  [-0.83907153  0.0044257   0.84385396]] -c:5: RuntimeWarning: invalid value encountered in sqrt -c:5: RuntimeWarning: invalid value encountered in log</p>"},{"location":"Documentations/Libraries/numpy/#binary-ufuncs","title":"Binary ufuncs","text":"<p>There are also many binary ufuncs, that apply elementwise on two <code>ndarray</code>s. Broadcasting rules are applied if the arrays do not have the same shape:</p> <pre><code>a = np.array([1, -2, 3, 4])\nb = np.array([2, 8, -1, 7])\nnp.add(a, b)  # equivalent to a + b\n</code></pre> Output <p>array([ 3,  6,  2, 11])</p> <pre><code>np.greater(a, b)  # equivalent to a &gt; b\n</code></pre> Output <p>array([False, False,  True, False], dtype=bool)</p> <pre><code>np.maximum(a, b)\n</code></pre> Output <p>array([2, 8, 3, 7])</p> <pre><code>np.copysign(a, b)\n</code></pre> Output <p>array([ 1.,  2., -3.,  4.])</p>"},{"location":"Documentations/Libraries/numpy/#array-indexing","title":"Array indexing","text":""},{"location":"Documentations/Libraries/numpy/#one-dimensional-arrays","title":"One-dimensional arrays","text":"<p>One-dimensional NumPy arrays can be accessed more or less like regular python arrays:</p> <pre><code>a = np.array([1, 5, 3, 19, 13, 7, 3])\na[3]\n</code></pre> Output <p>19</p> <pre><code>a[2:5]\n</code></pre> Output <p>array([ 3, 19, 13])</p> <pre><code>a[2:-1]\n</code></pre> Output <p>array([ 3, 19, 13,  7])</p> <pre><code>a[:2]\n</code></pre> Output <p>array([1, 5])</p> <pre><code>a[2::2]\n</code></pre> Output <p>array([ 3, 13,  3])</p> <pre><code>a[::-1]\n</code></pre> Output <p>array([ 3,  7, 13, 19,  3,  5,  1])</p> <p>Of course, you can modify elements:</p> <pre><code>a[3]=999\na\n</code></pre> Output <p>array([  1,   5,   3, 999,  13,   7,   3])</p> <p>You can also modify an <code>ndarray</code> slice:</p> <pre><code>a[2:5] = [997, 998, 999]\na\n</code></pre> Output <p>array([  1,   5, 997, 998, 999,   7,   3])</p>"},{"location":"Documentations/Libraries/numpy/#differences-with-regular-python-arrays","title":"Differences with regular python arrays","text":"<p>Contrary to regular python arrays, if you assign a single value to an <code>ndarray</code> slice, it is copied across the whole slice, thanks to broadcasting rules discussed above.</p> <pre><code>a[2:5] = -1\na\n</code></pre> Output <p>array([ 1,  5, -1, -1, -1,  7,  3])</p> <p>Also, you cannot grow or shrink <code>ndarrays</code> this way:</p> <pre><code>try:\n    a[2:5] = [1,2,3,4,5,6]  # too long\nexcept ValueError as e:\n    print(e)\n</code></pre> Output <p>cannot copy sequence with size 6 to array axis with dimension 3</p> <p>You cannot delete elements either:</p> <pre><code>try:\n    del a[2:5]\nexcept ValueError as e:\n    print(e)\n</code></pre> Output <p>cannot delete array elements</p> <p>Last but not least, <code>ndarray</code> slices are actually views on the same data buffer. This means that if you create a slice and modify it, you are actually going to modify the original <code>ndarray</code> as well!</p> <pre><code>a_slice = a[2:6]\na_slice[1] = 1000\na  # the original array was modified!\n</code></pre> Output <p>array([   1,    5,   -1, 1000,   -1,    7,    3])</p> <pre><code>a[3] = 2000\na_slice  # similarly, modifying the original array modifies the slice!\n</code></pre> Output <p>array([  -1, 2000,   -1,    7])</p> <p>If you want a copy of the data, you need to use the <code>copy</code> method:</p> <pre><code>another_slice = a[2:6].copy()\nanother_slice[1] = 3000\na  # the original array is untouched\n</code></pre> Output <p>array([   1,    5,   -1, 2000,   -1,    7,    3])</p> <pre><code>a[3] = 4000\nanother_slice  # similary, modifying the original array does not affect the slice copy\n</code></pre> Output <p>array([  -1, 3000,   -1,    7])</p>"},{"location":"Documentations/Libraries/numpy/#multi-dimensional-arrays","title":"Multi-dimensional arrays","text":"<p>Multi-dimensional arrays can be accessed in a similar way by providing an index or slice for each axis, separated by commas:</p> <pre><code>b = np.arange(48).reshape(4, 12)\nb\n</code></pre> Output <p>array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],        [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]])</p> <pre><code>b[1, 2]  # row 1, col 2\n</code></pre> Output <p>14</p> <pre><code>b[1, :]  # row 1, all columns\n</code></pre> Output <p>array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])</p> <pre><code>b[:, 1]  # all rows, column 1\n</code></pre> Output <p>array([ 1, 13, 25, 37])</p> <p>Caution</p> <p>note the subtle difference between these two expressions:</p> <pre><code>b[1, :]\n</code></pre> Output <p>array([12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])</p> <pre><code>b[1:2, :]\n</code></pre> Output <p>array([[12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]])</p> <p>The first expression returns row 1 as a 1D array of shape <code>(12,)</code>, while the second returns that same row as a 2D array of shape <code>(1, 12)</code>.</p>"},{"location":"Documentations/Libraries/numpy/#fancy-indexing","title":"Fancy indexing","text":"<p>You may also specify a list of indices that you are interested in. This is referred to as fancy indexing.</p> <pre><code>b[(0,2), 2:5]  # rows 0 and 2, columns 2 to 4 (5-1)\n</code></pre> Output <p>array([[ 2,  3,  4],        [26, 27, 28]])</p> <pre><code>b[:, (-1, 2, -1)]  # all rows, columns -1 (last), 2 and -1 (again, and in this order)\n</code></pre> Output <p>array([[11,  2, 11],        [23, 14, 23],        [35, 26, 35],        [47, 38, 47]])</p> <p>If you provide multiple index arrays, you get a 1D <code>ndarray</code> containing the values of the elements at the specified coordinates.</p> <pre><code>b[(-1, 2, -1, 2), (5, 9, 1, 9)]  # returns a 1D array with b[-1, 5], b[2, 9], b[-1, 1] and b[2, 9] (again)\n</code></pre> Output <p>array([41, 33, 37, 33])</p>"},{"location":"Documentations/Libraries/numpy/#higher-dimensions","title":"Higher dimensions","text":"<p>Everything works just as well with higher dimensional arrays, but it's useful to look at a few examples:</p> <pre><code>c = b.reshape(4,2,6)\nc\n</code></pre> Output <p>array([[[ 0,  1,  2,  3,  4,  5],         [ 6,  7,  8,  9, 10, 11]],</p> <pre><code>   [[12, 13, 14, 15, 16, 17],\n    [18, 19, 20, 21, 22, 23]],\n\n   [[24, 25, 26, 27, 28, 29],\n    [30, 31, 32, 33, 34, 35]],\n\n   [[36, 37, 38, 39, 40, 41],\n    [42, 43, 44, 45, 46, 47]]])\n</code></pre> <pre><code>c[2, 1, 4]  # matrix 2, row 1, col 4\n</code></pre> Output <p>34</p> <pre><code>c[2, :, 3]  # matrix 2, all rows, col 3\n</code></pre> Output <p>array([27, 33])</p> <p>If you omit coordinates for some axes, then all elements in these axes are returned:</p> <pre><code>c[2, 1]  # Return matrix 2, row 1, all columns.  This is equivalent to c[2, 1, :]\n</code></pre> Output <p>array([30, 31, 32, 33, 34, 35])</p>"},{"location":"Documentations/Libraries/numpy/#ellipsis","title":"Ellipsis (...)","text":"<p>You may also write an ellipsis (<code>...</code>) to ask that all non-specified axes be entirely included.</p> <pre><code>c[2, ...]  #  matrix 2, all rows, all columns.  This is equivalent to c[2, :, :]\n</code></pre> Output <p>array([[24, 25, 26, 27, 28, 29],        [30, 31, 32, 33, 34, 35]])</p> <pre><code>c[2, 1, ...]  # matrix 2, row 1, all columns.  This is equivalent to c[2, 1, :]\n</code></pre> Output <p>array([30, 31, 32, 33, 34, 35])</p> <pre><code>c[2, ..., 3]  # matrix 2, all rows, column 3.  This is equivalent to c[2, :, 3]\n</code></pre> Output <p>array([27, 33])</p> <pre><code>c[..., 3]  # all matrices, all rows, column 3.  This is equivalent to c[:, :, 3]\n</code></pre> Output <p>array([[ 3,  9],        [15, 21],        [27, 33],        [39, 45]])</p>"},{"location":"Documentations/Libraries/numpy/#boolean-indexing","title":"Boolean indexing","text":"<p>You can also provide an <code>ndarray</code> of boolean values on one axis to specify the indices that you want to access.</p> <pre><code>b = np.arange(48).reshape(4, 12)\nb\n</code></pre> Output <p>array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],        [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23],        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35],        [36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]])</p> <pre><code>rows_on = np.array([True, False, True, False])\nb[rows_on, :]  # Rows 0 and 2, all columns. Equivalent to b[(0, 2), :]\n</code></pre> Output <p>array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],        [24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]])</p> <pre><code>cols_on = np.array([False, True, False] * 4)\nb[:, cols_on]  # All rows, columns 1, 4, 7 and 10\n</code></pre> Output <p>array([[ 1,  4,  7, 10],        [13, 16, 19, 22],        [25, 28, 31, 34],        [37, 40, 43, 46]])</p>"},{"location":"Documentations/Libraries/numpy/#npix_","title":"np.ix_","text":"<p>You cannot use boolean indexing this way on multiple axes, but you can work around this by using the <code>ix_</code> function:</p> <pre><code>b[np.ix_(rows_on, cols_on)]\n</code></pre> Output <p>array([[ 1,  4,  7, 10],        [25, 28, 31, 34]])</p> <pre><code>np.ix_(rows_on, cols_on)\n</code></pre> Output <p>(array([[0],         [2]]), array([[ 1,  4,  7, 10]]))</p> <p>If you use a boolean array that has the same shape as the <code>ndarray</code>, then you get in return a 1D array containing all the values that have <code>True</code> at their coordinate. This is generally used along with conditional operators:</p> <pre><code>b[b % 3 == 1]\n</code></pre> Output <p>array([ 1,  4,  7, 10, 13, 16, 19, 22, 25, 28, 31, 34, 37, 40, 43, 46])</p>"},{"location":"Documentations/Libraries/numpy/#iterating","title":"Iterating","text":"<p>Iterating over <code>ndarrays</code> is very similar to iterating over regular python arrays. Note that iterating over multidimensional arrays is done with respect to the first axis.</p> <pre><code>c = np.arange(24).reshape(2, 3, 4)  # A 3D array (composed of two 3x4 matrices)\nc\n</code></pre> Output <p>array([[[ 0,  1,  2,  3],         [ 4,  5,  6,  7],         [ 8,  9, 10, 11]],</p> <pre><code>   [[12, 13, 14, 15],\n    [16, 17, 18, 19],\n    [20, 21, 22, 23]]])\n</code></pre> <pre><code>for m in c:\n    print(\"Item:\")\n    print(m)\n</code></pre> Output <p>Item: [[ 0  1  2  3]  [ 4  5  6  7]  [ 8  9 10 11]] Item: [[12 13 14 15]  [16 17 18 19]  [20 21 22 23]]</p> <pre><code>for i in range(len(c)):  # Note that len(c) == c.shape[0]\n    print(\"Item:\")\n    print(c[i])\n</code></pre> Output <p>Item: [[ 0  1  2  3]  [ 4  5  6  7]  [ 8  9 10 11]] Item: [[12 13 14 15]  [16 17 18 19]  [20 21 22 23]]</p> <p>If you want to iterate on all elements in the <code>ndarray</code>, simply iterate over the <code>flat</code> attribute:</p> <pre><code>for i in c.flat:\n    print(\"Item:\", i)\n</code></pre> Output <p>Item: 0 Item: 1 Item: 2 Item: 3 Item: 4 Item: 5 Item: 6 Item: 7 Item: 8 Item: 9 Item: 10 Item: 11 Item: 12 Item: 13 Item: 14 Item: 15 Item: 16 Item: 17 Item: 18 Item: 19 Item: 20 Item: 21 Item: 22 Item: 23</p>"},{"location":"Documentations/Libraries/numpy/#stacking-arrays","title":"Stacking arrays","text":"<p>It is often useful to stack together different arrays. NumPy offers several functions to do just that. Let's start by creating a few arrays.</p> <pre><code>q1 = np.full((3,4), 1.0)\nq1\n</code></pre> Output <p>array([[ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.]])</p> <pre><code>q2 = np.full((4,4), 2.0)\nq2\n</code></pre> Output <p>array([[ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.]])</p> <pre><code>q3 = np.full((3,4), 3.0)\nq3\n</code></pre> Output <p>array([[ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.]])</p>"},{"location":"Documentations/Libraries/numpy/#vstack","title":"vstack","text":"<p>Now let's stack them vertically using <code>vstack</code>:</p> <pre><code>q4 = np.vstack((q1, q2, q3))\nq4\n</code></pre> Output <p>array([[ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.]])</p> <pre><code>q4.shape\n</code></pre> Output <p>(10, 4)</p> <p>This was possible because q1, q2 and q3 all have the same shape (except for the vertical axis, but that's ok since we are stacking on that axis).</p>"},{"location":"Documentations/Libraries/numpy/#hstack","title":"hstack","text":"<p>We can also stack arrays horizontally using <code>hstack</code>:</p> <pre><code>q5 = np.hstack((q1, q3))\nq5\n</code></pre> Output <p>array([[ 1.,  1.,  1.,  1.,  3.,  3.,  3.,  3.],        [ 1.,  1.,  1.,  1.,  3.,  3.,  3.,  3.],        [ 1.,  1.,  1.,  1.,  3.,  3.,  3.,  3.]])</p> <pre><code>q5.shape\n</code></pre> Output <p>(3, 8)</p> <p>This is possible because q1 and q3 both have 3 rows. But since q2 has 4 rows, it cannot be stacked horizontally with q1 and q3:</p> <pre><code>try:\n    q5 = np.hstack((q1, q2, q3))\nexcept ValueError as e:\n    print(e)\n</code></pre> Output <p>all the input array dimensions except for the concatenation axis must match exactly</p>"},{"location":"Documentations/Libraries/numpy/#concatenate","title":"concatenate","text":"<p>The <code>concatenate</code> function stacks arrays along any given existing axis.</p> <pre><code>q7 = np.concatenate((q1, q2, q3), axis=0)  # Equivalent to vstack\nq7\n</code></pre> Output <p>array([[ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 1.,  1.,  1.,  1.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 2.,  2.,  2.,  2.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.],        [ 3.,  3.,  3.,  3.]])</p> <pre><code>q7.shape\n</code></pre> Output <p>(10, 4)</p> <p>As you might guess, <code>hstack</code> is equivalent to calling <code>concatenate</code> with <code>axis=1</code>.</p>"},{"location":"Documentations/Libraries/numpy/#stack","title":"stack","text":"<p>The <code>stack</code> function stacks arrays along a new axis. All arrays have to have the same shape.</p> <pre><code>q8 = np.stack((q1, q3))\nq8\n</code></pre> Output <p>array([[[ 1.,  1.,  1.,  1.],         [ 1.,  1.,  1.,  1.],         [ 1.,  1.,  1.,  1.]],</p> <pre><code>   [[ 3.,  3.,  3.,  3.],\n    [ 3.,  3.,  3.,  3.],\n    [ 3.,  3.,  3.,  3.]]])\n</code></pre> <pre><code>q8.shape\n</code></pre> Output <p>(2, 3, 4)</p>"},{"location":"Documentations/Libraries/numpy/#splitting-arrays","title":"Splitting arrays","text":"<p>Splitting is the opposite of stacking. For example, let's use the <code>vsplit</code> function to split a matrix vertically.</p> <p>First let's create a 6x4 matrix:</p> <pre><code>r = np.arange(24).reshape(6,4)\nr\n</code></pre> Output <p>array([[ 0,  1,  2,  3],        [ 4,  5,  6,  7],        [ 8,  9, 10, 11],        [12, 13, 14, 15],        [16, 17, 18, 19],        [20, 21, 22, 23]])</p> <p>Now let's split it in three equal parts, vertically:</p> <pre><code>r1, r2, r3 = np.vsplit(r, 3)\nr1\n</code></pre> Output <p>array([[0, 1, 2, 3],        [4, 5, 6, 7]])</p> <pre><code>r2\n</code></pre> Output <p>array([[ 8,  9, 10, 11],        [12, 13, 14, 15]])</p> <pre><code>r3\n</code></pre> Output <p>array([[16, 17, 18, 19],        [20, 21, 22, 23]])</p> <p>There is also a <code>split</code> function which splits an array along any given axis. Calling <code>vsplit</code> is equivalent to calling <code>split</code> with <code>axis=0</code>. There is also an <code>hsplit</code> function, equivalent to calling <code>split</code> with <code>axis=1</code>:</p> <pre><code>r4, r5 = np.hsplit(r, 2)\nr4\n</code></pre> Output <p>array([[ 0,  1],        [ 4,  5],        [ 8,  9],        [12, 13],        [16, 17],        [20, 21]])</p> <pre><code>r5\n</code></pre> Output <p>array([[ 2,  3],        [ 6,  7],        [10, 11],        [14, 15],        [18, 19],        [22, 23]])</p>"},{"location":"Documentations/Libraries/numpy/#transposing-arrays","title":"Transposing arrays","text":"<p>The <code>transpose</code> method creates a new view on an <code>ndarray</code>'s data, with axes permuted in the given order.</p> <p>For example, let's create a 3D array:</p> <pre><code>t = np.arange(24).reshape(4,2,3)\nt\n</code></pre> Output <p>array([[[ 0,  1,  2],         [ 3,  4,  5]],</p> <pre><code>   [[ 6,  7,  8],\n    [ 9, 10, 11]],\n\n   [[12, 13, 14],\n    [15, 16, 17]],\n\n   [[18, 19, 20],\n    [21, 22, 23]]])\n</code></pre> <p>Now let's create an <code>ndarray</code> such that the axes <code>0, 1, 2</code> (depth, height, width) are re-ordered to <code>1, 2, 0</code> (depth\u2192width, height\u2192depth, width\u2192height):</p> <pre><code>t1 = t.transpose((1,2,0))\nt1\n</code></pre> Output <p>array([[[ 0,  6, 12, 18],         [ 1,  7, 13, 19],         [ 2,  8, 14, 20]],</p> <pre><code>   [[ 3,  9, 15, 21],\n    [ 4, 10, 16, 22],\n    [ 5, 11, 17, 23]]])\n</code></pre> <pre><code>t1.shape\n</code></pre> Output <p>(2, 3, 4)</p> <p>By default, <code>transpose</code> reverses the order of the dimensions:</p> <pre><code>t2 = t.transpose()  # equivalent to t.transpose((2, 1, 0))\nt2\n</code></pre> Output <p>array([[[ 0,  6, 12, 18],         [ 3,  9, 15, 21]],</p> <pre><code>   [[ 1,  7, 13, 19],\n    [ 4, 10, 16, 22]],\n\n   [[ 2,  8, 14, 20],\n    [ 5, 11, 17, 23]]])\n</code></pre> <pre><code>t2.shape\n</code></pre> Output <p>(3, 2, 4)</p> <p>NumPy provides a convenience function <code>swapaxes</code> to swap two axes. For example, let's create a new view of <code>t</code> with depth and height swapped:</p> <pre><code>t3 = t.swapaxes(0,1)  # equivalent to t.transpose((1, 0, 2))\nt3\n</code></pre> Output <p>array([[[ 0,  1,  2],         [ 6,  7,  8],         [12, 13, 14],         [18, 19, 20]],</p> <pre><code>   [[ 3,  4,  5],\n    [ 9, 10, 11],\n    [15, 16, 17],\n    [21, 22, 23]]])\n</code></pre> <pre><code>t3.shape\n</code></pre> Output <p>(2, 4, 3)</p>"},{"location":"Documentations/Libraries/numpy/#linear-algebra","title":"Linear algebra","text":"<p>NumPy 2D arrays can be used to represent matrices efficiently in python. We will just quickly go through some of the main matrix operations available. For more details about Linear Algebra, vectors and matrics, go through the Linear Algebra tutorial.</p>"},{"location":"Documentations/Libraries/numpy/#matrix-transpose","title":"Matrix transpose","text":"<p>The <code>T</code> attribute is equivalent to calling <code>transpose()</code> when the rank is \u22652:</p> <pre><code>m1 = np.arange(10).reshape(2,5)\nm1\n</code></pre> Output <p>array([[0, 1, 2, 3, 4],        [5, 6, 7, 8, 9]])</p> <pre><code>m1.T\n</code></pre> Output <p>array([[0, 5],        [1, 6],        [2, 7],        [3, 8],        [4, 9]])</p> <p>The <code>T</code> attribute has no effect on rank 0 (empty) or rank 1 arrays:</p> <pre><code>m2 = np.arange(5)\nm2\n</code></pre> Output <p>array([0, 1, 2, 3, 4])</p> <pre><code>m2.T\n</code></pre> Output <p>array([0, 1, 2, 3, 4])</p> <p>We can get the desired transposition by first reshaping the 1D array to a single-row matrix (2D):</p> <pre><code>m2r = m2.reshape(1,5)\nm2r\n</code></pre> Output <p>array([[0, 1, 2, 3, 4]])</p> <pre><code>m2r.T\n</code></pre> Output <p>array([[0],       [1],       [2],       [3],       [4]])</p>"},{"location":"Documentations/Libraries/numpy/#matrix-multiplication","title":"Matrix multiplication","text":"<p>Let's create two matrices and execute a matrix multiplication using the <code>dot()</code> method.</p> <pre><code>n1 = np.arange(10).reshape(2, 5)\nn1\n</code></pre> Output <p>array([[0, 1, 2, 3, 4],        [5, 6, 7, 8, 9]])</p> <pre><code>n2 = np.arange(15).reshape(5,3)\nn2\n</code></pre> Output <p>array([[ 0,  1,  2],        [ 3,  4,  5],        [ 6,  7,  8],        [ 9, 10, 11],        [12, 13, 14]])</p> <pre><code>n1.dot(n2)\n</code></pre> Output <p>array([[ 90, 100, 110],        [240, 275, 310]])</p> <p>Caution</p> <p>As mentionned previously, <code>n1*n2</code> is not a matric multiplication, it is an elementwise product (also called a Hadamard product).</p>"},{"location":"Documentations/Libraries/numpy/#matrix-inverse-and-pseudo-inverse","title":"Matrix inverse and pseudo-inverse","text":"<p>Many of the linear algebra functions are available in the <code>numpy.linalg</code> module, in particular the <code>inv</code> function to compute a square matrix's inverse:</p> <pre><code>import numpy.linalg as linalg\n\nm3 = np.array([[1,2,3],[5,7,11],[21,29,31]])\nm3\n</code></pre> Output <p>array([[ 1,  2,  3],        [ 5,  7, 11],        [21, 29, 31]])</p> <pre><code>linalg.inv(m3)\n</code></pre> Output <p>array([[-2.31818182,  0.56818182,  0.02272727],        [ 1.72727273, -0.72727273,  0.09090909],        [-0.04545455,  0.29545455, -0.06818182]])</p> <p>You can also compute the pseudoinverse using <code>pinv</code>:</p> <pre><code>linalg.pinv(m3)\n</code></pre> Output <p>array([[-2.31818182,  0.56818182,  0.02272727],        [ 1.72727273, -0.72727273,  0.09090909],        [-0.04545455,  0.29545455, -0.06818182]])</p>"},{"location":"Documentations/Libraries/numpy/#identity-matrix","title":"Identity matrix","text":"<p>The product of a matrix by its inverse returns the identiy matrix (with small floating point errors):</p> <pre><code>m3.dot(linalg.inv(m3))\n</code></pre> Output <p>array([[  1.00000000e+00,  -1.11022302e-16,  -6.93889390e-18],        [ -1.33226763e-15,   1.00000000e+00,  -5.55111512e-17],        [  2.88657986e-15,   0.00000000e+00,   1.00000000e+00]])</p> <p>You can create an identity matrix of size NxN by calling <code>eye</code>:</p> <pre><code>np.eye(3)\n</code></pre> Output <p>array([[ 1.,  0.,  0.],        [ 0.,  1.,  0.],        [ 0.,  0.,  1.]])</p>"},{"location":"Documentations/Libraries/numpy/#qr-decomposition","title":"QR decomposition","text":"<p>The <code>qr</code> function computes the QR decomposition of a matrix:</p> <pre><code>q, r = linalg.qr(m3)\nq\n</code></pre> Output <p>array([[-0.04627448,  0.98786672,  0.14824986],        [-0.23137241,  0.13377362, -0.96362411],        [-0.97176411, -0.07889213,  0.22237479]])</p> <pre><code>r\n</code></pre> Output <p>array([[-21.61018278, -29.89331494, -32.80860727],        [  0.        ,   0.62427688,   1.9894538 ],        [  0.        ,   0.        ,  -3.26149699]])</p> <pre><code>q.dot(r)  # q.r equals m3\n</code></pre> Output <p>array([[  1.,   2.,   3.],        [  5.,   7.,  11.],        [ 21.,  29.,  31.]])</p>"},{"location":"Documentations/Libraries/numpy/#determinant","title":"Determinant","text":"<p>The <code>det</code> function computes the matrix determinant:</p> <pre><code>linalg.det(m3)  # Computes the matrix determinant\n</code></pre> Output <p>43.999999999999972</p>"},{"location":"Documentations/Libraries/numpy/#eigenvalues-and-eigenvectors","title":"Eigenvalues and eigenvectors","text":"<p>The <code>eig</code> function computes the eigenvalues and eigenvectors of a square matrix:</p> <pre><code>eigenvalues, eigenvectors = linalg.eig(m3)\neigenvalues # \u03bb\n</code></pre> Output <p>array([ 42.26600592,  -0.35798416,  -2.90802176])</p> <pre><code>eigenvectors # v\n</code></pre> Output <p>array([[-0.08381182, -0.76283526, -0.18913107],        [-0.3075286 ,  0.64133975, -0.6853186 ],        [-0.94784057, -0.08225377,  0.70325518]])</p> <pre><code>m3.dot(eigenvectors) - eigenvalues * eigenvectors  # m3.v - \u03bb*v = 0\n</code></pre> Output <p>array([[  8.88178420e-15,   2.49800181e-15,  -3.33066907e-16],        [  1.77635684e-14,  -1.66533454e-16,  -3.55271368e-15],        [  3.55271368e-14,   3.61516372e-15,  -4.44089210e-16]])</p>"},{"location":"Documentations/Libraries/numpy/#singular-value-decomposition","title":"Singular Value Decomposition","text":"<p>The <code>svd</code> function takes a matrix and returns its singular value decomposition:</p> <pre><code>m4 = np.array([[1,0,0,0,2], [0,0,3,0,0], [0,0,0,0,0], [0,2,0,0,0]])\nm4\n</code></pre> Output <p>array([[1, 0, 0, 0, 2],        [0, 0, 3, 0, 0],        [0, 0, 0, 0, 0],        [0, 2, 0, 0, 0]])</p> <pre><code>U, S_diag, V = linalg.svd(m4)\nU\n</code></pre> Output <p>array([[ 0.,  1.,  0.,  0.],        [ 1.,  0.,  0.,  0.],        [ 0.,  0.,  0., -1.],        [ 0.,  0.,  1.,  0.]])</p> <pre><code>S_diag\n</code></pre> Output <p>array([ 3.        ,  2.23606798,  2.        ,  0.        ])</p> <p>The <code>svd</code> function just returns the values in the diagonal of \u03a3, but we want the full \u03a3 matrix, so let's create it:</p> <pre><code>S = np.zeros((4, 5))\nS[np.diag_indices(4)] = S_diag\nS  # \u03a3\n</code></pre> Output <p>array([[ 3.        ,  0.        ,  0.        ,  0.        ,  0.        ],        [ 0.        ,  2.23606798,  0.        ,  0.        ,  0.        ],        [ 0.        ,  0.        ,  2.        ,  0.        ,  0.        ],        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ]])</p> <pre><code>V\n</code></pre> Output <p>array([[-0.        ,  0.        ,  1.        , -0.        ,  0.        ],        [ 0.4472136 ,  0.        ,  0.        ,  0.        ,  0.89442719],        [-0.        ,  1.        ,  0.        , -0.        ,  0.        ],        [ 0.        ,  0.        ,  0.        ,  1.        ,  0.        ],        [-0.89442719,  0.        ,  0.        ,  0.        ,  0.4472136 ]])</p> <pre><code>U.dot(S).dot(V) # U.\u03a3.V == m4\n</code></pre> Output <p>array([[ 1.,  0.,  0.,  0.,  2.],        [ 0.,  0.,  3.,  0.,  0.],        [ 0.,  0.,  0.,  0.,  0.],        [ 0.,  2.,  0.,  0.,  0.]])</p>"},{"location":"Documentations/Libraries/numpy/#diagonal-and-trace","title":"Diagonal and trace","text":"<pre><code>np.diag(m3)  # the values in the diagonal of m3 (top left to bottom right)\n</code></pre> Output <p>array([ 1,  7, 31])</p> <pre><code>np.trace(m3)  # equivalent to np.diag(m3).sum()\n</code></pre> Output <p>39</p>"},{"location":"Documentations/Libraries/numpy/#solving-a-system-of-linear-scalar-equations","title":"Solving a system of linear scalar equations","text":"<p>The <code>solve</code> function solves a system of linear scalar equations, such as:</p> <ul> <li>2x + 6y = 6</li> <li>5x + 3y = -9</li> </ul> <pre><code>coeffs  = np.array([[2, 6], [5, 3]])\ndepvars = np.array([6, -9])\nsolution = linalg.solve(coeffs, depvars)\nsolution\n</code></pre> Output <p>array([-3.,  2.])</p> <p>Let's check the solution:</p> <pre><code>coeffs.dot(solution), depvars  # yep, it's the same\n</code></pre> Output <p>(array([ 6., -9.]), array([ 6, -9]))</p> <p>Looks good! Another way to check the solution:</p> <pre><code>np.allclose(coeffs.dot(solution), depvars)\n</code></pre> Output <p>True</p>"},{"location":"Documentations/Libraries/numpy/#vectorization","title":"Vectorization","text":"<p>Instead of executing operations on individual array items, one at a time, your code is much more efficient if you try to stick to array operations. This is called vectorization. This way, you can benefit from NumPy's many optimizations.</p> <p>For example, let's say we want to generate a 768x1024 array based on the formula sin(xy/40.5). A bad option would be to do the math in python using nested loops:</p> <pre><code>import math\ndata = np.empty((768, 1024))\nfor y in range(768):\n    for x in range(1024):\n        data[y, x] = math.sin(x*y/40.5)  # BAD! Very inefficient.\n</code></pre> <p>Sure, this works, but it's terribly inefficient since the loops are taking place in pure python. Let's vectorize this algorithm. First, we will use NumPy's <code>meshgrid</code> function which generates coordinate matrices from coordinate vectors.</p> <pre><code>x_coords = np.arange(0, 1024)  # [0, 1, 2, ..., 1023]\ny_coords = np.arange(0, 768)   # [0, 1, 2, ..., 767]\nX, Y = np.meshgrid(x_coords, y_coords)\nX\n</code></pre> Output <p>array([[   0,    1,    2, ..., 1021, 1022, 1023],        [   0,    1,    2, ..., 1021, 1022, 1023],        [   0,    1,    2, ..., 1021, 1022, 1023],        ...,         [   0,    1,    2, ..., 1021, 1022, 1023],        [   0,    1,    2, ..., 1021, 1022, 1023],        [   0,    1,    2, ..., 1021, 1022, 1023]])</p> <pre><code>Y\n</code></pre> Output <p>array([[  0,   0,   0, ...,   0,   0,   0],        [  1,   1,   1, ...,   1,   1,   1],        [  2,   2,   2, ...,   2,   2,   2],        ...,         [765, 765, 765, ..., 765, 765, 765],        [766, 766, 766, ..., 766, 766, 766],        [767, 767, 767, ..., 767, 767, 767]])</p> <p>As you can see, both <code>X</code> and <code>Y</code> are 768x1024 arrays, and all values in <code>X</code> correspond to the horizontal coordinate, while all values in <code>Y</code> correspond to the the vertical coordinate.</p> <p>Now we can simply compute the result using array operations:</p> <pre><code>data = np.sin(X*Y/40.5)\n</code></pre> <p>Now we can plot this data using matplotlib's <code>imshow</code> function</p> <pre><code>import matplotlib.pyplot as plt\nimport matplotlib.cm as cm\nfig = plt.figure(1, figsize=(7, 6))\nplt.imshow(data, cmap=cm.hot, interpolation=\"bicubic\")\nplt.show()\n</code></pre>"},{"location":"Documentations/Libraries/numpy/#saving-and-loading","title":"Saving and loading","text":"<p>NumPy makes it easy to save and load <code>ndarray</code>s in binary or text format.</p>"},{"location":"Documentations/Libraries/numpy/#binary-npy-format","title":"Binary <code>.npy</code> format","text":"<p>Let's create a random array and save it.</p> <pre><code>a = np.random.rand(2,3)\na\n</code></pre> Output <p>array([[ 0.41307972,  0.20933385,  0.32025581],        [ 0.19853514,  0.408001  ,  0.6038287 ]])</p> <pre><code>np.save(\"my_array\", a)\n</code></pre> <p>Done! Since the file name contains no file extension was provided, NumPy automatically added <code>.npy</code>. Let's take a peek at the file content:</p> <pre><code>with open(\"my_array.npy\", \"rb\") as f:\n    content = f.read()\n\ncontent\n</code></pre> Output <p>\"\\x93NUMPY\\x01\\x00F\\x00{'descr': '\\x12\\x7f\\xd4?x&lt;h\\x81\\x99i\\xc9?@\\xa4\\x027\\xb0\\x1c\\xda?&lt;P\\x05\\x8f\\x90R\\xe3?\" <p>To load this file into a NumPy array, simply call <code>load</code>:</p> <pre><code>a_loaded = np.load(\"my_array.npy\")\na_loaded\n</code></pre> Output <p>array([[ 0.41307972,  0.20933385,  0.32025581],        [ 0.19853514,  0.408001  ,  0.6038287 ]])</p>"},{"location":"Documentations/Libraries/numpy/#text-format","title":"Text format","text":"<p>Let's try saving the array in text format:</p> <pre><code>np.savetxt(\"my_array.csv\", a)\n</code></pre> <p>Now let's look at the file content:</p> <pre><code>with open(\"my_array.csv\", \"rt\") as f:\n    print(f.read())\n</code></pre> Output <p>4.130797191668116319e-01 2.093338525574361952e-01 3.202558143634371968e-01 1.985351449843368865e-01 4.080009972772735694e-01 6.038286965726977762e-01</p> <p>This is a CSV file with tabs as delimiters. You can set a different delimiter:</p> <pre><code>np.savetxt(\"my_array.csv\", a, delimiter=\",\")\n</code></pre> <p>To load this file, just use <code>loadtxt</code>:</p> <pre><code>a_loaded = np.loadtxt(\"my_array.csv\", delimiter=\",\")\na_loaded\n</code></pre> Output <p>array([[ 0.41307972,  0.20933385,  0.32025581],        [ 0.19853514,  0.408001  ,  0.6038287 ]])</p>"},{"location":"Documentations/Libraries/numpy/#zipped-npz-format","title":"Zipped <code>.npz</code> format","text":"<p>It is also possible to save multiple arrays in one zipped file:</p> <pre><code>b = np.arange(24, dtype=np.uint8).reshape(2, 3, 4)\nb\n</code></pre> Output <p>array([[[ 0,  1,  2,  3],         [ 4,  5,  6,  7],         [ 8,  9, 10, 11]],</p> <pre><code>   [[12, 13, 14, 15],\n[16, 17, 18, 19],\n[20, 21, 22, 23]]], dtype=uint8)\n</code></pre> <pre><code>np.savez(\"my_arrays\", my_a=a, my_b=b)\n</code></pre> <p>Again, let's take a peek at the file content. Note that the <code>.npz</code> file extension was automatically added.</p> <pre><code>with open(\"my_arrays.npz\", \"rb\") as f:\n    content = f.read()\n\nrepr(content)[:180] + \"[...]\"\n</code></pre> Output <p>u'\"PK\\x03\\x04\\x14\\x00\\x00\\x00\\x00\\x00x\\x94cH\\xb6\\x96\\xe4{h\\x00\\x00\\x00h\\x00\\x00\\x00\\x08\\x00\\x00\\x00my_b.npy\\x93NUMPY\\x01\\x00F\\x00{\\'descr\\': \\'|u1\\', \\'fortran_order\\': False, \\'shape\\': (2,[...]'</p> <p>You then load this file like so:</p> <pre><code>my_arrays = np.load(\"my_arrays.npz\")\nmy_arrays\n</code></pre> Output <p> <p>This is a dict-like object which loads the arrays lazily:</p> <pre><code>my_arrays.keys()\n</code></pre> Output <p>['my_b', 'my_a']</p> <pre><code>my_arrays[\"my_a\"]\n</code></pre> Output <p>array([[ 0.41307972,  0.20933385,  0.32025581],        [ 0.19853514,  0.408001  ,  0.6038287 ]])</p>"},{"location":"Documentations/Libraries/numpy/#what-next","title":"What next?","text":"<p>Now you know all the fundamentals of NumPy, but there are many more options available. The best way to learn more is to experiment with NumPy, and go through the excellent reference documentation to find more functions and features you may be interested in.</p>"},{"location":"Documentations/Libraries/pandas/","title":"Pandas","text":"<p>The <code>pandas</code> library provides high-performance, easy-to-use data structures and data analysis tools. The main data structure is the <code>DataFrame</code>, which you can think of as an in-memory 2D table (like a spreadsheet, with column names and row labels). Many features available in Excel are available programmatically, such as creating pivot tables, computing columns based on other columns, plotting graphs, etc. You can also group rows by column value, or join tables much like in SQL. Pandas is also great at handling time series.</p> <p>Prerequisites:</p> <ul> <li>NumPy \u2013 if you are not familiar with NumPy, we recommend that you go through the NumPy tutorial now.</li> </ul>"},{"location":"Documentations/Libraries/pandas/#setup","title":"Setup","text":"<p>First, let's import <code>pandas</code>. People usually import it as <code>pd</code>:</p> <pre><code>import pandas as pd\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#series-objects","title":"Series objects","text":"<p>The <code>pandas</code> library contains these useful data structures:</p> <ul> <li> <p><code>Series</code> objects, that we will discuss now. A <code>Series</code> object is 1D array, similar to a column in a spreadsheet (with a column name and row labels).</p> </li> <li> <p><code>DataFrame</code> objects. This is a 2D table, similar to a spreadsheet (with column names and row labels).</p> </li> <li> <p><code>Panel</code> objects. You can see a <code>Panel</code> as a dictionary of <code>DataFrame</code>s. These are less used, so we will not discuss them here.</p> </li> </ul>"},{"location":"Documentations/Libraries/pandas/#creating-a-series","title":"Creating a Series","text":"<p>Let's start by creating our first <code>Series</code> object!</p> <pre><code>s = pd.Series([2,-1,3,5])\ns\n</code></pre> Output <pre><code>0    2\n1   -1\n2    3\n3    5\ndtype: int64\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#similar-to-a-1d-ndarray","title":"Similar to a 1D ndarray","text":"<p><code>Series</code> objects behave much like one-dimensional NumPy <code>ndarray</code>s, and you can often pass them as parameters to NumPy functions:</p> <pre><code>import numpy as np\nnp.exp(s)\n</code></pre> Output <pre><code>0      7.389056\n1      0.367879\n2     20.085537\n3    148.413159\ndtype: float64\n</code></pre> <p>Arithmetic operations on <code>Series</code> are also possible, and they apply elementwise, just like for <code>ndarray</code>s:</p> <pre><code>s + [1000,2000,3000,4000]\n</code></pre> Output <pre><code>0    1002\n1    1999\n2    3003\n3    4005\ndtype: int64\n</code></pre> <p>Similar to NumPy, if you add a single number to a <code>Series</code>, that number is added to all items in the <code>Series</code>. This is called * broadcasting*:</p> <pre><code>s + 1000\n</code></pre> Output <pre><code>0    1002\n1     999\n2    1003\n3    1005\ndtype: int64\n</code></pre> <p>The same is true for all binary operations such as <code>*</code> or <code>/</code>, and even conditional operations:</p> <pre><code>s &lt; 0\n</code></pre> Output <pre><code>0    False\n1     True\n2    False\n3    False\ndtype: bool\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#index-labels","title":"Index labels","text":"<p>Each item in a <code>Series</code> object has a unique identifier called the index label. By default, it is simply the rank of the item in the <code>Series</code> (starting at <code>0</code>) but you can also set the index labels manually:</p> <pre><code>s2 = pd.Series([68, 83, 112, 68], index=[\"alice\", \"bob\", \"charles\", \"darwin\"])\ns2\n</code></pre> Output <pre><code>alice       68\nbob         83\ncharles    112\ndarwin      68\ndtype: int64\n</code></pre> <p>You can then use the <code>Series</code> just like a <code>dict</code>:</p> <pre><code>s2[\"bob\"]\n</code></pre> Output <p>83</p> <p>You can still access the items by integer location, like in a regular array:</p> <pre><code>s2[1]\n</code></pre> Output <p>83</p> <p>To make it clear when you are accessing by label or by integer location, it is recommended to always use the <code>loc</code> attribute when accessing by label, and the <code>iloc</code> attribute when accessing by integer location:</p> <pre><code>s2.loc[\"bob\"]\n</code></pre> Output <p>83</p> <pre><code>s2.iloc[1]\n</code></pre> Output <p>83</p> <p>Slicing a <code>Series</code> also slices the index labels:</p> <pre><code>s2.iloc[1:3]\n</code></pre> Output <pre><code>bob         83\ncharles    112\ndtype: int64\n</code></pre> <p>This can lead to unexpected results when using the default numeric labels, so be careful:</p> <pre><code>surprise = pd.Series([1000, 1001, 1002, 1003])\nsurprise\n</code></pre> Output <pre><code>0    1000\n1    1001\n2    1002\n3    1003\ndtype: int64\n</code></pre> <pre><code>surprise_slice = surprise[2:]\nsurprise_slice\n</code></pre> Output <pre><code>2    1002\n3    1003\ndtype: int64\n</code></pre> <p>Oh look! The first element has index label <code>2</code>. The element with index label <code>0</code> is absent from the slice:</p> <pre><code>try:\n    surprise_slice[0]\nexcept KeyError as e:\n    print(\"Key error:\", e)\n</code></pre> Output <p>Key error: 0</p> <p>But remember that you can access elements by integer location using the <code>iloc</code> attribute. This illustrates another reason why it's always better to use <code>loc</code> and <code>iloc</code> to access <code>Series</code> objects:</p> <pre><code>surprise_slice.iloc[0]\n</code></pre> Output <p>1002</p>"},{"location":"Documentations/Libraries/pandas/#init-from-dict","title":"Init from dict","text":"<p>You can create a <code>Series</code> object from a <code>dict</code>. The keys will be used as index labels:</p> <pre><code>weights = {\"alice\": 68, \"bob\": 83, \"colin\": 86, \"darwin\": 68}\ns3 = pd.Series(weights)\ns3\n</code></pre> Output <pre><code>alice     68\nbob       83\ncolin     86\ndarwin    68\ndtype: int64\n</code></pre> <p>You can control which elements you want to include in the <code>Series</code> and in what order by explicitly specifying the desired <code>index</code>:</p> <pre><code>s4 = pd.Series(weights, index = [\"colin\", \"alice\"])\ns4\n</code></pre> Output <pre><code>colin    86\nalice    68\ndtype: int64\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#automatic-alignment","title":"Automatic alignment","text":"<p>When an operation involves multiple <code>Series</code> objects, <code>pandas</code> automatically aligns items by matching index labels.</p> <pre><code>print(s2.keys())\nprint(s3.keys())\n\ns2 + s3\n</code></pre> Output <pre><code>Index(['alice', 'bob', 'charles', 'darwin'], dtype='object')\nIndex(['alice', 'bob', 'colin', 'darwin'], dtype='object')\nalice      136.0\nbob        166.0\ncharles      NaN\ncolin        NaN\ndarwin     136.0\ndtype: float64\n</code></pre> <p>The resulting <code>Series</code> contains the union of index labels from <code>s2</code> and <code>s3</code>. Since <code>\"colin\"</code> is missing from <code>s2</code> and <code>\"charles\"</code> is missing from <code>s3</code>, these items have a <code>NaN</code> result value. (ie. Not-a-Number means missing).</p> <p>Automatic alignment is very handy when working with data that may come from various sources with varying structure and missing items. But if you forget to set the right index labels, you can have surprising results:</p> <pre><code>s5 = pd.Series([1000,1000,1000,1000])\nprint(\"s2 =\", s2.values)\nprint(\"s5 =\", s5.values)\n\ns2 + s5\n</code></pre> Output <pre><code>s2 = [ 68  83 112  68]\ns5 = [1000 1000 1000 1000]\nalice     NaN\nbob       NaN\ncharles   NaN\ndarwin    NaN\n0         NaN\n1         NaN\n2         NaN\n3         NaN\ndtype: float64\n</code></pre> <p>Pandas could not align the <code>Series</code>, since their labels do not match at all, hence the full <code>NaN</code> result.</p>"},{"location":"Documentations/Libraries/pandas/#init-with-a-scalar","title":"Init with a scalar","text":"<p>You can also initialize a <code>Series</code> object using a scalar and a list of index labels: all items will be set to the scalar.</p> <pre><code>meaning = pd.Series(42, [\"life\", \"universe\", \"everything\"])\nmeaning\n</code></pre> Output <pre><code>life          42\nuniverse      42\neverything    42\ndtype: int64\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#series-name","title":"Series name","text":"<p>A <code>Series</code> can have a <code>name</code>:</p> <pre><code>s6 = pd.Series([83, 68], index=[\"bob\", \"alice\"], name=\"weights\")\ns6\n</code></pre> Output <pre><code>bob      83\nalice    68\nName: weights, dtype: int64\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#plotting-a-series","title":"Plotting a Series","text":"<p>Pandas makes it easy to plot <code>Series</code> data using matplotlib (for more details on matplotlib, check out the matplotlib tutorial). Just import matplotlib and call the <code>plot()</code> method:</p> <pre><code>%matplotlib inline\nimport matplotlib.pyplot as plt\ntemperatures = [4.4,5.1,6.1,6.2,6.1,6.1,5.7,5.2,4.7,4.1,3.9,3.5]\ns7 = pd.Series(temperatures, name=\"Temperature\")\ns7.plot()\nplt.show()\n</code></pre> Output <p></p> <p>There are many options for plotting your data. It is not necessary to list them all here: if you need a particular type of plot (histograms, pie charts, etc.), just look for it in the excellent Visualization section of pandas' documentation, and look at the example code.</p>"},{"location":"Documentations/Libraries/pandas/#handling-time","title":"Handling time","text":"<p>Many datasets have timestamps, and pandas is awesome at manipulating such data:</p> <ul> <li> <p>it can represent periods (such as 2016Q3) and frequencies (such as \"monthly\"),</p> </li> <li> <p>it can convert periods to actual timestamps, and vice versa,</p> </li> <li> <p>it can resample data and aggregate values any way you like,</p> </li> <li> <p>it can handle timezones.</p> </li> </ul>"},{"location":"Documentations/Libraries/pandas/#time-range","title":"Time range","text":"<p>Let's start by creating a time series using <code>pd.date_range()</code>. This returns a <code>DatetimeIndex</code> containing one datetime per hour for 12 hours starting on October 29th 2016 at 5:30pm.</p> <pre><code>dates = pd.date_range('2016/10/29 5:30pm', periods=12, freq='H')\ndates\n</code></pre> Output <pre><code>DatetimeIndex(['2016-10-29 17:30:00', '2016-10-29 18:30:00',\n            '2016-10-29 19:30:00', '2016-10-29 20:30:00',\n            '2016-10-29 21:30:00', '2016-10-29 22:30:00',\n            '2016-10-29 23:30:00', '2016-10-30 00:30:00',\n            '2016-10-30 01:30:00', '2016-10-30 02:30:00',\n            '2016-10-30 03:30:00', '2016-10-30 04:30:00'],\n            dtype='datetime64[ns]', freq='H')\n</code></pre> <p>This <code>DatetimeIndex</code> may be used as an index in a <code>Series</code>:</p> <pre><code>temp_series = pd.Series(temperatures, dates)\ntemp_series\n</code></pre> Output <pre><code>2016-10-29 17:30:00    4.4\n2016-10-29 18:30:00    5.1\n2016-10-29 19:30:00    6.1\n2016-10-29 20:30:00    6.2\n2016-10-29 21:30:00    6.1\n2016-10-29 22:30:00    6.1\n2016-10-29 23:30:00    5.7\n2016-10-30 00:30:00    5.2\n2016-10-30 01:30:00    4.7\n2016-10-30 02:30:00    4.1\n2016-10-30 03:30:00    3.9\n2016-10-30 04:30:00    3.5\nFreq: H, dtype: float64\n</code></pre> <p>Let's plot this series:</p> <pre><code>temp_series.plot(kind=\"bar\")\n\nplt.grid(True)\nplt.show()\n</code></pre> Output <p></p>"},{"location":"Documentations/Libraries/pandas/#resampling","title":"Resampling","text":"<p>Pandas lets us resample a time series very simply. Just call the <code>resample()</code> method and specify a new frequency:</p> <pre><code>temp_series_freq_2H = temp_series.resample(\"2H\")\ntemp_series_freq_2H\n</code></pre> Output <pre><code>DatetimeIndexResampler [freq=&lt;2 * Hours&gt;, axis=0, closed=left, label=left, convention=start, base=0]\n</code></pre> <p>The resampling operation is actually a deferred operation, which is why we did not get a <code>Series</code> object, but a <code>DatetimeIndexResampler</code> object instead. To actually perform the resampling operation, we can simply call the <code>mean()</code> method: Pandas will compute the mean of every pair of consecutive hours:</p> <pre><code>temp_series_freq_2H = temp_series_freq_2H.mean()\n</code></pre> <p>Let's plot the result:</p> <pre><code>temp_series_freq_2H.plot(kind=\"bar\")\nplt.show()\n</code></pre> Output <p></p> <p>Note how the values have automatically been aggregated into 2-hour periods. If we look at the 6-8pm period, for example, we had a value of <code>5.1</code> at 6:30pm, and <code>6.1</code> at 7:30pm. After resampling, we just have one value of <code>5.6</code>, which is the mean of <code>5.1</code> and <code>6.1</code>. Rather than computing the mean, we could have used any other aggregation function, for example we can decide to keep the minimum value of each period:</p> <pre><code>temp_series_freq_2H = temp_series.resample(\"2H\").min()\ntemp_series_freq_2H\n</code></pre> Output <pre><code>2016-10-29 16:00:00    4.4\n2016-10-29 18:00:00    5.1\n2016-10-29 20:00:00    6.1\n2016-10-29 22:00:00    5.7\n2016-10-30 00:00:00    4.7\n2016-10-30 02:00:00    3.9\n2016-10-30 04:00:00    3.5\nFreq: 2H, dtype: float64\n</code></pre> <p>Or, equivalently, we could use the <code>apply()</code> method instead:</p> <pre><code>temp_series_freq_2H = temp_series.resample(\"2H\").apply(np.min)\ntemp_series_freq_2H\n</code></pre> Output <pre><code>2016-10-29 16:00:00    4.4\n2016-10-29 18:00:00    5.1\n2016-10-29 20:00:00    6.1\n2016-10-29 22:00:00    5.7\n2016-10-30 00:00:00    4.7\n2016-10-30 02:00:00    3.9\n2016-10-30 04:00:00    3.5\nFreq: 2H, dtype: float64\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#upsampling-and-interpolation","title":"Upsampling and interpolation","text":"<p>This was an example of downsampling. We can also upsample (ie. increase the frequency), but this creates holes in our data:</p> <pre><code>temp_series_freq_15min = temp_series.resample(\"15Min\").mean()\ntemp_series_freq_15min.head(n=10) # `head` displays the top n values\n</code></pre> Output <pre><code>2016-10-29 17:30:00    4.4\n2016-10-29 17:45:00    NaN\n2016-10-29 18:00:00    NaN\n2016-10-29 18:15:00    NaN\n2016-10-29 18:30:00    5.1\n2016-10-29 18:45:00    NaN\n2016-10-29 19:00:00    NaN\n2016-10-29 19:15:00    NaN\n2016-10-29 19:30:00    6.1\n2016-10-29 19:45:00    NaN\nFreq: 15T, dtype: float64\n</code></pre> <p>One solution is to fill the gaps by interpolating. We just call the <code>interpolate()</code> method. The default is to use linear interpolation, but we can also select another method, such as cubic interpolation:</p> <pre><code>temp_series_freq_15min = temp_series.resample(\"15Min\").interpolate(method=\"cubic\")\ntemp_series_freq_15min.head(n=10)\n</code></pre> Output <pre><code>2016-10-29 17:30:00    4.400000\n2016-10-29 17:45:00    4.452911\n2016-10-29 18:00:00    4.605113\n2016-10-29 18:15:00    4.829758\n2016-10-29 18:30:00    5.100000\n2016-10-29 18:45:00    5.388992\n2016-10-29 19:00:00    5.669887\n2016-10-29 19:15:00    5.915839\n2016-10-29 19:30:00    6.100000\n2016-10-29 19:45:00    6.203621\nFreq: 15T, dtype: float64\n</code></pre> <pre><code>temp_series.plot(label=\"Period: 1 hour\")\ntemp_series_freq_15min.plot(label=\"Period: 15 minutes\")\nplt.legend()\nplt.show()\n</code></pre> Output <p></p>"},{"location":"Documentations/Libraries/pandas/#timezones","title":"Timezones","text":"<p>By default datetimes are naive: they are not aware of timezones, so 2016-10-30 02:30 might mean October 30th 2016 at 2:30am in Paris or in New York. We can make datetimes timezone aware by calling the <code>tz_localize()</code> method:</p> <pre><code>temp_series_ny = temp_series.tz_localize(\"America/New_York\")\ntemp_series_ny\n</code></pre> Output <pre><code>2016-10-29 17:30:00-04:00    4.4\n2016-10-29 18:30:00-04:00    5.1\n2016-10-29 19:30:00-04:00    6.1\n2016-10-29 20:30:00-04:00    6.2\n2016-10-29 21:30:00-04:00    6.1\n2016-10-29 22:30:00-04:00    6.1\n2016-10-29 23:30:00-04:00    5.7\n2016-10-30 00:30:00-04:00    5.2\n2016-10-30 01:30:00-04:00    4.7\n2016-10-30 02:30:00-04:00    4.1\n2016-10-30 03:30:00-04:00    3.9\n2016-10-30 04:30:00-04:00    3.5\nFreq: H, dtype: float64\n</code></pre> <p>Note that <code>-04:00</code> is now appended to all the datetimes. This means that these datetimes refer to UTC - 4 hours.</p> <p>We can convert these datetimes to Paris time like this:</p> <pre><code>temp_series_paris = temp_series_ny.tz_convert(\"Europe/Paris\")\ntemp_series_paris\n</code></pre> Output <pre><code>2016-10-29 23:30:00+02:00    4.4\n2016-10-30 00:30:00+02:00    5.1\n2016-10-30 01:30:00+02:00    6.1\n2016-10-30 02:30:00+02:00    6.2\n2016-10-30 02:30:00+01:00    6.1\n2016-10-30 03:30:00+01:00    6.1\n2016-10-30 04:30:00+01:00    5.7\n2016-10-30 05:30:00+01:00    5.2\n2016-10-30 06:30:00+01:00    4.7\n2016-10-30 07:30:00+01:00    4.1\n2016-10-30 08:30:00+01:00    3.9\n2016-10-30 09:30:00+01:00    3.5\nFreq: H, dtype: float64\n</code></pre> <p>You may have noticed that the UTC offset changes from <code>+02:00</code> to <code>+01:00</code>: this is because France switches to winter time at 3am that particular night (time goes back to 2am). Notice that 2:30am occurs twice! Let's go back to a naive representation (if you log some data hourly using local time, without storing the timezone, you might get something like this):</p> <pre><code>temp_series_paris_naive = temp_series_paris.tz_localize(None)\ntemp_series_paris_naive\n</code></pre> Output <pre><code>2016-10-29 23:30:00    4.4\n2016-10-30 00:30:00    5.1\n2016-10-30 01:30:00    6.1\n2016-10-30 02:30:00    6.2\n2016-10-30 02:30:00    6.1\n2016-10-30 03:30:00    6.1\n2016-10-30 04:30:00    5.7\n2016-10-30 05:30:00    5.2\n2016-10-30 06:30:00    4.7\n2016-10-30 07:30:00    4.1\n2016-10-30 08:30:00    3.9\n2016-10-30 09:30:00    3.5\nFreq: H, dtype: float64\n</code></pre> <p>Now <code>02:30</code> is really ambiguous. If we try to localize these naive datetimes to the Paris timezone, we get an error:</p> <pre><code>try:\n    temp_series_paris_naive.tz_localize(\"Europe/Paris\")\nexcept Exception as e:\n    print(type(e))\n    print(e)\n</code></pre> Output <pre><code>&lt;class 'pytz.exceptions.AmbiguousTimeError'&gt;\nCannot infer dst time from Timestamp('2016-10-30 02:30:00'), try using the 'ambiguous' argument\n</code></pre> <p>Fortunately using the <code>ambiguous</code> argument we can tell pandas to infer the right DST (Daylight Saving Time) based on the order of the ambiguous timestamps:</p> <pre><code>temp_series_paris_naive.tz_localize(\"Europe/Paris\", ambiguous=\"infer\")\n</code></pre> Output <pre><code>2016-10-29 23:30:00+02:00    4.4\n2016-10-30 00:30:00+02:00    5.1\n2016-10-30 01:30:00+02:00    6.1\n2016-10-30 02:30:00+02:00    6.2\n2016-10-30 02:30:00+01:00    6.1\n2016-10-30 03:30:00+01:00    6.1\n2016-10-30 04:30:00+01:00    5.7\n2016-10-30 05:30:00+01:00    5.2\n2016-10-30 06:30:00+01:00    4.7\n2016-10-30 07:30:00+01:00    4.1\n2016-10-30 08:30:00+01:00    3.9\n2016-10-30 09:30:00+01:00    3.5\nFreq: H, dtype: float64\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#periods","title":"Periods","text":"<p>The <code>pd.period_range()</code> function returns a <code>PeriodIndex</code> instead of a <code>DatetimeIndex</code>. For example, let's get all quarters in 2016 and 2017:</p> <pre><code>quarters = pd.period_range('2016Q1', periods=8, freq='Q')\nquarters\n</code></pre> Output <pre><code>PeriodIndex(['2016Q1', '2016Q2', '2016Q3', '2016Q4', '2017Q1', '2017Q2',\n            '2017Q3', '2017Q4'],\n            dtype='period[Q-DEC]', freq='Q-DEC')\n</code></pre> <p>Adding a number <code>N</code> to a <code>PeriodIndex</code> shifts the periods by <code>N</code> times the <code>PeriodIndex</code>'s frequency:</p> <pre><code>quarters + 3\n</code></pre> Output <pre><code>PeriodIndex(['2016Q4', '2017Q1', '2017Q2', '2017Q3', '2017Q4', '2018Q1',\n            '2018Q2', '2018Q3'],\n            dtype='period[Q-DEC]', freq='Q-DEC')\n</code></pre> <p>The <code>asfreq()</code> method lets us change the frequency of the <code>PeriodIndex</code>. All periods are lengthened or shortened accordingly. For example, let's convert all the quarterly periods to monthly periods (zooming in):</p> <pre><code>quarters.asfreq(\"M\")\n</code></pre> Output <pre><code>PeriodIndex(['2016-03', '2016-06', '2016-09', '2016-12', '2017-03', '2017-06',\n            '2017-09', '2017-12'],\n            dtype='period[M]', freq='M')\n</code></pre> <p>By default, the <code>asfreq</code> zooms on the end of each period. We can tell it to zoom on the start of each period instead:</p> <pre><code>quarters.asfreq(\"M\", how=\"start\")\n</code></pre> Output <pre><code>PeriodIndex(['2016-01', '2016-04', '2016-07', '2016-10', '2017-01', '2017-04',\n            '2017-07', '2017-10'],\n            dtype='period[M]', freq='M')\n</code></pre> <p>And we can zoom out:</p> <pre><code>quarters.asfreq(\"A\")\n</code></pre> Output <pre><code>PeriodIndex(['2016', '2016', '2016', '2016', '2017', '2017', '2017', '2017'], dtype='period[A-DEC]', freq='A-DEC')\n</code></pre> <p>Of course we can create a <code>Series</code> with a <code>PeriodIndex</code>:</p> <pre><code>quarterly_revenue = pd.Series([300, 320, 290, 390, 320, 360, 310, 410], index = quarters)\nquarterly_revenue\n</code></pre> Output <pre><code>2016Q1    300\n2016Q2    320\n2016Q3    290\n2016Q4    390\n2017Q1    320\n2017Q2    360\n2017Q3    310\n2017Q4    410\nFreq: Q-DEC, dtype: int64\n</code></pre> <pre><code>quarterly_revenue.plot(kind=\"line\")\nplt.show()\n</code></pre> Output <p></p> <p>We can convert periods to timestamps by calling <code>to_timestamp</code>. By default this will give us the first day of each period, but by setting <code>how</code> and <code>freq</code>, we can get the last hour of each period:</p> <pre><code>last_hours = quarterly_revenue.to_timestamp(how=\"end\", freq=\"H\")\nlast_hours\n</code></pre> Output <pre><code>2016-03-31 23:00:00    300\n2016-06-30 23:00:00    320\n2016-09-30 23:00:00    290\n2016-12-31 23:00:00    390\n2017-03-31 23:00:00    320\n2017-06-30 23:00:00    360\n2017-09-30 23:00:00    310\n2017-12-31 23:00:00    410\nFreq: Q-DEC, dtype: int64\n</code></pre> <p>And back to periods by calling <code>to_period</code>:</p> <pre><code>last_hours.to_period()\n</code></pre> Output <pre><code>2016Q1    300\n2016Q2    320\n2016Q3    290\n2016Q4    390\n2017Q1    320\n2017Q2    360\n2017Q3    310\n2017Q4    410\nFreq: Q-DEC, dtype: int64\n</code></pre> <p>Pandas also provides many other time-related functions that we recommend you check out in the documentation. To whet your appetite, here is one way to get the last business day of each month in 2016, at 9am:</p> <pre><code>months_2016 = pd.period_range(\"2016\", periods=12, freq=\"M\")\none_day_after_last_days = months_2016.asfreq(\"D\") + 1\nlast_bdays = one_day_after_last_days.to_timestamp() - pd.tseries.offsets.BDay()\nlast_bdays.to_period(\"H\") + 9\n</code></pre> Output <pre><code>PeriodIndex(['2016-01-29 09:00', '2016-02-29 09:00', '2016-03-31 09:00',\n            '2016-04-29 09:00', '2016-05-31 09:00', '2016-06-30 09:00',\n            '2016-07-29 09:00', '2016-08-31 09:00', '2016-09-30 09:00',\n            '2016-10-31 09:00', '2016-11-30 09:00', '2016-12-30 09:00'],\n            dtype='period[H]', freq='H')\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#dataframe-objects","title":"DataFrame objects","text":"<p>A DataFrame object represents a spreadsheet, with cell values, column names and row index labels. You can define expressions to compute columns based on other columns, create pivot-tables, group rows, draw graphs, etc. You can see <code>DataFrame</code>s as dictionaries of <code>Series</code>.</p>"},{"location":"Documentations/Libraries/pandas/#creating-a-dataframe","title":"Creating a DataFrame","text":"<p>You can create a DataFrame by passing a dictionary of <code>Series</code> objects:</p> <pre><code>people_dict = {\n    \"weight\": pd.Series([68, 83, 112], index=[\"alice\", \"bob\", \"charles\"]),\n    \"birthyear\": pd.Series([1984, 1985, 1992], index=[\"bob\", \"alice\", \"charles\"], name=\"year\"),\n    \"children\": pd.Series([0, 3], index=[\"charles\", \"bob\"]),\n    \"hobby\": pd.Series([\"Biking\", \"Dancing\"], index=[\"alice\", \"bob\"]),\n}\npeople = pd.DataFrame(people_dict)\npeople\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 bob 1984 3.0 Dancing 83 charles 1992 0.0 NaN 112 <p>A few things to note:</p> <ul> <li> <p>the <code>Series</code> were automatically aligned based on their index,</p> </li> <li> <p>missing values are represented as <code>NaN</code>,</p> </li> <li> <p><code>Series</code> names are ignored (the name <code>\"year\"</code> was dropped),</p> </li> <li> <p><code>DataFrame</code>s are displayed nicely in Jupyter notebooks, woohoo!</p> </li> </ul> <p>You can access columns pretty much as you would expect. They are returned as <code>Series</code> objects:</p> <pre><code>people[\"birthyear\"]\n</code></pre> Output <pre><code>alice      1985\nbob        1984\ncharles    1992\nName: birthyear, dtype: int64\n</code></pre> <p>You can also get multiple columns at once:</p> <pre><code>people[[\"birthyear\", \"hobby\"]]\n</code></pre> Output birthyear hobby alice 1985 Biking bob 1984 Dancing charles 1992 NaN <p>If you pass a list of columns and/or index row labels to the <code>DataFrame</code> constructor, it will guarantee that these columns and/or rows will exist, in that order, and no other column/row will exist. For example:</p> <pre><code>d2 = pd.DataFrame(\n        people_dict,\n        columns=[\"birthyear\", \"weight\", \"height\"],\n        index=[\"bob\", \"alice\", \"eugene\"]\n     )\nd2\n</code></pre> Output birthyear weight weight bob 1984.0 83.0 NaN alice 1985.0 68.0 NaN eugene NaN NaN NaN <p>Another convenient way to create a <code>DataFrame</code> is to pass all the values to the constructor as an <code>ndarray</code>, or a list of lists, and specify the column names and row index labels separately:</p> <pre><code>values = [\n            [1985, np.nan, \"Biking\",   68],\n            [1984, 3,      \"Dancing\",  83],\n            [1992, 0,      np.nan,    112]\n         ]\nd3 = pd.DataFrame(\n        values,\n        columns=[\"birthyear\", \"children\", \"hobby\", \"weight\"],\n        index=[\"alice\", \"bob\", \"charles\"]\n     )\nd3\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 bob 1984 3.0 Dancing 83 charles 1992 0.0 NaN 112 <p>To specify missing values, you can either use <code>np.nan</code> or NumPy's masked arrays:</p> <pre><code>masked_array = np.ma.asarray(values, dtype=np.object)\nmasked_array[(0, 2), (1, 2)] = np.ma.masked\nd3 = pd.DataFrame(\n        masked_array,\n        columns=[\"birthyear\", \"children\", \"hobby\", \"weight\"],\n        index=[\"alice\", \"bob\", \"charles\"]\n     )\nd3\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 bob 1984 3 Dancing 83 charles 1992 0 NaN 112 <p>Instead of an <code>ndarray</code>, you can also pass a <code>DataFrame</code> object:</p> <pre><code>d4 = pd.DataFrame(\n         d3,\n         columns=[\"hobby\", \"children\"],\n         index=[\"alice\", \"bob\"]\n     )\nd4\n</code></pre> Output hobby children alice Biking NaN bob Dancing 3 <p>It is also possible to create a <code>DataFrame</code> with a dictionary (or list) of dictionaries (or list):</p> <pre><code>people = pd.DataFrame({\n    \"birthyear\": {\"alice\":1985, \"bob\": 1984, \"charles\": 1992},\n    \"hobby\": {\"alice\":\"Biking\", \"bob\": \"Dancing\"},\n    \"weight\": {\"alice\":68, \"bob\": 83, \"charles\": 112},\n    \"children\": {\"bob\": 3, \"charles\": 0}\n})\npeople\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 bob 1984 3.0 Dancing 83 charles 1992 0.0 NaN 112"},{"location":"Documentations/Libraries/pandas/#multi-indexing","title":"Multi-indexing","text":"<p>If all columns are tuples of the same size, then they are understood as a multi-index. The same goes for row index labels. For example:</p> <pre><code>d5 = pd.DataFrame(\n  {\n    (\"public\", \"birthyear\"):\n        {(\"Paris\",\"alice\"):1985, (\"Paris\",\"bob\"): 1984, (\"London\",\"charles\"): 1992},\n    (\"public\", \"hobby\"):\n        {(\"Paris\",\"alice\"):\"Biking\", (\"Paris\",\"bob\"): \"Dancing\"},\n    (\"private\", \"weight\"):\n        {(\"Paris\",\"alice\"):68, (\"Paris\",\"bob\"): 83, (\"London\",\"charles\"): 112},\n    (\"private\", \"children\"):\n        {(\"Paris\", \"alice\"):np.nan, (\"Paris\",\"bob\"): 3, (\"London\",\"charles\"): 0}\n  }\n)\nd5\n</code></pre> <p>You can now get a <code>DataFrame</code> containing all the <code>\"public\"</code> columns very simply:</p> <pre><code>d5[\"public\"]\n</code></pre> <pre><code>d5[\"public\", \"hobby\"]  # Same result as d5[\"public\"][\"hobby\"]\n</code></pre> Output <pre><code>London  charles        NaN\nParis   alice       Biking\n        bob        Dancing\nName: (public, hobby), dtype: object\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#dropping-a-level","title":"Dropping a level","text":"<p>Let's look at <code>d5</code> again:</p> <pre><code>d5\n</code></pre> <p>There are two levels of columns, and two levels of indices. We can drop a column level by calling <code>droplevel()</code> (the same goes for indices):</p> <pre><code>d5.columns = d5.columns.droplevel(level = 0)\nd5\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#transposing","title":"Transposing","text":"<p>You can swap columns and indices using the <code>T</code> attribute:</p> <pre><code>d6 = d5.T\nd6\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#stacking-and-unstacking-levels","title":"Stacking and unstacking levels","text":"<p>Calling the <code>stack()</code> method will push the lowest column level after the lowest index:</p> <pre><code>d7 = d6.stack()\nd7\n</code></pre> <p>Note that many <code>NaN</code> values appeared. This makes sense because many new combinations did not exist before (eg. there was no <code>bob</code> in <code>London</code>).</p> <p>Calling <code>unstack()</code> will do the reverse, once again creating many <code>NaN</code> values.</p> <pre><code>d8 = d7.unstack()\nd8\n</code></pre> <p>If we call <code>unstack</code> again, we end up with a <code>Series</code> object:</p> <pre><code>d9 = d8.unstack()\nd9\n</code></pre> Output <pre><code>London  alice    children        None\n                weight           NaN\n                birthyear        NaN\n                hobby            NaN\n        bob      children         NaN\n                weight           NaN\n                birthyear        NaN\n                hobby            NaN\n        charles  children           0\n                weight           112\n                birthyear       1992\n                hobby           None\nParis   alice    children        None\n                weight            68\n                birthyear       1985\n                hobby         Biking\n        bob      children           3\n                weight            83\n                birthyear       1984\n                hobby        Dancing\n        charles  children         NaN\n                weight           NaN\n                birthyear        NaN\n                hobby           None\ndtype: object\n</code></pre> <p>The <code>stack()</code> and <code>unstack()</code> methods let you select the <code>level</code> to stack/unstack. You can even stack/unstack multiple levels at once:</p> <pre><code>d10 = d9.unstack(level = (0,1))\nd10\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#most-methods-return-modified-copies","title":"Most methods return modified copies","text":"<p>As you may have noticed, the <code>stack()</code> and <code>unstack()</code> methods do not modify the object they apply to. Instead, they work on a copy and return that copy. This is true of most methods in pandas.</p>"},{"location":"Documentations/Libraries/pandas/#accessing-rows","title":"Accessing rows","text":"<p>Let's go back to the <code>people</code> <code>DataFrame</code>:</p> <pre><code>people\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 bob 1984 3.0 Dancing 83 charles 1992 0.0 NaN 112 <p>The <code>loc</code> attribute lets you access rows instead of columns. The result is a <code>Series</code> object in which the <code>DataFrame</code>'s column names are mapped to row index labels:</p> <pre><code>people.loc[\"charles\"]\n</code></pre> Output <pre><code>birthyear    1992\nchildren        0\nhobby         NaN\nweight        112\nName: charles, dtype: object\n</code></pre> <p>You can also access rows by integer location using the <code>iloc</code> attribute:</p> <pre><code>people.iloc[2]\n</code></pre> Output <pre><code>birthyear    1992\nchildren        0\nhobby         NaN\nweight        112\nName: charles, dtype: object\n</code></pre> <p>You can also get a slice of rows, and this returns a <code>DataFrame</code> object:</p> <pre><code>people.iloc[1:3]\n</code></pre> Output birthyear children hobby weight bob 1984 3.0 Dancing 83 charles 1992 0.0 NaN 112 <p>Finally, you can pass a boolean array to get the matching rows:</p> <pre><code>people[np.array([True, False, True])]\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 charles 1992 0.0 NaN 112 <p>This is most useful when combined with boolean expressions:</p> <pre><code>people[people[\"birthyear\"] &lt; 1990]\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 bob 1984 3.0 Dancing 83"},{"location":"Documentations/Libraries/pandas/#adding-and-removing-columns","title":"Adding and removing columns","text":"<p>You can generally treat <code>DataFrame</code> objects like dictionaries of <code>Series</code>, so the following work fine:</p> <pre><code>people\n</code></pre> Output birthyear children hobby weight alice 1985 NaN Biking 68 bob 1984 3.0 Dancing 83 charles 1992 0.0 NaN 112 <pre><code>people[\"age\"] = 2018 - people[\"birthyear\"]  # adds a new column \"age\"\npeople[\"over 30\"] = people[\"age\"] &gt; 30      # adds another column \"over 30\"\nbirthyears = people.pop(\"birthyear\")\ndel people[\"children\"]\n\npeople\n</code></pre> Output hobby weight age over 30 alice Biking 68 33 True bob Dancing 83 34 True charles NaN 112 26 False <pre><code>birthyears\n</code></pre> Output <pre><code>alice      1985\nbob        1984\ncharles    1992\nName: birthyear, dtype: int64\n</code></pre> <p>When you add a new colum, it must have the same number of rows. Missing rows are filled with NaN, and extra rows are ignored:</p> <pre><code>people[\"pets\"] = pd.Series({\"bob\": 0, \"charles\": 5, \"eugene\":1})  # alice is missing, eugene is ignored\npeople\n</code></pre> Output hobby weight age over 30 pets alice Biking 68 33 True NaN bob Dancing 83 34 True 0.0 charles NaN 112 26 False 5.0 <p>When adding a new column, it is added at the end (on the right) by default. You can also insert a column anywhere else using the <code>insert()</code> method:</p> <pre><code>people.insert(1, \"height\", [172, 181, 185])\npeople\n</code></pre> Output hobby height weight age over 30 pets alice Biking 172 68 33 True NaN bob Dancing 181 83 34 True 0.0 charles NaN 185 112 26 False 5.0"},{"location":"Documentations/Libraries/pandas/#assigning-new-columns","title":"Assigning new columns","text":"<p>You can also create new columns by calling the <code>assign()</code> method. Note that this returns a new <code>DataFrame</code> object, the original is not modified:</p> <p><pre><code>people.assign(\n    body_mass_index = people[\"weight\"] / (people[\"height\"] / 100) ** 2,\n    has_pets = people[\"pets\"] &gt; 0\n)\n</code></pre> Note that you cannot access columns created within the same assignment:</p> <pre><code>try:\n    people.assign(\n        body_mass_index = people[\"weight\"] / (people[\"height\"] / 100) ** 2,\n        overweight = people[\"body_mass_index\"] &gt; 25\n    )\nexcept KeyError as e:\n    print(\"Key error:\", e)\n</code></pre> Output <p>Key error: 'body_mass_index'</p> <p>The solution is to split this assignment in two consecutive assignments:</p> <pre><code>d6 = people.assign(body_mass_index = people[\"weight\"] / (people[\"height\"] / 100) ** 2)\nd6.assign(overweight = d6[\"body_mass_index\"] &gt; 25)\n</code></pre> <p>Having to create a temporary variable <code>d6</code> is not very convenient. You may want to just chain the assigment calls, but it does not work because the <code>people</code> object is not actually modified by the first assignment:</p> <pre><code>try:\n    (people\n         .assign(body_mass_index = people[\"weight\"] / (people[\"height\"] / 100) ** 2)\n         .assign(overweight = people[\"body_mass_index\"] &gt; 25)\n    )\nexcept KeyError as e:\n    print(\"Key error:\", e)\n</code></pre> Output <p>Key error: 'body_mass_index'</p> <p>But fear not, there is a simple solution. You can pass a function to the <code>assign()</code> method (typically a <code>lambda</code> function), and this function will be called with the <code>DataFrame</code> as a parameter:</p> <pre><code>(people\n     .assign(body_mass_index = lambda df: df[\"weight\"] / (df[\"height\"] / 100) ** 2)\n     .assign(overweight = lambda df: df[\"body_mass_index\"] &gt; 25)\n)\n</code></pre> <p>Problem solved!</p>"},{"location":"Documentations/Libraries/pandas/#evaluating-an-expression","title":"Evaluating an expression","text":"<p>A great feature supported by pandas is expression evaluation. This relies on the <code>numexpr</code> library which must be installed.</p> <pre><code>people.eval(\"weight / (height/100) ** 2 &gt; 25\")\n</code></pre> Output <pre><code>alice      False\nbob         True\ncharles     True\ndtype: bool\n</code></pre> <p>Assignment expressions are also supported. Let's set <code>inplace=True</code> to directly modify the <code>DataFrame</code> rather than getting a modified copy:</p> <pre><code>people.eval(\"body_mass_index = weight / (height/100) ** 2\", inplace=True)\npeople\n</code></pre> <p>You can use a local or global variable in an expression by prefixing it with <code>'@'</code>:</p> <pre><code>overweight_threshold = 30\npeople.eval(\"overweight = body_mass_index &gt; @overweight_threshold\", inplace=True)\npeople\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#querying-a-dataframe","title":"Querying a DataFrame","text":"<p>The <code>query()</code> method lets you filter a <code>DataFrame</code> based on a query expression:</p> <pre><code>people.query(\"age &gt; 30 and pets == 0\")\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#sorting-a-dataframe","title":"Sorting a DataFrame","text":"<p>You can sort a <code>DataFrame</code> by calling its <code>sort_index</code> method. By default it sorts the rows by their index label, in ascending order, but let's reverse the order:</p> <pre><code>people.sort_index(ascending=False)\n</code></pre> <p>Note that <code>sort_index</code> returned a sorted copy of the <code>DataFrame</code>. To modify <code>people</code> directly, we can set the <code>inplace</code> argument to <code>True</code>. Also, we can sort the columns instead of the rows by setting <code>axis=1</code>:</p> <pre><code>people.sort_index(axis=1, inplace=True)\npeople\n</code></pre> <p>To sort the <code>DataFrame</code> by the values instead of the labels, we can use <code>sort_values</code> and specify the column to sort by:</p> <pre><code>people.sort_values(by=\"age\", inplace=True)\npeople\n</code></pre>"},{"location":"Documentations/Libraries/pandas/#plotting-a-dataframe","title":"Plotting a DataFrame","text":"<p>Just like for <code>Series</code>, pandas makes it easy to draw nice graphs based on a <code>DataFrame</code>.</p> <p>For example, it is trivial to create a line plot from a <code>DataFrame</code>'s data by calling its <code>plot</code> method:</p> <pre><code>people.plot(kind = \"line\", x = \"body_mass_index\", y = [\"height\", \"weight\"])\nplt.show()\n</code></pre> Output <p></p> <p>You can pass extra arguments supported by matplotlib's functions. For example, we can create scatterplot and pass it a list of sizes using the <code>s</code> argument of matplotlib's <code>scatter()</code> function:</p> <pre><code>people.plot(kind = \"scatter\", x = \"height\", y = \"weight\", s=[40, 120, 200])\nplt.show()\n</code></pre> Output <p></p> <p>Again, there are way too many options to list here: the best option is to scroll through the Visualization page in pandas' documentation, find the plot you are interested in and look at the example code.</p>"},{"location":"Documentations/Machine%20Learning%20Algorithms/","title":"Algorithmes de machine learning","text":""},{"location":"Documentations/Machine%20Learning%20Algorithms/#les-algorithmes-les-plus-utilises-en-machine-learning","title":"Les algorithmes les plus utilis\u00e9s en machine learning","text":"<p>Les algorithmes les plus utilis\u00e9s en machine learning sont les suivants:</p> <p>R\u00e9gression lin\u00e9aire</p> <p>C'est un algorithme simple qui est utilis\u00e9 pour pr\u00e9dire la valeur d'une variable continue en utilisant une ou plusieurs variables explicatives.</p> <p>R\u00e9gression logistique</p> <p>C'est un algorithme de classification utilis\u00e9 pour pr\u00e9dire une variable de sortie binaire.</p> <p>For\u00eat al\u00e9atoire (Random Forest)</p> <p>C'est un algorithme de classification et de r\u00e9gression bas\u00e9 sur l'apprentissage ensembliste qui utilise plusieurs arbres de d\u00e9cision pour pr\u00e9dire la sortie.</p> <p>K-Nearest Neighbors (K-NN)</p> <p>C'est un algorithme de classification et de r\u00e9gression bas\u00e9 sur l'apprentissage par instance qui pr\u00e9dit la sortie en utilisant les donn\u00e9es les plus proches de l'exemple \u00e0 pr\u00e9dire.</p> <p>Naive Bayes</p> <p>C'est un algorithme de classification probabiliste qui pr\u00e9dit la classe d'une instance en utilisant les probabilit\u00e9s conditionnelles de chaque classe donn\u00e9e les caract\u00e9ristiques de l'instance.</p> <p>Arbre de d\u00e9cision</p> <p>C'est un algorithme de classification et de r\u00e9gression qui cr\u00e9e un arbre de d\u00e9cision pour repr\u00e9senter les relations entre les variables d'entr\u00e9e et les sorties.</p> <p>Support Vector Machine (SVM)</p> <p>C'est un algorithme de classification qui d\u00e9finit une fronti\u00e8re de d\u00e9cision en utilisant les donn\u00e9es d'entra\u00eenement les plus repr\u00e9sentatives pour s\u00e9parer les diff\u00e9rentes classes.</p> <p>R\u00e9seau de neurones artificiels (RNA)</p> <p>C'est un algorithme de deep learning qui mod\u00e9lise les connexions entre les neurones pour effectuer des t\u00e2ches complexes telles que la reconnaissance d'images ou la g\u00e9n\u00e9ration de langage.</p> Note <p>Il est important de noter que le choix de l'algorithme d\u00e9pend des donn\u00e9es d'entr\u00e9e, de la t\u00e2che de machine learning et de l'objectif de l'analyse. Il est donc souvent n\u00e9cessaire d'essayer plusieurs algorithmes pour trouver le meilleur pour chaque cas d'utilisation.</p>"},{"location":"Documentations/Machine%20Learning%20Algorithms/#implementation-simple-de-la-regression-lineaire","title":"Impl\u00e9mentation simple de la r\u00e9gression lin\u00e9aire","text":"<p>Voici une impl\u00e9mentation simple de la r\u00e9gression lin\u00e9aire en utilisant Python avec le module scikit-learn:</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LinearRegression\n\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data[['Variable_1', 'Variable_2', 'Variable_3']]\ny = data['Variable_cible']\n\n# cr\u00e9ation d'un mod\u00e8le de r\u00e9gression lin\u00e9aire\nreg = LinearRegression().fit(X, y)\n\n# coefficients de r\u00e9gression\nprint(\"Coefficients de r\u00e9gression:\", reg.coef_)\n\n# intercept de la r\u00e9gression\nprint(\"Intercept de la r\u00e9gression:\", reg.intercept_)\n\n# pr\u00e9diction sur les donn\u00e9es d'entra\u00eenement\ny_pred = reg.predict(X)\n\n# calcul de la performance du mod\u00e8le\nr2_score = reg.score(X, y)\nprint(\"Score R^2:\", r2_score)\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es. Le mod\u00e8le de r\u00e9gression lin\u00e9aire est cr\u00e9\u00e9 en utilisant la fonction <code>LinearRegression</code> du module scikit-learn. Ensuite, nous utilisons le mod\u00e8le pour pr\u00e9dire la variable cible en utilisant les variables explicatives, en stockant les pr\u00e9dictions dans la variable <code>y_pred</code>. Enfin, nous calculons le score R^2 pour \u00e9valuer la performance du mod\u00e8le.</p>"},{"location":"Documentations/Machine%20Learning%20Algorithms/#implementation-simple-de-la-regression-logistique","title":"Impl\u00e9mentation simple de la r\u00e9gression logistique","text":"<p>Voici une impl\u00e9mentation simple de la r\u00e9gression logistique en utilisant Python avec le module scikit-learn:</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import LogisticRegression\n\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data[['Variable_1', 'Variable_2', 'Variable_3']]\ny = data['Variable_cible']\n\n# cr\u00e9ation d'un mod\u00e8le de r\u00e9gression logistique\nlogreg = LogisticRegression().fit(X, y)\n\n# coefficients de r\u00e9gression\nprint(\"Coefficients de r\u00e9gression:\", logreg.coef_)\n\n# intercept de la r\u00e9gression\nprint(\"Intercept de la r\u00e9gression:\", logreg.intercept_)\n\n# pr\u00e9diction sur les donn\u00e9es d'entra\u00eenement\ny_pred = logreg.predict(X)\n\n# calcul de la performance du mod\u00e8le\naccuracy = logreg.score(X, y)\nprint(\"Pr\u00e9cision:\", accuracy)\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es. Le mod\u00e8le de r\u00e9gression logistique est cr\u00e9\u00e9 en utilisant la fonction <code>LogisticRegression</code> du module scikit-learn. Ensuite, nous utilisons le mod\u00e8le pour pr\u00e9dire la variable cible en utilisant les variables explicatives, en stockant les pr\u00e9dictions dans la variable <code>y_pred</code>. Enfin, nous calculons la pr\u00e9cision du mod\u00e8le pour \u00e9valuer la performance. Notez que la r\u00e9gression logistique est un algorithme de classification binaire, donc la variable cible doit \u00eatre binaire.</p>"},{"location":"Documentations/Machine%20Learning%20Algorithms/#implementation-simple-de-foret-aleatoire-random-forest","title":"Impl\u00e9mentation simple de For\u00eat al\u00e9atoire (Random Forest)","text":"<p>Voici une impl\u00e9mentation simple de l'algorithme Random Forest en utilisant Python avec le module scikit-learn:</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\n\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data.drop('Variable_cible', axis=1)\ny = data['Variable_cible']\n\n# cr\u00e9ation d'un mod\u00e8le de Random Forest\nclf = RandomForestClassifier(n_estimators=100)\nclf.fit(X, y)\n\n# pr\u00e9diction sur les donn\u00e9es d'entra\u00eenement\ny_pred = clf.predict(X)\n\n# calcul de la performance du mod\u00e8le\naccuracy = clf.score(X, y)\nprint(\"Pr\u00e9cision:\", accuracy)\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es. Le mod\u00e8le de Random Forest est cr\u00e9\u00e9 en utilisant la fonction <code>RandomForestClassifier</code> du module scikit-learn. Ensuite, nous utilisons le mod\u00e8le pour pr\u00e9dire la variable cible en utilisant les variables explicatives, en stockant les pr\u00e9dictions dans la variable <code>y_pred</code>. Enfin, nous calculons la pr\u00e9cision du mod\u00e8le pour \u00e9valuer la performance. Notez que ce code impl\u00e9mente un mod\u00e8le de Random Forest pour une classification binaire, mais vous pouvez \u00e9galement utiliser l'algorithme pour des t\u00e2ches de r\u00e9gression en utilisant la fonction <code>RandomForestRegressor</code> au lieu de <code>RandomForestClassifier</code>.</p>"},{"location":"Documentations/Machine%20Learning%20Algorithms/#implementation-simple-de-k-nearest-neighbors-k-nn","title":"Impl\u00e9mentation simple de K-Nearest Neighbors (K-NN)","text":"<p>Voici une impl\u00e9mentation simple de l'algorithme K-Nearest Neighbors (K-NN) en utilisant Python avec le module scikit-learn:</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data.drop('Variable_cible', axis=1)\ny = data['Variable_cible']\n\n# cr\u00e9ation d'un mod\u00e8le K-NN\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(X, y)\n\n# pr\u00e9diction sur les donn\u00e9es d'entra\u00eenement\ny_pred = knn.predict(X)\n\n# calcul de la performance du mod\u00e8le\naccuracy = knn.score(X, y)\nprint(\"Pr\u00e9cision:\", accuracy)\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es. Le mod\u00e8le K-NN est cr\u00e9\u00e9 en utilisant la fonction <code>KNeighborsClassifier</code> du module scikit-learn. Ensuite, nous utilisons le mod\u00e8le pour pr\u00e9dire la variable cible en utilisant les variables explicatives, en stockant les pr\u00e9dictions dans la variable y_pred. Enfin, nous calculons la pr\u00e9cision du mod\u00e8le pour \u00e9valuer la performance. Notez que ce code impl\u00e9mente un mod\u00e8le K-NN pour une classification binaire, mais vous pouvez \u00e9galement utiliser l'algorithme pour des t\u00e2ches de r\u00e9gression en utilisant la fonction <code>KNeighborsRegressor</code> au lieu de <code>KNeighborsClassifier</code>.</p>"},{"location":"Documentations/Machine%20Learning%20Algorithms/#implementation-simple-de-naive-bayes","title":"Impl\u00e9mentation simple de Naive Bayes","text":"<p>Voici une impl\u00e9mentation simple de l'algorithme Naive Bayes en utilisant Python avec le module scikit-learn:</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom sklearn.naive_bayes import GaussianNB\n\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data.drop('Variable_cible', axis=1)\ny = data['Variable_cible']\n\n# cr\u00e9ation d'un mod\u00e8le Naive Bayes\ngnb = GaussianNB()\ngnb.fit(X, y)\n\n# pr\u00e9diction sur les donn\u00e9es d'entra\u00eenement\ny_pred = gnb.predict(X)\n\n# calcul de la performance du mod\u00e8le\naccuracy = gnb.score(X, y)\nprint(\"Pr\u00e9cision:\", accuracy)\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es. Le mod\u00e8le Naive Bayes est cr\u00e9\u00e9 en utilisant la fonction <code>GaussianNB</code> du module scikit-learn. Ensuite, nous utilisons le mod\u00e8le pour pr\u00e9dire la variable cible en utilisant les variables explicatives, en stockant les pr\u00e9dictions dans la variable <code>y_pred</code>. Enfin, nous calculons la pr\u00e9cision du mod\u00e8le pour \u00e9valuer la performance. Notez que ce code impl\u00e9mente un mod\u00e8le Naive Bayes pour une classification binaire, mais vous pouvez \u00e9galement utiliser l'algorithme pour des t\u00e2ches de r\u00e9gression en utilisant la fonction <code>MultinomialNB</code> ou <code>BernoulliNB</code> selon le type de donn\u00e9es.</p>"},{"location":"Documentations/Machine%20Learning%20Algorithms/#implementation-simple-darbre-de-decision","title":"Impl\u00e9mentation simple d'Arbre de d\u00e9cision","text":"<p>Voici une impl\u00e9mentation simple de l'algorithme d'Arbre de d\u00e9cision en utilisant Python avec le module scikit-learn:</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom sklearn.tree import DecisionTreeClassifier\n\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data.drop('Variable_cible', axis=1)\ny = data['Variable_cible']\n\n# cr\u00e9ation d'un mod\u00e8le d'Arbre de d\u00e9cision\ndt = DecisionTreeClassifier()\ndt.fit(X, y)\n\n# pr\u00e9diction sur les donn\u00e9es d'entra\u00eenement\ny_pred = dt.predict(X)\n\n# calcul de la performance du mod\u00e8le\naccuracy = dt.score(X, y)\nprint(\"Pr\u00e9cision:\", accuracy)\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es. Le mod\u00e8le d'Arbre de d\u00e9cision est cr\u00e9\u00e9 en utilisant la fonction <code>DecisionTreeClassifier</code> du module scikit-learn. Ensuite, nous utilisons le mod\u00e8le pour pr\u00e9dire la variable cible en utilisant les variables explicatives, en stockant les pr\u00e9dictions dans la variable <code>y_pred</code>. Enfin, nous calculons la pr\u00e9cision du mod\u00e8le pour \u00e9valuer la performance. Notez que ce code impl\u00e9mente un mod\u00e8le d'Arbre de d\u00e9cision pour une classification binaire, mais vous pouvez \u00e9galement utiliser l'algorithme pour des t\u00e2ches de r\u00e9gression en utilisant la fonction <code>DecisionTreeRegressor</code>.</p>"},{"location":"Documentations/Machine%20Learning%20Algorithms/#implementation-simple-de-support-vector-machine-svm","title":"Impl\u00e9mentation simple de Support Vector Machine (SVM)","text":"<p>Voici une impl\u00e9mentation simple de l'algorithme Support Vector Machine (SVM) en utilisant Python avec le module scikit-learn:</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom sklearn import svm\n\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data.drop('Variable_cible', axis=1)\ny = data['Variable_cible']\n\n# cr\u00e9ation d'un mod\u00e8le SVM\nclf = svm.SVC(kernel='linear', C=1)\nclf.fit(X, y)\n\n# pr\u00e9diction sur les donn\u00e9es d'entra\u00eenement\ny_pred = clf.predict(X)\n\n# calcul de la performance du mod\u00e8le\naccuracy = clf.score(X, y)\nprint(\"Pr\u00e9cision:\", accuracy)\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es. Le mod\u00e8le SVM est cr\u00e9\u00e9 en utilisant la classe <code>SVC</code> du module scikit-learn. Nous sp\u00e9cifions ici que nous souhaitons utiliser un noyau lin\u00e9aire et un coefficient de r\u00e9gularisation <code>C</code> de 1. Ensuite, nous utilisons le mod\u00e8le pour pr\u00e9dire la variable cible en utilisant les variables explicatives, en stockant les pr\u00e9dictions dans la variable <code>y_pred</code>. Enfin, nous calculons la pr\u00e9cision du mod\u00e8le pour \u00e9valuer la performance. Notez que vous pouvez \u00e9galement utiliser d'autres types de noyaux, tels que les noyaux polynomiaux et les noyaux Gaussiens, pour r\u00e9soudre des t\u00e2ches de classification et de r\u00e9gression.</p>"},{"location":"Documentations/Machine%20Learning%20Algorithms/#implementation-simple-de-reseau-de-neurones-artificiels-rna","title":"Impl\u00e9mentation simple de R\u00e9seau de neurones artificiels (RNA)","text":"<p>Voici une impl\u00e9mentation simple de l'algorithme R\u00e9seau de neurones artificiels (RNA) en utilisant Python avec le module Keras :</p> <pre><code># importation des biblioth\u00e8ques n\u00e9cessaires\nimport numpy as np\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import Dense\n\n# chargement des donn\u00e9es\ndata = pd.read_csv(\"data.csv\")\n\n# s\u00e9lection des variables explicatives et de la variable cible\nX = data.drop('Variable_cible', axis=1)\ny = data['Variable_cible']\n\n# normalisation des donn\u00e9es\nX = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n\n# cr\u00e9ation d'un mod\u00e8le de RNA\nmodel = Sequential()\nmodel.add(Dense(64, activation='relu', input_shape=(X.shape[1],)))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# compilation du mod\u00e8le\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# entra\u00eenement du mod\u00e8le\nmodel.fit(X, y, epochs=50, batch_size=32, validation_split=0.2)\n\n# \u00e9valuation du mod\u00e8le\nscore = model.evaluate(X, y)\nprint(\"Pr\u00e9cision:\", score[1])\n</code></pre> <p>Dans cet exemple, nous importons les biblioth\u00e8ques numpy et pandas pour charger et manipuler les donn\u00e9es, et nous utilisons Keras pour construire et entra\u00eener le mod\u00e8le de RNA. Nous normalisons d'abord les donn\u00e9es pour am\u00e9liorer la convergence de l'entra\u00eenement. Ensuite, nous d\u00e9finissons un mod\u00e8le s\u00e9quentiel avec deux couches cach\u00e9es utilisant la fonction d'activation <code>relu</code>, ainsi qu'une couche de sortie utilisant la fonction d'activation <code>sigmoid</code>. Nous compilons le mod\u00e8le en sp\u00e9cifiant l'optimiseur <code>adam</code>, la fonction de co\u00fbt <code>binary_crossentropy</code> (car nous r\u00e9solvons ici une t\u00e2che de classification binaire) et les m\u00e9triques d'\u00e9valuation <code>accuracy</code>. Enfin, nous entra\u00eenons le mod\u00e8le en utilisant les donn\u00e9es d'entra\u00eenement, et nous \u00e9valuons la performance en utilisant la pr\u00e9cision. Il est important de noter que ceci n'est qu'une impl\u00e9mentation simple, et qu'il est souvent n\u00e9cessaire d'exp\u00e9rimenter avec diff\u00e9rents architectures et hyperparam\u00e8tres pour obtenir les meilleurs r\u00e9sultats sur les donn\u00e9es r\u00e9elles.</p>"},{"location":"Documentations/Natural%20Language%20Processing/","title":"Index","text":""},{"location":"Documentations/Natural%20Language%20Processing/#what-is-nlp","title":"What is NLP?","text":""},{"location":"Documentations/Natural%20Language%20Processing/#history-of-nlp","title":"History of NLP","text":""},{"location":"Documentations/Natural%20Language%20Processing/#challenges","title":"Challenges","text":""},{"location":"Documentations/Natural%20Language%20Processing/#applications","title":"Applications","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/","title":"Advanced","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#text-classification","title":"Text Classification","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#text-clustering","title":"Text Clustering","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#latent-dirichlet-allocation-lda","title":"Latent Dirichlet Allocation (LDA)","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#non-negative-matrix-factorization-nmf","title":"Non-Negative Matrix Factorization (NMF)","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#glove","title":"GloVe","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#lexicons","title":"Lexicons","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#ngrams","title":"NGrams","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#langague-modeling","title":"Langague Modeling","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#text-generation","title":"Text Generation","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#sentimental-analysis","title":"Sentimental Analysis","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#naive-bayes","title":"Na\u00efve Bayes","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#vader","title":"Vader","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#auto-correct","title":"Auto Correct","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#answering-questions","title":"Answering Questions","text":""},{"location":"Documentations/Natural%20Language%20Processing/advanced/#summarization","title":"Summarization","text":""},{"location":"Documentations/Natural%20Language%20Processing/bases/","title":"Bases","text":""},{"location":"Documentations/Natural%20Language%20Processing/bases/#libraries","title":"Libraries","text":""},{"location":"Documentations/Natural%20Language%20Processing/bases/#reading-text","title":"Reading Text","text":""},{"location":"Documentations/Natural%20Language%20Processing/bases/#handling-pdf","title":"Handling PDF","text":""},{"location":"Documentations/Natural%20Language%20Processing/bases/#search-in-text","title":"Search in Text","text":""},{"location":"Documentations/Natural%20Language%20Processing/collection/","title":"Collection","text":""},{"location":"Documentations/Natural%20Language%20Processing/collection/#tweet-collecting","title":"Tweet Collecting","text":""},{"location":"Documentations/Natural%20Language%20Processing/collection/#data-scraping","title":"Data Scraping","text":""},{"location":"Documentations/Natural%20Language%20Processing/collection/#information-extraction","title":"Information Extraction","text":""},{"location":"Documentations/Natural%20Language%20Processing/collection/#information-retrieval","title":"Information Retrieval","text":""},{"location":"Documentations/Natural%20Language%20Processing/collection/#relative-extraction","title":"Relative Extraction","text":""},{"location":"Documentations/Natural%20Language%20Processing/collection/#search-engine","title":"Search Engine","text":""},{"location":"Documentations/Natural%20Language%20Processing/modern/","title":"Modern","text":""},{"location":"Documentations/Natural%20Language%20Processing/modern/#teacher-forcing","title":"Teacher Forcing","text":""},{"location":"Documentations/Natural%20Language%20Processing/modern/#attention-models","title":"Attention Models","text":""},{"location":"Documentations/Natural%20Language%20Processing/modern/#hugging-face","title":"Hugging Face","text":""},{"location":"Documentations/Natural%20Language%20Processing/modern/#bert","title":"Bert","text":""},{"location":"Documentations/Natural%20Language%20Processing/modern/#fasttext","title":"FastText","text":""},{"location":"Documentations/Natural%20Language%20Processing/modern/#gensim","title":"Gensim","text":""},{"location":"Documentations/Natural%20Language%20Processing/modern/#chatbot","title":"Chatbot","text":""},{"location":"Documentations/Natural%20Language%20Processing/modern/#translation","title":"Translation","text":""},{"location":"Documentations/Natural%20Language%20Processing/reseaunn/","title":"Reseaunn","text":""},{"location":"Documentations/Natural%20Language%20Processing/reseaunn/#rnn","title":"RNN","text":""},{"location":"Documentations/Natural%20Language%20Processing/reseaunn/#lstm","title":"LSTM","text":""},{"location":"Documentations/Natural%20Language%20Processing/reseaunn/#gru","title":"GRU","text":""},{"location":"Documentations/Natural%20Language%20Processing/reseaunn/#tnn","title":"TNN","text":""},{"location":"Documentations/Natural%20Language%20Processing/reseaunn/#cnn","title":"CNN","text":""},{"location":"Documentations/Natural%20Language%20Processing/simple/","title":"Simple","text":""},{"location":"Documentations/Natural%20Language%20Processing/simple/#word-meaning","title":"Word Meaning","text":""},{"location":"Documentations/Natural%20Language%20Processing/simple/#word-embedding","title":"Word Embedding","text":""},{"location":"Documentations/Natural%20Language%20Processing/simple/#text-vectors","title":"Text Vectors","text":""},{"location":"Documentations/Natural%20Language%20Processing/simple/#word2vec","title":"Word2Vec","text":""},{"location":"Documentations/Natural%20Language%20Processing/simple/#bag-of-words-bow","title":"Bag Of Words (BOW)","text":""},{"location":"Documentations/Natural%20Language%20Processing/simple/#tf-idf","title":"TF-IDF","text":""},{"location":"Documentations/Natural%20Language%20Processing/simple/#text-similarity","title":"Text Similarity","text":""},{"location":"Documentations/Natural%20Language%20Processing/simple/#distributional-similarity","title":"Distributional Similarity","text":""},{"location":"Documentations/Natural%20Language%20Processing/tools/","title":"Tools","text":""},{"location":"Documentations/Natural%20Language%20Processing/tools/#tokenization","title":"Tokenization","text":""},{"location":"Documentations/Natural%20Language%20Processing/tools/#sentence-segmentation","title":"Sentence Segmentation","text":""},{"location":"Documentations/Natural%20Language%20Processing/tools/#part-of-speech-pos","title":"Part of Speech (POS)","text":""},{"location":"Documentations/Natural%20Language%20Processing/tools/#stemming-lemmatization","title":"Stemming &amp; Lemmatization","text":""},{"location":"Documentations/Natural%20Language%20Processing/tools/#named-entity-recognition-ner","title":"Named-Entity Recognition (NER)","text":""},{"location":"Documentations/Natural%20Language%20Processing/tools/#stopwords","title":"Stopwords","text":""},{"location":"Documentations/Natural%20Language%20Processing/tools/#matchers","title":"Matchers","text":""},{"location":"Documentations/Natural%20Language%20Processing/tools/#syntactic-structure","title":"Syntactic Structure","text":""},{"location":"Documentations/Natural%20Language%20Processing/tools/#text-visualization","title":"Text Visualization","text":""},{"location":"books/not%20yet/","title":"Books","text":""},{"location":"books/Hands%20on%20machine%20learning/preface/","title":"Preface","text":""},{"location":"books/Hands%20on%20machine%20learning/preface/#the-machine-learning-tsunami","title":"The Machine Learning Tsunami","text":"<p>In 2006, Geoffrey Hinton et al. published a paper [^1] showing how to train a deep neural network capable of recognizing handwritten digits with state-of-the-art precision (&gt;98%). They branded this technique \u201cDeep Learning.\u201d Training a deep neural net was widely considered impossible at the time,[^2] and most researchers had abandoned the idea since the 1990s. This paper revived the interest of the scientific community and before long many new papers demonstrated that Deep Learning was not only possible, but capable of mind-blowing achievements that no other Machine Learning (ML) technique could hope to match (with the help of tremendous computing power and great amounts of data). This enthusiasm soon extended to many other areas of Machine Learning.</p> <p>Fast-forward 10 years and Machine Learning has conquered the industry: it is now at the heart of much of the magic in today\u2019s high-tech products, ranking your web search results, powering your smartphone\u2019s speech recognition, recommending videos, and beating the world champion at the game of Go. Before you know it, it will be driving your car.</p>"},{"location":"books/Hands%20on%20machine%20learning/preface/#machine-learning-in-your-projects","title":"Machine Learning in Your Projects","text":"<p>So naturally you are excited about Machine Learning and you would love to join the party!</p> <p>Perhaps you would like to give your homemade robot a brain of its own? Make it recognize faces? Or learn to walk around?</p> <p>Or maybe your company has tons of data (user logs, financial data, production data, machine sensor data, hotline stats, HR reports, etc.), and more than likely you could unearth some hidden gems if you just knew where to look; for example:</p> <ul> <li> <p>Segment customers and find the best marketing strategy for each group</p> </li> <li> <p>Recommend products for each client based on what similar clients bought</p> </li> <li> <p>Detect which transactions are likely to be fraudulent</p> </li> <li> <p>Forecast next year\u2019s revenue</p> </li> <li> <p>And more</p> </li> </ul> <p>Whatever the reason, you have decided to learn Machine Learning and implement it in your projects. Great idea!</p>"},{"location":"books/Hands%20on%20machine%20learning/preface/#objective-and-approach","title":"Objective and Approach","text":"<p>This book assumes that you know close to nothing about Machine Learning. Its goal is to give you the concepts, the intuitions, and the tools you need to actually implement programs capable of learning from data.</p> <p>We will cover a large number of techniques, from the simplest and most commonly used (such as linear regression) to some of the Deep Learning techniques that regularly win competitions.</p> <p>Rather than implementing our own toy versions of each algorithm, we will be using actual production-ready Python frameworks:</p> <ul> <li> <p>Scikit-Learn is very easy to use, yet it implements many Machine Learning algorithms efficiently, so it makes for a great entry point to learn Machine Learning.</p> </li> <li> <p>TensorFlow is a more complex library for distributed numerical computation. It makes it possible to train and run very large neural networks efficiently by distributing the computations across potentially hundreds of multi-GPU servers. TensorFlow was created at Google and supports many of their large-scale Machine Learning applications. It was open sourced in November 2015.</p> </li> <li> <p>Keras is a high level Deep Learning API that makes it very simple to train and run neural networks. It can run on top of either TensorFlow, Theano or Microsoft Cognitive Toolkit (formerly known as CNTK). TensorFlow comes with its own implementation of this API, called tf.keras, which provides support for some advanced TensorFlow features (e.g., to efficiently load data).</p> </li> </ul> <p>The book favors a hands-on approach, growing an intuitive understanding of Machine Learning through concrete working examples and just a little bit of theory. While you can read this book without picking up your laptop, we highly recommend you experiment with the code examples available online as Jupyter notebooks at https://github.com/ageron/handson-ml2.</p>"},{"location":"books/Hands%20on%20machine%20learning/preface/#prerequisites","title":"Prerequisites","text":"<p>This book assumes that you have some Python programming experience and that you are familiar with Python\u2019s main scientific libraries, in particular NumPy, Pandas, and Matplotlib.</p> <p>Also, if you care about what\u2019s under the hood you should have a reasonable understanding of college-level math as well (calculus, linear algebra, probabilities, and statistics).</p> <p>If you don\u2019t know Python yet, http://learnpython.org/ is a great place to start. The official tutorial on python.org is also quite good.</p> <p>If you have never used Jupyter, Chapter 2 will guide you through installation and the basics: it is a great tool to have in your toolbox.</p> <p>If you are not familiar with Python\u2019s scientific libraries, the provided Jupyter notebooks include a few tutorials. There is also a quick math tutorial for linear algebra.</p>"},{"location":"books/Hands%20on%20machine%20learning/preface/#roadmap","title":"Roadmap","text":"<p>This book is organized in two parts. The Fundamentals of Machine Learning, covers the following topics:</p> <ul> <li> <p>What is Machine Learning? What problems does it try to solve? What are the main categories and fundamental concepts of Machine Learning systems?</p> </li> <li> <p>The main steps in a typical Machine Learning project.</p> </li> <li> <p>Learning by fitting a model to data.</p> </li> <li> <p>Optimizing a cost function.</p> </li> <li> <p>Handling, cleaning, and preparing data.</p> </li> <li> <p>Selecting and engineering features.</p> </li> <li> <p>The main challenges of Machine Learning, in particular underfitting and overfitting (the bias/variance tradeoff).</p> </li> <li> <p>Reducing the dimensionality of the training data to fight the curse of dimensionality.</p> </li> <li> <p>Other unsupervised learning techniques, including clustering, density estimation and anomaly detection.</p> </li> <li> <p>The most common learning algorithms: Linear and Polynomial Regression, Logistic Regression, k-Nearest Neighbors, Support Vector Machines, Decision Trees, Random Forests, and Ensemble methods.</p> </li> </ul> <p>Neural Networks and Deep Learning, covers the following topics:</p> <ul> <li> <p>What are neural nets? What are they good for?</p> </li> <li> <p>The most important neural net architectures: feedforward neural nets, convolutional nets, recurrent nets, long short-term memory (LSTM) nets, autoencoders and generative adversarial networks (GANs).</p> </li> <li> <p>Techniques for training deep neural nets.</p> </li> <li> <p>Scaling neural networks for large datasets.</p> </li> <li> <p>Learning strategies with Reinforcement Learning.</p> </li> <li> <p>Handling uncertainty with Bayesian Deep Learning.</p> </li> </ul> <p>The first part is based mostly on Scikit-Learn while the second part uses TensorFlow and Keras.</p> <p>Warning</p> <p>Don\u2019t jump into deep waters too hastily: while Deep Learning is no doubt one of the most exciting areas in Machine Learning, you should master the fundamentals first. Moreover, most problems can be solved quite well using simpler techniques such as Random Forests and Ensemble methods (discussed in The Fundamentals of Machine Learning). Deep Learning is best suited for complex problems such as image recognition, speech recognition, or natural language processing, provided you have enough data, computing power, and patience.</p>"},{"location":"books/Hands%20on%20machine%20learning/preface/#other-resources","title":"Other Resources","text":"<p>Many resources are available to learn about Machine Learning. Andrew Ng\u2019s ML course on Coursera and Geoffrey Hinton\u2019s course on neural networks and Deep Learning are amazing, although they both require a significant time investment (think months).</p> <p>There are also many interesting websites about Machine Learning, including of course Scikit-Learn\u2019s exceptional User Guide. You may also enjoy Dataquest, which provides very nice interactive tutorials, and ML blogs such as those listed on Quora. Finally, the Deep Learning website has a good list of resources to learn more.</p> <p>Of course there are also many other introductory books about Machine Learning, in particular:</p> <ul> <li> <p>Joel Grus, Data Science from Scratch (O\u2019Reilly). This book presents the fundamentals of Machine Learning, and implements some of the main algorithms in pure Python (from scratch, as the name suggests).</p> </li> <li> <p>Stephen Marsland, Machine Learning: An Algorithmic Perspective (Chapman and Hall). This book is a great introduction to Machine Learning, covering a wide range of topics in depth, with code examples in Python (also from scratch, but using NumPy).</p> </li> <li> <p>Sebastian Raschka, Python Machine Learning (Packt Publishing). Also a great introduction to Machine Learning, this book leverages Python open source libra\u2010 ries (Pylearn 2 and Theano).</p> </li> <li> <p>Fran\u00e7ois Chollet, Deep Learning with Python (Manning). A very practical book that covers a large range of topics in a clear and concise way, as you might expect from the author of the excellent Keras library. It favors code examples over math\u2010 ematical theory.</p> </li> <li> <p>Yaser S. Abu-Mostafa, Malik Magdon-Ismail, and Hsuan-Tien Lin, Learning from Data (AMLBook). A rather theoretical approach to ML, this book provides deep insights, in particular on the bias/variance tradeoff (see Training Models).</p> </li> <li> <p>Stuart Russell and Peter Norvig, Artificial Intelligence: A Modern Approach, 3rd Edition (Pearson). This is a great (and huge) book covering an incredible amount of topics, including Machine Learning. It helps put ML into perspective.</p> </li> </ul> <p>Finally, a great way to learn is to join ML competition websites such as Kaggle.com this will allow you to practice your skills on real-world problems, with help and insights from some of the best ML professionals out there.</p>"},{"location":"books/Hands%20on%20machine%20learning/preface/#conventions-used-in-this-book","title":"Conventions Used in This Book","text":"<p>The following typographical conventions are used in this book: Italic     Indicates new terms, URLs, email addresses, filenames, and file extensions. Constant width     Used for program listings, as well as within paragraphs to refer to program elements such as variable or function names, databases, data types, environment variables, statements and keywords. Constant width bold     Shows commands or other text that should be typed literally by the user. Constant width italic     Shows text that should be replaced with user-supplied values or by values determined by context.</p> <p>Tip</p> <p>This element signifies a tip or suggestion.</p> <p>Note</p> <p>This element signifies a general note.</p> <p>Warning</p> <p>This element indicates a warning or caution.</p>"},{"location":"books/Hands%20on%20machine%20learning/preface/#code-examples","title":"Code Examples","text":"<p>Supplemental material (code examples, exercises, etc.) is available for download at https://github.com/ageron/handson-ml2. It is mostly composed of Jupyter notebooks.</p> <p>Some of the code examples in the book leave out some repetitive sections, or details that are obvious or unrelated to Machine Learning. This keeps the focus on the important parts of the code, and it saves space to cover more topics. However, if you want the full code examples, they are all available in the Jupyter notebooks.</p> <p>Note that when the code examples display some outputs, then these code examples are shown with Python prompts (&gt;&gt;&gt; and ...), as in a Python shell, to clearly distinguish the code from the outputs. For example, this code defines the square() function then it computes and displays the square of 3:</p> <p><pre><code>def square(x):\n    return x ** 2\n...\nresult = square(3)\nresult\n</code></pre> 9</p> <p>When code does not display anything, prompts are not used. However, the result may sometimes be shown as a comment like this:</p> <pre><code>def square(x):\n    return x ** 2\n\nresult = square(3)\nresult # result is 9\n</code></pre>"},{"location":"books/Hands%20on%20machine%20learning/preface/#using-code-examples","title":"Using Code Examples","text":"<p>This book is here to help you get your job done. In general, if example code is offered with this book, you may use it in your programs and documentation. You do not need to contact us for permission unless you\u2019re reproducing a significant portion of the code. For example, writing a program that uses several chunks of code from this book does not require permission. Selling or distributing a CD-ROM of examples from O\u2019Reilly books does require permission. Answering a question by citing this book and quoting example code does not require permission. Incorporating a significant amount of example code from this book into your product\u2019s documentation does require permission.</p> <p>We appreciate, but do not require, attribution. An attribution usually includes the title, author, publisher, and ISBN. For example: \u201cHands-On Machine Learning with Scikit-Learn, Keras and TensorFlow by Aur\u00e9lien G\u00e9ron (O\u2019Reilly). Copyright 2019 Aur\u00e9lien G\u00e9ron, 978-1-492-03264-9.\u201d If you feel your use of code examples falls outside fair use or the permission given above, feel free to contact us at permissions@oreilly.com.</p>"},{"location":"books/Hands%20on%20machine%20learning/preface/#oreilly-safari","title":"O\u2019Reilly Safari","text":"<p>Safari (formerly Safari Books Online) is a membership-based training and reference platform for enterprise, government, educators, and individuals.</p> <p>Members have access to thousands of books, training videos, Learning Paths, interactive tutorials, and curated playlists from over 250 publishers, including O\u2019Reilly Media, Harvard Business Review, Prentice Hall Professional, Addison-Wesley Professional, Microsoft Press, Sams, Que, Peachpit Press, Adobe, Focal Press, Cisco Press, John Wiley &amp; Sons, Syngress, Morgan Kaufmann, IBM Redbooks, Packt, Adobe Press, FT Press, Apress, Manning, New Riders, McGraw-Hill, Jones &amp; Bartlett, and Course Technology, among others.</p> <p>For more information, please visit http://oreilly.com/safari.</p>"},{"location":"books/Hands%20on%20machine%20learning/preface/#how-to-contact-us","title":"How to Contact Us","text":"<p>Please address comments and questions concerning this book to the publisher:</p> <p>:   O\u2019Reilly Media, Inc.</p> <pre><code>1005 Gravenstein Highway North\n\nSebastopol, CA 95472\n\n800-998-9938 (in the United States or Canada)\n\n707-829-0515 (international or local)\n\n707-829-0104 (fax)\n</code></pre> <p>We have a web page for this book, where we list errata, examples, and any additional information. You can access this page at http://bit.ly/hands-on-machine-learning-with-scikit-learn-and-tensorflow or https://homl.info/oreilly.</p> <p>To comment or ask technical questions about this book, send email to bookques\u2010tions@oreilly.com.</p> <p>For more information about our books, courses, conferences, and news, see our website at http://www.oreilly.com.</p> <p>Find us on Facebook: http://facebook.com/oreilly</p> <p>Follow us on Twitter: http://twitter.com/oreillymedia</p> <p>Watch us on YouTube: http://www.youtube.com/oreillymedia</p>"},{"location":"books/Hands%20on%20machine%20learning/preface/#changes-in-the-second-edition","title":"Changes in the Second Edition","text":"<p>This second edition has five main objectives:</p> <ol> <li> <p>Cover additional topics: additional unsupervised learning techniques (including clustering, anomaly detection, density estimation and mixture models), additional techniques for training deep nets (including self-normalized networks), additional computer vision techniques (including the Xception, SENet, object detection with YOLO, and semantic segmentation using R-CNN), handling sequences using CNNs (including WaveNet), natural language processing using RNNs, CNNs and Transformers, generative adversarial networks, deploying TensorFlow models, and more.</p> </li> <li> <p>Update the book to mention some of the latest results from Deep Learning research.</p> </li> <li> <p>Migrate all TensorFlow chapters to TensorFlow 2, and use TensorFlow\u2019s implementation of the Keras API (called tf.keras) whenever possible, to simplify the code examples.</p> </li> <li> <p>Update the code examples to use the latest version of Scikit-Learn, NumPy, Pandas, Matplotlib and other libraries.</p> </li> <li> <p>Clarify some sections and fix some errors, thanks to plenty of great feedback from readers.</p> </li> </ol> <p>Some chapters were added, others were rewritten and a few were reordered. Table P-1 shows the mapping between the 1st edition chapters and the 2nd edition chapters:</p> <p>Table P-1. Chapter mapping between 1st and 2nd edition</p> 1st Ed.chapter 2nd Ed.chapter % Changes 2nd Ed.chapter 1 1 &lt;10% The Machine Learning Landscape 2 2 &lt;10% End-to-End Machine Learning Project 3 3 &lt;10% Classification 4 4 &lt;10% Training Models 5 5 &lt;10% Support Vector Machines 6 6 &lt;10% Decision Trees 7 7 &lt;10% Ensemble Learning and Random Forests 8 8 &lt;10% Dimensionality Reduction N/A 9 100% new Unsupervised Learning Techniques 10 10 ~75% Introduction to Artificial Neural Networks with Keras 11 11 ~50% Training Deep Neural Networks 9 12 100% rewritten Custom Models and Training with TensorFlow Part of 12 13 100% rewritten Loading and Preprocessing Data with TensorFlow 13 14 ~50% Deep Computer Vision Using Convolutional Neural Networks Part of 14 15 ~75% Processing Sequences Using RNNs and CNNs Part of 14 16 ~90% Natural Language Processing with RNNs and Attention 15 17 ~75% Autoencoders and GANs 16 18 ~75% Reinforcement Learning Part of 12 19 100% rewritten Deploying your TensorFlow Models <p>More specifically, here are the main changes for each 2nd edition chapter (other than clarifications, corrections and code updates):</p> <ul> <li> <p>Chapter 1</p> <ul> <li>Added a section on handling mismatch between the training set and the validation &amp; test sets.</li> </ul> </li> <li> <p>Chapter 2</p> <ul> <li>Added how to compute a confidence interval.</li> <li>Improved the installation instructions (e.g., for Windows).</li> <li>Introduced the upgraded OneHotEncoder and the new ColumnTransformer.</li> </ul> </li> <li> <p>Chapter 4</p> <ul> <li>Explained the need for training instances to be Independent and Identically Distributed (IID).</li> </ul> </li> <li> <p>Chapter 7</p> <ul> <li>Added a short section about XGBoost.</li> </ul> </li> <li> <p>Chapter 9 \u2013 new chapter including:</p> <ul> <li>Clustering with K-Means, how to choose the number of clusters, how to use it for dimensionality reduction, semi-supervised learning, image segmentation, and more.</li> <li>Gaussian mixture models, the Expectation-Maximization (EM) algorithm, Bayesian variational inference, and how mixture models can be used for clustering, density estimation, anomaly detection and novelty detection.</li> <li>Overview of other anomaly detection and novelty detection algorithms.</li> </ul> </li> <li> <p>Chapter 10 (mostly new)</p> <ul> <li>Added an introduction to the Keras API, including all its APIs (Sequential, Functional and Subclassing), persistence and callbacks (including the Tensor Board callback).</li> </ul> </li> <li> <p>Chapter 11 (many changes)</p> <ul> <li>Introduced self-normalizing nets, the SELU activation function and Alpha Dropout.</li> <li>Introduced self-supervised learning.</li> <li>Added Nadam optimization.</li> <li>Added Monte-Carlo Dropout.</li> <li>Added a note about the risks of adaptive optimization methods.</li> <li>Updated the practical guidelines.</li> </ul> </li> <li> <p>Chapter 12 \u2013 completely rewritten chapter, including:</p> <ul> <li>A tour of TensorFlow 2</li> <li>TensorFlow\u2019s lower-level Python API</li> <li>Writing custom loss functions, metrics, layers, models</li> <li>Using auto-differentiation and creating custom training algorithms.</li> <li>TensorFlow Functions and graphs (including tracing and autograph).</li> </ul> </li> <li> <p>Chapter 13 \u2013 new chapter, including:</p> <ul> <li>The Data API</li> <li>Loading/Storing data efficiently using TFRecords</li> <li>The Features API (including an introduction to embeddings).</li> <li>An overview of TF Transform and TF Datasets</li> <li>Moved the low-level implementation of the neural network to the exercises.</li> <li>Removed details about queues and readers that are now superseded by the Data API.</li> </ul> </li> <li> <p>Chapter 14</p> <ul> <li>Added Xception and SENet architectures.</li> <li>Added a Keras implementation of ResNet-34.</li> <li>Showed how to use pretrained models using Keras.</li> <li>Added an end-to-end transfer learning example.</li> <li>Added classification and localization.</li> <li>Introduced Fully Convolutional Networks (FCNs).</li> <li>Introduced object detection using the YOLO architecture.</li> <li>Introduced semantic segmentation using R-CNN.</li> </ul> </li> <li> <p>Chapter 15</p> <ul> <li>Added an introduction to Wavenet.</li> <li>Moved the Encoder\u2013Decoder architecture and Bidirectional RNNs to Chapter 16.</li> </ul> </li> <li> <p>Chapter 16</p> <ul> <li>Explained how to use the Data API to handle sequential data.</li> <li>Showed an end-to-end example of text generation using a Character RNN, using both a stateless and a stateful RNN.</li> <li>Showed an end-to-end example of sentiment analysis using an LSTM.</li> <li>Explained masking in Keras.</li> <li>Showed how to reuse pretrained embeddings using TF Hub.</li> <li>Showed how to build an Encoder\u2013Decoder for Neural Machine Translation using TensorFlow Addons/seq2seq.</li> <li>Introduced beam search.</li> <li>Explained attention mechanisms.</li> <li>Added a short overview of visual attention and a note on explainability.</li> <li>Introduced the fully attention-based Transformer architecture, including positional embeddings and multi-head attention.</li> <li>Added an overview of recent language models (2018).</li> </ul> </li> <li> <p>Chapters 17, 18 and 19: coming soon.</p> </li> </ul>"},{"location":"books/Hands%20on%20machine%20learning/preface/#acknowledgments","title":"Acknowledgments","text":"<p>Never in my wildest dreams did I imagine that the first edition of this book would get such a large audience. I received so many messages from readers, many asking questions, some kindly pointing out errata, and most sending me encouraging words. I cannot express how grateful I am to all these readers for their tremendous support. Thank you all so very much! Please do not hesitate to file issues on github if you find errors in the code examples (or just to ask questions), or to submit errata if you find errors in the text. Some readers also shared how this book helped them get their first job, or how it helped them solve a concrete problem they were working on: I find such feedback incredibly motivating. If you find this book helpful, I would love it if you could share your story with me, either privately (e.g., via LinkedIn) or publicly (e.g., in an Amazon review).</p> <p>I am also incredibly thankful to all the amazing people who took time out of their busy lives to review my book with such care. In particular, I would like to thank Fran\u00e7ois Chollet for reviewing all the chapters based on Keras &amp; TensorFlow, and giving me some great, in-depth feedback. Since Keras is one of the main additions to this 2nd edition, having its author review the book was invaluable. I highly recommend Fran\u00e7ois\u2019s excellent book Deep Learning with Python[#3]: it has the conciseness, clarity and depth of the Keras library itself. Big thanks as well to Ankur Patel, who reviewed every chapter of this 2nd edition and gave me excellent feedback.</p> <p>This book also benefited from plenty of help from members of the TensorFlow team, in particular Martin Wicke, who tirelessly answered dozens of my questions and dispatched the rest to the right people, including Alexandre Passos, Allen Lavoie, Andr\u00e9 Susano Pinto, Anna Revinskaya, Anthony Platanios, Clemens Mewald, Dan Moldo\u2010van, Daniel Dobson, Dustin Tran, Edd Wilder-James, Goldie Gadde, Jiri Simsa, Karmel Allison, Nick Felt, Paige Bailey, Pete Warden (who also reviewed the 1st edition), Ryan Sepassi, Sandeep Gupta, Sean Morgan, Todd Wang, Tom O\u2019Malley, William Chargin, and Yuefeng Zhou, all of whom were tremendously helpful. A huge thank you to all of you, and to all other members of the TensorFlow team. Not just for your help, but also for making such a great library.</p> <p>Big thanks to Haesun Park, who gave me plenty of excellent feedback and caught several errors while he was writing the Korean translation of the 1st edition of this book. He also translated the Jupyter notebooks to Korean, not to mention TensorFlow\u2019s documentation. I do not speak Korean, but judging by the quality of his feedback, all his translations must be truly excellent! Moreover, he kindly contributed some of the solutions to the exercises in this book.</p> <p>Many thanks as well to O\u2019Reilly\u2019s fantastic staff, in particular Nicole Tache, who gave me insightful feedback, always cheerful, encouraging, and helpful: I could not dream of a better editor. Big thanks to Michele Cronin as well, who was very helpful (and patient) at the start of this 2nd edition. Thanks to Marie Beaugureau, Ben Lorica, Mike Loukides, and Laurel Ruma for believing in this project and helping me define its scope. Thanks to Matt Hacker and all of the Atlas team for answering all my technical questions regarding formatting, asciidoc, and LaTeX, and thanks to Rachel Monaghan, Nick Adams, and all of the production team for their final review and their hundreds of corrections.</p> <p>I would also like to thank my former Google colleagues, in particular the YouTube video classification team, for teaching me so much about Machine Learning. I could never have started the first edition without them. Special thanks to my personal ML gurus: Cl\u00e9ment Courbet, Julien Dubois, Mathias Kende, Daniel Kitachewsky, James Pack, Alexander Pak, Anosh Raj, Vitor Sessak, Wiktor Tomczak, Ingrid von Glehn, Rich Washington, and everyone I worked with at YouTube and in the amazing Google research teams in Mountain View. All these people are just as nice and helpful as they are bright, and that\u2019s saying a lot.</p> <p>I will never forget the kind people who reviewed the 1st edition of this book, including David Andrzejewski, Eddy Hung, Gr\u00e9goire Mesnil, Iain Smears, Ingrid von Glehn, Justin Francis, Karim Matrah, Lukas Biewald, Michel Tessier, Salim S\u00e9maoune, Vincent Guilbeau and of course my dear brother Sylvain.</p> <p>Last but not least, I am infinitely grateful to my beloved wife, Emmanuelle, and to our three wonderful children, Alexandre, R\u00e9mi, and Gabrielle, for encouraging me to work hard on this book, as well as for their insatiable curiosity: explaining some of the most difficult concepts in this book to my wife and children helped me clarify my thoughts and directly improved many parts of this book. Plus, they keep bringing me cookies and coffee! What more can one dream of?</p> <p>[^1]: Available on Hinton\u2019s home page at http://www.cs.toronto.edu/~hinton/.</p> <p>[^2]: Despite the fact that Yann Lecun\u2019s deep convolutional neural networks had worked well for image recognition since the 1990s, although they were not as general purpose.</p> <p>[#3]:     \u201cDeep Learning with Python,\u201d Fran\u00e7ois Chollet (2017).</p>"},{"location":"books/Hands%20on%20machine%20learning/Neural%20Networks%20and%20Deep%20Learning/4.1.%20Introduction%20to%20Artificial%20Neural%20Networks%20with%20Keras/","title":"Introduction to Artificial Neural Networks with Keras","text":""},{"location":"books/Hands%20on%20machine%20learning/Neural%20Networks%20and%20Deep%20Learning/4.2.%20Training%20Deep%20Neural%20Networks/","title":"Training Deep Neural Networks","text":""},{"location":"books/Hands%20on%20machine%20learning/Neural%20Networks%20and%20Deep%20Learning/4.3.%20Custom%20Models%20and%20Training%20with%20TensorFlow/","title":"Custom Models and Training with TensorFlow","text":""},{"location":"books/Hands%20on%20machine%20learning/Neural%20Networks%20and%20Deep%20Learning/4.4.%20Loading%20and%20Preprocessing%20Data%20with%20TensorFlow/","title":"Custom Models and Training with TensorFlow","text":""},{"location":"books/Hands%20on%20machine%20learning/Neural%20Networks%20and%20Deep%20Learning/4.5.%20Deep%20Computer%20Vision%20Using%20Convolutional%20Neural%20Networks/","title":"Deep Computer Vision Using Convolutional Neural Networks","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.1.%20The%20Machine%20Learning%20Landscape/","title":"The Machine Learning Landscape","text":"<p>Note</p> <p>With Early Release ebooks, you get books in their earliest form the author\u2019s raw and unedited content as he or she writes\u2014so you can take advantage of these technologies long before the official release of these titles. The following will be Chapter 1 in the final release of the book.</p> <p>When most people hear \u201cMachine Learning,\u201d they picture a robot: a dependable but\u2010ler or a deadly Terminator depending on who you ask. But Machine Learning is not just a futuristic fantasy, it\u2019s already here. In fact, it has been around for decades in some specialized applications, such as Optical Character Recognition (OCR). But the first ML application that really became mainstream, improving the lives of hundreds of millions of people, took over the world back in the 1990s: it was the spam filter. Not exactly a self-aware Skynet, but it does technically qualify as Machine Learning (it has actually learned so well that you seldom need to flag an email as spam anymore). It was followed by hundreds of ML applications that now quietly power hundreds of products and features that you use regularly, from better recommendations to voice search.</p> <p>Where does Machine Learning start and where does it end? What exactly does it mean for a machine to learn something? If I download a copy of Wikipedia, has my computer really \u201clearned\u201d something? Is it suddenly smarter? In this chapter we will start by clarifying what Machine Learning is and why you may want to use it.</p> <p>Then, before we set out to explore the Machine Learning continent, we will take a look at the map and learn about the main regions and the most notable landmarks: supervised versus unsupervised learning, online versus batch learning, instance-based versus model-based learning. Then we will look at the workflow of a typical ML project, discuss the main challenges you may face, and cover how to evaluate and fine-tune a Machine Learning system.</p> <p>his chapter introduces a lot of fundamental concepts (and jargon) that every data scientist should know by heart. It will be a high-level overview (the only chapter without much code), all rather simple, but you should make sure everything is crystal-clear to you before continuing to the rest of the book. So grab a coffee and let\u2019s get started!</p> <p>Tip</p> <p>If you already know all the Machine Learning basics, you may want to skip directly to End-to-End Machine Learning Project. If you are not sure, try to answer all the questions listed at the end of the chapter before moving on.</p>"},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.1.%20The%20Machine%20Learning%20Landscape/#what-is-machine-learning","title":"What Is Machine Learning?","text":"<p>Machine Learning is the science (and art) of programming computers so they can learn from data.</p> <p>Here is a slightly more general definition:     * [Machine Learning is the] field of study that gives computers the ability to learn without being explicitly programmed.         - Arthur Samuel, 1959</p>"},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.2.%20End-to-End%20Machine%20Learning%20Project/","title":"End-to-End Machine Learning Project","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.3.%20Classification/","title":"Classification","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.4.%20Training%20Models/","title":"Training Models","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.5.%20Support%20Vector%20Machines/","title":"Support Vector Machines","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.6.%20Decision%20Trees/","title":"Decision Trees","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.7.%20Ensemble%20Learning%20and%20Random%20Forests/","title":"Ensemble Learning and Random Forests","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.8.%20Dimensionality%20Reduction/","title":"Dimensionality Reduction","text":""},{"location":"books/Hands%20on%20machine%20learning/The%20Fundamentals%20of%20Machine%20Learning/3.9.%20Unsupervised%20Learning%20Techniques/","title":"Unsupervised Learning Techniques","text":""},{"location":"projects/Painting%20Vermeer/","title":"Algorithmes G\u00e9n\u00e9tiques 2: Peindre Vermeer","text":""},{"location":"projects/Painting%20Vermeer/#introduction","title":"Introduction","text":"<p>Packages</p> <p>Les Algorithmes G\u00e9n\u00e9tiques 2: Peindre Vermeer est un probl\u00e8me dans lequel un algorithme g\u00e9n\u00e9tique peut \u00eatre appliqu\u00e9. L'objectif est de cr\u00e9er une peinture g\u00e9n\u00e9r\u00e9e par ordinateur qui ressemble \u00e0 une peinture du c\u00e9l\u00e8bre peintre hollandais Johannes Vermeer.</p> <p>Pour appliquer un algorithme g\u00e9n\u00e9tique \u00e0 ce probl\u00e8me, nous devons d\u00e9finir un ensemble de g\u00e8nes, qui repr\u00e9sentent dans ce cas la couleur et la position de chaque coup de pinceau. Chaque individu de la population serait une peinture cr\u00e9\u00e9e en combinant les g\u00e8nes d'une mani\u00e8re particuli\u00e8re. La fonction d'adaptation serait utilis\u00e9e pour \u00e9valuer dans quelle mesure chaque peinture ressemble \u00e0 une v\u00e9ritable peinture de Vermeer.</p> <p>L'algorithme g\u00e9n\u00e9tique serait ensuite appliqu\u00e9 de la mani\u00e8re suivante :</p> <ol> <li> <p>Initialisation : G\u00e9n\u00e9rer une population initiale d'individus al\u00e9atoires.</p> </li> <li> <p>\u00c9valuation : \u00c9valuer la qualit\u00e9 de chaque individu en utilisant la fonction d'adaptation.</p> </li> <li> <p>S\u00e9lection : S\u00e9lectionner un sous-ensemble d'individus de la population pour servir de parents \u00e0 la prochaine g\u00e9n\u00e9ration.</p> </li> <li> <p>Croisement : Combiner les g\u00e8nes des parents s\u00e9lectionn\u00e9s pour cr\u00e9er de nouveaux individus.</p> </li> <li> <p>Mutation : Introduire des changements al\u00e9atoires dans les g\u00e8nes des nouveaux individus.</p> </li> <li> <p>Remplacement : Remplacer certains individus de la population actuelle par les nouveaux individus.</p> </li> <li> <p>Condition d'arr\u00eat : V\u00e9rifier si la condition d'arr\u00eat a \u00e9t\u00e9 atteinte. Si ce n'est pas le cas, revenir \u00e0 l'\u00e9tape 2.</p> </li> </ol> <p>Dans le cas de la peinture de Vermeer, la condition d'arr\u00eat pourrait \u00eatre un nombre maximal de g\u00e9n\u00e9rations ou un niveau d'adaptation seuil.</p> <p>En appliquant ces \u00e9tapes de mani\u00e8re it\u00e9rative, l'algorithme g\u00e9n\u00e9tique am\u00e9liorera progressivement la qualit\u00e9 des peintures dans la population. Au fil du temps, l'algorithme peut converger vers une peinture qui ressemble \u00e9troitement \u00e0 une peinture de Vermeer.</p>"},{"location":"projects/Painting%20Vermeer/#importer-les-packages","title":"Importer les Packages","text":"<p>Packages</p> <ul> <li> <p>os : est une biblioth\u00e8que standard de Python qui permet d'interagir avec le syst\u00e8me d'exploitation sous-jacent. Il fournit des fonctionnalit\u00e9s pour effectuer des op\u00e9rations li\u00e9es aux fichiers et aux r\u00e9pertoires, \u00e0 l'environnement syst\u00e8me, aux processus, etc.</p> </li> <li> <p>NumPy : NumPy est une biblioth\u00e8que Python populaire pour le calcul scientifique qui fournit des structures de donn\u00e9es pour la repr\u00e9sentation de tableaux multidimensionnels et des fonctions pour manipuler ces tableaux.</p> </li> <li> <p>random : The random module in Python provides a suite of functions for generating random numbers.</p> </li> <li> <p>colour : est une biblioth\u00e8que de gestion des couleurs qui offre des fonctionnalit\u00e9s pour la manipulation, la conversion et la repr\u00e9sentation des couleurs dans diff\u00e9rents espaces colorim\u00e9triques.</p> </li> <li> <p>json : cette biblioth\u00e8que permet de travailler avec des donn\u00e9es au format JSON (JavaScript Object Notation). Le module json offre des fonctions pour la s\u00e9rialisation (encodage) et la d\u00e9s\u00e9rialisation (d\u00e9codage) des objets Python en JSON et vice versa.</p> </li> <li> <p>Pygame : est une biblioth\u00e8que Python populaire utilis\u00e9e pour d\u00e9velopper des jeux vid\u00e9o et des applications multim\u00e9dias interactives. Elle fournit des fonctionnalit\u00e9s pour la cr\u00e9ation de graphismes, la gestion des \u00e9v\u00e9nements, le traitement du son, la gestion des entr\u00e9es utilisateur et bien plus encore.</p> </li> </ul> <pre><code>import os\nimport numpy as np\nfrom numpy.random import choice, random, normal\nfrom colour import Color\nimport json\nimport pygame\n</code></pre>"},{"location":"projects/Painting%20Vermeer/#initialiser-un-organisme","title":"Initialiser un organisme","text":"<p>Organism</p> <p>Ce code d\u00e9finit la classe <code>Organism</code> (Organisme) qui repr\u00e9sente un organisme avec un ensemble de g\u00e8nes. Elle a les attributs suivants :</p> <p>chromosome: un tableau numpy repr\u00e9sentant les g\u00e8nes de l'organisme. Les valeurs des g\u00e8nes sont limit\u00e9es entre 0 et 1 \u00e0 l'aide de np.clip(genes, 0, 1).</p> <p>visual: une variable utilis\u00e9e pour stocker une repr\u00e9sentation visuelle de l'organisme (probablement une image).</p> <p>fitness: une variable utilis\u00e9e pour stocker la valeur de fitness de l'organisme.</p> <p>La classe <code>Organism</code> a \u00e9galement une m\u00e9thode <code>mutate</code> qui effectue une mutation sur l'organisme. Les param\u00e8tres rate, scale et add sont les taux de mutation et d'ajout, ainsi que l'\u00e9chelle de mutation utilis\u00e9s dans le processus de mutation. Voici ce que fait la m\u00e9thode <code>mutate</code> :</p> <ul> <li> <p>Elle effectue une copie du chromosome de l'organisme en utilisant np.copy(self.chromosome).</p> </li> <li> <p>Elle d\u00e9termine le nombre de mutations \u00e0 effectuer en fonction du taux de mutation : num_mutations = 1 + int(rate * n_gene).</p> </li> <li> <p>Elle it\u00e8re sur le nombre de mutations et effectue les mutations suivantes :</p> <ul> <li> <p>Si le r\u00e9sultat de random() &gt; add est True, une mutation sur un g\u00e8ne existant est effectu\u00e9e.</p> <ul> <li> <p>Un indice i est choisi al\u00e9atoirement \u00e0 partir des indices de caract\u00e9ristiques (n_feat).</p> </li> <li> <p>Une valeur al\u00e9atoire est ajout\u00e9e \u00e0 la caract\u00e9ristique s\u00e9lectionn\u00e9e dans un g\u00e8ne s\u00e9lectionn\u00e9 al\u00e9atoirement dans le chromosome.</p> </li> <li> <p>Si l'indice est 3, la valeur de cette caract\u00e9ristique est modulo 1.</p> </li> </ul> </li> <li> <p>Sinon, une op\u00e9ration d'ajout ou de suppression d'un g\u00e8ne est effectu\u00e9e.</p> <ul> <li>Si random() &lt; 0.3, un g\u00e8ne est supprim\u00e9 al\u00e9atoirement du chromosome. Sinon, deux g\u00e8nes existants sont s\u00e9lectionn\u00e9s al\u00e9atoirement pour cr\u00e9er un nouveau g\u00e8ne. Le nouveau g\u00e8ne est obtenu en faisant la moyenne des deux g\u00e8nes s\u00e9lectionn\u00e9s et en ajoutant une perturbation. La troisi\u00e8me caract\u00e9ristique du nouveau g\u00e8ne est multipli\u00e9e par 0.2.</li> </ul> </li> </ul> </li> <li> <p>Enfin, la m\u00e9thode renvoie un nouvel objet <code>Organism</code> avec le chromosome mut\u00e9.</p> </li> </ul> <pre><code>class Organism:\n    def __init__(self, genes):\n\"\"\"\n        Initialise un organisme avec un ensemble de g\u00e8nes.\n\n        - genes : Matrice repr\u00e9sentant les g\u00e8nes de l'organisme.\n        \"\"\"\n        self.chromosome = np.clip(genes, 0, 1)\n        self.visual = None\n        self.fitness = None\n\n    def mutate(self, rate=0.01, scale=0.3, add=0.3):\n\"\"\"\n        Effectue une mutation sur l'organisme avec des taux de mutation et une \u00e9chelle donn\u00e9s.\n\n        - rate : Taux de mutation, probabilit\u00e9 qu'un g\u00e8ne soit mut\u00e9.\n        - scale : \u00c9chelle de la mutation, d\u00e9termine l'amplitude des mutations.\n        - add : Probabilit\u00e9 d'ajouter un nouveau g\u00e8ne lors de la mutation.\n\n        Retourne un nouvel organisme mut\u00e9.\n        \"\"\"\n        chromosome = np.copy(self.chromosome)\n        n_gene, n_feat = chromosome.shape\n\n        # Ici, nous pouvons ajouter/supprimer un g\u00e8ne ou muter un g\u00e8ne existant\n        if random() &gt; add:\n            # Mutation des caract\u00e9ristiques de nos g\u00e8nes\n            num_mutations = 1 + int(rate * n_gene)\n            # \u00c0 mesure que nous effectuons plus de mutations, la taille des mutations diminue\n            scale2 = scale / num_mutations\n            for i in range(num_mutations):\n                if random() &gt; 0.5:\n                    i = 3\n                else:\n                    i = choice(n_feat)\n                chromosome[choice(n_gene), i] += normal() * scale2\n                if i == 3:\n                    chromosome[:, i] = np.mod(chromosome[:, i], 1)\n        else:\n            # Ajout ou suppression d'un g\u00e8ne\n            if random() &lt; 0.3:\n                chromosome = np.delete(chromosome, choice(n_gene), axis=0)\n            else:\n                # Lorsque nous ajoutons un g\u00e8ne, nous le ferons en m\u00e9langeant deux g\u00e8nes existants\n                # et en le perturbant. Il est plus probable de trouver un bon g\u00e8ne de cette mani\u00e8re.\n                a, b = choice(n_gene, 2, replace=False)\n                gene = np.atleast_2d(0.5 * (chromosome[a, :] + chromosome[b, :]))\n                gene += scale * normal(size=(1, gene.size))\n                gene[:, 2] *= 0.2\n                chromosome = np.append(chromosome, gene, axis=0)\n\n        return Organism(chromosome)\n</code></pre>"},{"location":"projects/Painting%20Vermeer/#initialiser-une-population","title":"Initialiser une population","text":"<p>Population</p> <p>La classe <code>Population</code> comprend plusieurs m\u00e9thodes pour simuler et faire \u00e9voluer une population d'organismes bas\u00e9e sur une image de r\u00e9f\u00e9rence.</p> <p>Le code utilise la biblioth\u00e8que Pygame pour g\u00e9rer les graphiques et la manipulation d'images. Voici un bref r\u00e9sum\u00e9 de chaque m\u00e9thode dans le code :</p> <ul> <li> <p>init(self, path) : M\u00e9thode constructeur qui charge une image de r\u00e9f\u00e9rence \u00e0 partir d'un chemin de fichier donn\u00e9 en utilisant la biblioth\u00e8que Pygame, cr\u00e9e une surface sur laquelle dessiner et initialise une liste de population vide.</p> </li> <li> <p>draw(self, organism) : M\u00e9thode pour dessiner un organisme sur la surface en it\u00e9rant sur son chromosome et en dessinant des cercles avec une position, une taille et une couleur donn\u00e9es.</p> </li> <li> <p>spawn(self, pop_size=30, complexity=10) : M\u00e9thode pour g\u00e9n\u00e9rer une nouvelle population d'organismes en cr\u00e9ant un certain nombre d'organismes avec un nombre sp\u00e9cifi\u00e9 de g\u00e8nes dans chaque membre.</p> </li> <li> <p>calc_fitness(self, organism) : M\u00e9thode pour calculer la forme physique d'un organisme en le dessinant et en le comparant \u00e0 l'image de r\u00e9f\u00e9rence. La forme physique est calcul\u00e9e comme la diff\u00e9rence absolue moyenne n\u00e9gative entre les pixels des deux images.</p> </li> <li> <p>get_child(self, a, b) : M\u00e9thode pour g\u00e9n\u00e9rer un nouvel organisme en combinant deux organismes parents. Les g\u00e8nes de chaque parent sont choisis au hasard avec une probabilit\u00e9 de 70% pour le premier parent et de 30% pour le deuxi\u00e8me parent. Les g\u00e8nes communs sont m\u00e9lang\u00e9s dans le nouvel organisme.</p> </li> <li> <p>save(self, path) : M\u00e9thode pour enregistrer la population actuelle dans un fichier JSON.</p> </li> <li> <p>load(self, path) : M\u00e9thode pour charger une population \u00e0 partir d'un fichier JSON.</p> </li> <li> <p>mutate_and_pick(self, organism, rate, scale, add, attempts=10) : M\u00e9thode pour muter un organisme en ajoutant une valeur al\u00e9atoire \u00e0 chaque g\u00e8ne avec une probabilit\u00e9 sp\u00e9cifi\u00e9e. La m\u00e9thode essaie de muter l'organisme un certain nombre de fois sp\u00e9cifi\u00e9 et renvoie l'organisme mut\u00e9 avec la forme physique la plus \u00e9lev\u00e9e.</p> </li> <li> <p>step(self, time, outdir, rate=0.01, scale=0.1, add=0.3) : M\u00e9thode pour simuler une \u00e9tape d'\u00e9volution en cr\u00e9ant de nouvelles descendances, en les mutant et en conservant les plus adapt\u00e9es. La m\u00e9thode enregistre une image de l'organisme le plus adapt\u00e9 dans un fichier et enregistre la population actuelle dans un fichier JSON.</p> </li> </ul> <pre><code>class Population:\n    def __init__(self, path):\n\"\"\"Charge l'image de r\u00e9f\u00e9rence et cr\u00e9e une surface sur laquelle on peut dessiner.\"\"\"\n        pygame.init()\n        self.ref = pygame.surfarray.pixels3d(pygame.image.load(path))\n        w, h, d = self.ref.shape\n        self.screen = pygame.Surface((w, h))\n        self.screen.fill((255, 255, 255))\n\n        self.population = []\n\n    def draw(self, organism):\n\"\"\"Dessine un organisme en exprimant chaque g\u00e8ne.\"\"\"\n        w, h, d = self.ref.shape\n        screen = self.screen.copy()\n        for gene in organism.chromosome:\n            x, y, size, *hsl = gene\n            position = (int(x * w), int(y * h))\n            c = tuple(map(lambda x: int(255 * x), Color(hsl=hsl).rgb))\n            pygame.draw.circle(screen, c, position, int((size * 0.3 + 0.01) * w))\n        return screen\n\n    def spawn(self, pop_size=30, complexity=10):\n\"\"\"G\u00e9n\u00e8re une nouvelle population avec `complexity` g\u00e8nes dans chaque membre.\"\"\"\n        for i in range(pop_size):\n            organism = Organism(random((complexity, 6)))\n            self.population.append(organism) \n            self.calc_fitness(organism)\n        self.population = sorted(self.population, key=lambda x: -x.fitness)\n\n    def calc_fitness(self, organism):\n\"\"\"Calcule la forme physique d'un g\u00e8ne en le dessinant et en le comparant \u00e0 la r\u00e9f\u00e9rence.\"\"\"\n        screen = self.draw(organism)\n        diff = pygame.surfarray.pixels3d(screen) - self.ref\n        organism.fitness = -np.mean(np.abs(diff)) - 1e-5 * organism.chromosome.size\n        organism.visual = screen\n\n    def get_child(self, a, b):\n\"\"\"Croit un nouvel organisme en m\u00e9langeant les g\u00e8nes de longueur commune, en privil\u00e9giant le premier parent.\"\"\"\n        new_genes = []\n        n_a, n_b = a.chromosome.shape[0], b.chromosome.shape[0]\n        for i in range(max(n_a, n_b)):\n            if i &lt; n_a and i &lt; n_b:\n                if random() &lt; 0.7:\n                    new_genes.append(a.chromosome[i, :])\n                else:\n                    new_genes.append(b.chromosome[i, :])\n            elif i &lt; n_a:\n                new_genes.append(a.chromosome[i, :])\n            else:\n                if random() &lt; 0.3:\n                    new_genes.append(b.chromosome[i, :])\n            chromosome = np.array(new_genes)\n        o = Organism(chromosome)\n        self.calc_fitness(o)\n        return o\n\n    def save(self, path):\n\"\"\"Enregistre la population dans un fichier JSON.\"\"\"\n        out = [o.chromosome.tolist() for o in self.population]\n        with open(path, \"w\") as f:\n            json.dump(out, f)\n\n    def load(self, path):\n\"\"\"Charge la population \u00e0 partir d'un fichier JSON.\"\"\"\n        with open(path) as f:\n            inp = json.load(f)\n        self.population = [Organism(np.array(x)) for x in inp]\n        for o in self.population:\n            self.calc_fitness(o)\n\n    def mutate_and_pick(self, organism, rate, scale, add, attempts=10):\n\"\"\" Muter l'organisme un certain nombre de fois pour essayer d'obtenir quelque chose de meilleur \"\"\"\n        for i in range(attempts):\n            o = organism.mutate(rate=rate, scale=scale, add=add)\n            self.calc_fitness(o)\n            if o.fitness &gt; organism.fitness:\n                return o\n        return organism\n\n    def step(self, time, outdir, rate=0.01, scale=0.1, add=0.3):\n\"\"\" Avancer dans le temps en cr\u00e9ant des enfants, en les mutant, puis en laissant les plus aptes survivre \"\"\"\n\n        new_orgs = []\n        weights = 1 - np.linspace(0, 0.2, len(self.population))\n        for i in range(len(self.population)):\n            a, b = choice(self.population, 2, replace=True, p=weights / weights.sum())\n            child = self.get_child(a, b)\n            new_orgs.append(self.mutate_and_pick(child, rate, scale, add))\n\n        for o in new_orgs:\n            self.calc_fitness(o)\n        sorted_orgs = sorted(new_orgs, key=lambda x: -x.fitness)\n        self.population = sorted_orgs[:len(self.population)]\n\n        path = outdir + f\"{time:04d}.png\"\n        pygame.image.save(self.population[0].visual, path)\n        self.save(outdir + \"save.json\")\n</code></pre>"},{"location":"projects/Painting%20Vermeer/#faire-evoluer-la-population-dorganismes","title":"Faire Evoluer la population d'organismes","text":"<p>evolve</p> <p>La fonction <code>evolve</code> effectue l'\u00e9volution de la population d'organismes en utilisant les param\u00e8tres de mutation fournis.</p> <p>La fonction commence par cr\u00e9er une instance de la classe <code>Population</code> en fournissant le chemin d'acc\u00e8s \u00e0 l'image de r\u00e9f\u00e9rence. Ensuite, elle cr\u00e9e un r\u00e9pertoire de sortie pour enregistrer les images g\u00e9n\u00e9r\u00e9es au cours de l'\u00e9volution.</p> <p>Si une sauvegarde de population existe d\u00e9j\u00e0, elle est charg\u00e9e \u00e0 partir du fichier JSON correspondant. Le num\u00e9ro de l'\u00e9tape de d\u00e9part est \u00e9galement d\u00e9termin\u00e9 en se basant sur le nom du dernier fichier d'image enregistr\u00e9.</p> <p>Si aucune sauvegarde de population n'existe, une population initiale est g\u00e9n\u00e9r\u00e9e en appelant la m\u00e9thode spawn de l'instance de <code>Population</code>.</p> <p>Ensuite, la boucle principale de l'\u00e9volution d\u00e9marre, it\u00e9rant sur le nombre d'\u00e9tapes sp\u00e9cifi\u00e9. \u00c0 chaque \u00e9tape, la m\u00e9thode step de l'instance de <code>Population</code> est appel\u00e9e pour effectuer une it\u00e9ration de l'\u00e9volution. Les param\u00e8tres de mutation (rate, scale, add_chance) sont transmis \u00e0 cette m\u00e9thode.</p> <p>L'image du meilleur organisme de chaque \u00e9tape est enregistr\u00e9e dans le r\u00e9pertoire de sortie, et la population actuelle est sauvegard\u00e9e dans un fichier JSON.</p> <pre><code>def evolve(rate, scale, add_chance, steps=700000):\n    pop = Population(\"/content/test.jpg\")\n    outdir = f\"genetic2/output/\"\n    os.makedirs(outdir, exist_ok=True)\n    save = outdir + \"save.json\"\n\n    # Chargement de la population pr\u00e9c\u00e9demment sauvegard\u00e9e si elle existe\n    if os.path.exists(save):\n        pop.load(save)\n        start = int(sorted(os.listdir(outdir))[-2][:-4]) * 2\n    else:\n        # G\u00e9n\u00e9ration initiale de la population\n        pop.spawn(complexity=20)\n        start = 0\n\n    # \u00c9volution de la population pendant le nombre d'\u00e9tapes sp\u00e9cifi\u00e9\n    for i in range(start, steps):\n        pop.step(i, outdir, rate=rate, scale=scale, add=add_chance)\n</code></pre>"},{"location":"projects/Painting%20Vermeer/#executer-le-processus-devolution-de-la-population-dorganismes","title":"Ex\u00e9cuter le processus d'\u00e9volution de la population d'organismes","text":"<p>evolve(0.01, 0.1, 0.01)</p> <p>La fonction <code>evolve(0.01, 0.1, 0.01)</code> ex\u00e9cute le processus d'\u00e9volution de la population d'organismes en utilisant les param\u00e8tres suivants :</p> <p>Taux de mutation : 0,01 (1% de chance de mutation)</p> <p>\u00c9chelle (scale) : 0,1 (distribution normale avec un \u00e9cart-type de 0,1)</p> <p>Chance d'ajout ou de suppression : 0,01 (1% de chance d'ajout ou de suppression de g\u00e8nes)</p> <ul> <li> <p> Cela signifie que lors de chaque it\u00e9ration de l'\u00e9volution, les organismes de la population seront soumis \u00e0 des mutations avec une probabilit\u00e9 de 0,01 (1% de chance). Les mutations consistent \u00e0 modifier les valeurs des g\u00e8nes des organismes. L'\u00e9chelle de mutation est d\u00e9finie \u00e0 0,1, ce qui signifie que les modifications de g\u00e8nes seront tir\u00e9es d'une distribution normale avec un \u00e9cart-type de 0,1.</p> </li> <li> <p> De plus, il y a une probabilit\u00e9 de 0,01 (1% de chance) d'ajouter ou de supprimer des g\u00e8nes lors de la mutation des organismes.</p> </li> <li> <p> Ces param\u00e8tres contr\u00f4lent le niveau de diversit\u00e9 g\u00e9n\u00e9tique et de variation au sein de la population, ainsi que la probabilit\u00e9 de modifications importantes des caract\u00e9ristiques des organismes au fil des \u00e9tapes de l'\u00e9volution.</p> </li> </ul> <pre><code>evolve(0.01, 0.1, 0.01)\n</code></pre> Image de test (Input) <p></p> R\u00e9sultat final (Output) <p></p>"},{"location":"projects/Painting%20Vermeer/#conclusion","title":"Conclusion","text":"<p>Conclusion</p> <p>Vous pouvez observer une am\u00e9lioration des images g\u00e9n\u00e9r\u00e9es \u00e0 chaque it\u00e9ration. Cependant, en raison des contraintes de ressources, je n'ai pas pu poursuivre l'ex\u00e9cution du code car j'utilisais Google Colab, qui est limit\u00e9 en termes de temps. Pour obtenir le r\u00e9sultat final de mon algorithme, il serait n\u00e9cessaire de souscrire \u00e0 Google Colab Pro.</p>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/","title":"Reciprocal n-body Collision Avoidance","text":""},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#importer-les-packages","title":"Importer les Packages","text":"<ul> <li> <p>NumPy : NumPy est une biblioth\u00e8que Python populaire pour le calcul scientifique qui fournit des structures de donn\u00e9es pour la repr\u00e9sentation de tableaux multidimensionnels et des fonctions pour manipuler ces tableaux.</p> </li> <li> <p>Matplotlib : Matplotlib est une biblioth\u00e8que en Python utilis\u00e9e pour tracer des graphiques et des visualisations.</p> </li> <li> <p>heapq : heapq est un module Python qui impl\u00e9mente les algorithmes d'heaps ou de tas pour des structures de donn\u00e9es.</p> </li> <li> <p>math : Le module math en Python fournit des fonctions math\u00e9matiques courantes, telles que les fonctions trigonom\u00e9triques, exponentielles, logarithmiques, etc.</p> </li> <li> <p>CVXOPT : CVXOPT est une biblioth\u00e8que open source Python pour l'optimisation convexe. Elle est utilis\u00e9e pour r\u00e9soudre des probl\u00e8mes d'optimisation convexe tels que la programmation lin\u00e9aire, la programmation quadratique, la programmation semi-d\u00e9finie, la programmation convexe et autres. Elle fournit des solveurs rapides et pr\u00e9cis pour les probl\u00e8mes d'optimisation convexe, y compris des interfaces pour les solvers externes.</p> </li> <li> <p>random : The random module in Python provides a suite of functions for generating random numbers.</p> </li> <li> <p>time : Le module time est un module Python qui fournit diverses fonctions permettant de manipuler le temps.</p> </li> <li> <p>cv2 : cv2 is a library for computer vision and image processing. It is a Python wrapper for OpenCV (Open Source Computer Vision), which is a C++ library that includes numerous computer vision algorithms.</p> </li> <li> <p>IPython : La biblioth\u00e8que IPython fournit un certain nombre d'outils pour faciliter le d\u00e9veloppement et l'analyse de donn\u00e9es en Python.</p> </li> <li> <p>tqdm : tqdm is a Python package that provides a progress bar visualization for iterative tasks, making it easy to see how far along a task is and how much longer it is expected to take.</p> </li> </ul> Packages<pre><code>import numpy\nfrom numpy.linalg import norm\nfrom numpy import dot,array\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Rectangle, Circle\nimport matplotlib.patches as patches\nfrom pylab import show,imshow\nimport heapq\nfrom math import *\nimport cvxopt\nfrom cvxopt import matrix,solvers\nimport random\nimport time\nimport os\nimport matplotlib.animation as animation\nimport cv2\nfrom IPython import display\nfrom tqdm import tqdm\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#initialiser-la-geometrie","title":"Initialiser la g\u00e9om\u00e9trie","text":""},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#draw","title":"draw","text":"<p>On commence par d\u00e9finir la fonction <code>draw</code> qui prend plusieurs arguments en entr\u00e9e et qui trace une sc\u00e8ne avec des agents et des obstacles.</p> <p>Les arguments en entr\u00e9e sont:</p> <p><code>Ex</code> : une liste des sorties de la sc\u00e8ne</p> <p><code>Obs</code> : une liste des obstacles rectangulaires</p> <p><code>Obs_cir</code> : une liste des obstacles circulaires</p> <p><code>scene</code> : une paire (L, l) qui repr\u00e9sente les dimensions de la sc\u00e8ne</p> <p><code>agents</code> : une liste d'agents, o\u00f9 chaque agent est repr\u00e9sent\u00e9 par sa position, sa taille et sa couleur</p> <p><code>t</code> : temps de simulation</p> <p><code>savepath</code> : le chemin pour enregistrer la figure g\u00e9n\u00e9r\u00e9e</p> <p><code>play</code> : un bool\u00e9en qui sp\u00e9cifie si l'animation doit \u00eatre affich\u00e9e ou non</p> <p>La fonction commence par cr\u00e9er une figure et un axe avec une taille d\u00e9termin\u00e9e par la dimension de la sc\u00e8ne. Ensuite, elle dessine les obstacles, les sorties et les agents sur la figure. Les obstacles rectangulaires sont repr\u00e9sent\u00e9s par des rectangles noirs, les obstacles circulaires par des cercles noirs, les sorties par des rectangles orange et les agents par des cercles de couleur.</p> <p>Enfin, la fonction sauvegarde la figure \u00e0 l'emplacement sp\u00e9cifi\u00e9 par \"savepath\". Si \"play\" est faux, la figure est ferm\u00e9e.</p> draw<pre><code>def draw(Ex, Obs, Obs_cir, scene, agents, t, savepath, play = False):\n\n    L , l = scene\n    ratio = l/L\n    c = 10\n\n    fig, ax = plt.subplots(figsize=(c/ratio,c))\n\n    title = ax.text(0.5, 1.05, \"Temps de simulation : %s s \\n Nombre des agents : %s\" %(t,len(agents)), \n                    transform=ax.transAxes, ha=\"center\", size=20)\n\n    #Draw the environment\n    plt.plot([0, L], [0, 0], 'white')\n    plt.plot([L, L], [0, l], 'white')\n    plt.plot([L, 0], [l,l], 'white')\n    plt.plot([0,0], [l,0], 'white')\n\n\n    #Draw Obstacle\n    for obs in Obs:\n        rect = Rectangle(obs.position, obs.width, obs.height)\n        rect.set_color('black')\n        ax.add_patch(rect)\n\n    #Draw Obstacle Cir\n    for obs in Obs_cir:\n        circle = Circle(obs.position, obs.rayon)\n        circle.set_color('black')\n        ax.add_patch(circle)\n\n    #Draw exits\n    for e in Ex:\n        rect = Rectangle(e.position, e.width, e.height)\n        rect.set_color('orange')\n        ax.add_patch(rect)\n\n    #Draw agents\n    for agent in agents:\n        x,y = agent.position\n        circle = Circle((x,y), agent.size)\n        circle.set_color(agent.color)\n        ax.add_patch(circle)\n\n    plt.xticks(fontsize=20)\n    plt.yticks(fontsize=20)\n\n    fig.savefig(savepath)\n\n    if not play:\n        plt.close()\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#record_video","title":"record_video","text":"<p>La fonction appel\u00e9e <code>record_video</code> prend un argument optionnel speed (dont la valeur par d\u00e9faut est 25). Le but de cette fonction est de cr\u00e9er une vid\u00e9o \u00e0 partir d'une s\u00e9quence d'images sauvegard\u00e9es dans un r\u00e9pertoire, et de sauvegarder le fichier vid\u00e9o r\u00e9sultant dans le r\u00e9pertoire de travail actuel. Les arguments pass\u00e9s \u00e0 cette fonction sont les suivants :</p> <p><code>speed</code> : une valeur enti\u00e8re repr\u00e9sentant le nombre d'images par seconde de la vid\u00e9o r\u00e9sultante (c'est-\u00e0-dire le taux de rafra\u00eechissement de la vid\u00e9o).</p> <p>La fonction commence par imprimer un message indiquant qu'elle commence l'enregistrement de la vid\u00e9o. Ensuite, elle lit la premi\u00e8re image de la s\u00e9quence d'images pour d\u00e9terminer les dimensions de la vid\u00e9o.</p> <p>Elle cr\u00e9e ensuite un objet VideoWriter en utilisant la m\u00e9thode cv2.VideoWriter d'OpenCV, en sp\u00e9cifiant le nom du fichier de sortie, le codec vid\u00e9o (dans ce cas XVID), le taux de rafra\u00eechissement et les dimensions de la vid\u00e9o (bas\u00e9es sur les dimensions de la premi\u00e8re image).</p> <p>Ensuite, elle boucle sur les images restantes de la s\u00e9quence et ajoute chacune \u00e0 la vid\u00e9o \u00e0 l'aide de la m\u00e9thode video.write(). Les images sont lues en utilisant la m\u00e9thode cv2.imread() d'OpenCV, qui lit une image \u00e0 partir d'un chemin de fichier sp\u00e9cifi\u00e9.</p> <p>Enfin, la fonction nettoie toutes les fen\u00eatres qui ont pu \u00eatre cr\u00e9\u00e9es pendant le processus et lib\u00e8re l'objet vid\u00e9o. Elle affiche un message indiquant que la vid\u00e9o a \u00e9t\u00e9 sauvegard\u00e9e.</p> record_video<pre><code>def record_video(speed = 25):\n    print('Recording video ...')\n    frame = cv2.imread('DossierImages/simulation' + str(10) + '.jpg')\n    height, width, layers = frame.shape\n\n    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n    video = cv2.VideoWriter('video.avi', fourcc, speed, (width,height))\n\n    for k in range(N_iter):\n        video.write(cv2.imread('DossierImages/simulation' + str(k+1) + '.jpg'))\n\n    cv2.destroyAllWindows()\n    video.release()\n    print('Video saved.')\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#generate_indivn","title":"generate_indiv(N)","text":"<p>La fonction <code>generate_indiv(N)</code> cr\u00e9e une liste de N agents en v\u00e9rifiant qu'ils ne se chevauchent pas et ne traversent pas les obstacles. Voici les \u00e9tapes principales :</p> <ul> <li> <p> La fonction d\u00e9finit la taille de la sc\u00e8ne, ainsi que des variables pour la distance minimale entre les agents et pour le rayon de chaque agent.</p> </li> <li> <p> La fonction cr\u00e9e une liste vide L qui contiendra les agents, puis elle commence une boucle qui s'arr\u00eatera quand il y aura N agents dans la liste L.</p> </li> <li> <p> \u00c0 chaque it\u00e9ration de la boucle, la fonction g\u00e9n\u00e8re une position al\u00e9atoire pour un nouvel agent en utilisant des fonctions al\u00e9atoires et l'ajoute \u00e0 une liste temporaire q, qui contient les positions de tous les agents d\u00e9j\u00e0 cr\u00e9\u00e9s, ainsi que les rayons de ces agents, qui sont stock\u00e9s dans la liste R.</p> </li> <li> <p> Ensuite, la fonction v\u00e9rifie s'il y a une collision entre le nouvel agent et les agents d\u00e9j\u00e0 cr\u00e9\u00e9s. Si c'est le cas, la variable choc est d\u00e9finie sur True, ce qui signifie qu'il y a eu une collision et que le nouvel agent ne sera pas ajout\u00e9 \u00e0 la liste L.</p> </li> <li> <p> Ensuite, la fonction v\u00e9rifie si le nouvel agent entre en collision avec un obstacle. Si c'est le cas, la variable choc est d\u00e9finie sur True.</p> </li> <li> <p> Si le nouvel agent ne provoque pas de collision, il est ajout\u00e9 \u00e0 la liste L.</p> </li> <li> <p> Lorsque N agents ont \u00e9t\u00e9 cr\u00e9\u00e9s et ajout\u00e9s \u00e0 la liste L, la fonction retourne cette liste.</p> </li> </ul> generate_indiv<pre><code>def generate_indiv(N):\n\n    def rand_float_range(start, end):\n        return random.random() * (end - start) + start\n\n    a , b = size_scene\n    dst = 0.2\n    r = 0.2\n    L = list()\n\n    while len(L) &lt; N:\n\n        choc = False\n\n        q = [agent.position for agent in L]\n        R = [agent.size for agent in L]\n\n        x = rand_float_range(int(0),int(a))\n        y = rand_float_range(int(0),int(b))\n\n        q.append([x,y])\n        R.append(r)\n\n\n        for j in range(len(q)-1):\n            if dist(q[-1], q[j]) - (R[-1]+R[j]) &lt;= dst:\n                choc = True\n                break\n\n        #chocs obstacle\n        for obstacle in obstacles_cir:\n            [a0, b0], rayon = obstacle.position, obstacle.rayon\n            if (x-a0)**2 + (y-b0)**2 &lt; (rayon+3)**2 : choc = True\n\n        for obstacle in obstacles:\n            [a0, b0], w, l = obstacle.position, obstacle.width, obstacle.height\n            a1, b1 = a0 + w , b0 + l\n\n            if (a0&lt;=x&lt;=a1 and b0-r-0.5&lt;=y&lt;=b1+r+0.5) or (b0&lt;=y&lt;=b1 and a0-r-0.5&lt;=x&lt;=a1+r+0.5): choc = True\n            elif distance_vecteur_obs([x,y] , r, obstacle)[0] &lt; 0.5: choc = True\n\n        if not choc:\n            agent = myAgent((x,y))\n            agent.size = r\n            L.append(agent)\n\n    return L\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#maximini-plot_directions","title":"maxiMini &amp; plot_directions","text":"<p>La premi\u00e8re fonction, nomm\u00e9e <code>maxiMini(FX,FY)</code>, prend en entr\u00e9e deux listes FX et FY, contenant des valeurs de directions. Cette fonction parcourt les deux listes et recherche la valeur maximale et la valeur minimale des directions dans chaque liste. Elle retourne ensuite ces deux valeurs.</p> <p>La deuxi\u00e8me fonction, nomm\u00e9e <code>plot_directions(FX,FY)</code>, prend \u00e9galement en entr\u00e9e deux listes FX et FY. Cette fonction affiche deux graphiques c\u00f4te \u00e0 c\u00f4te : un pour les directions selon X et un pour les directions selon Y. Les directions sont repr\u00e9sent\u00e9es par des couleurs sur chaque graphique, et les couleurs correspondent \u00e0 des valeurs. Les valeurs minimales et maximales sont obtenues en appelant la fonction <code>maxiMini(FX,FY)</code>. Les graphiques sont affich\u00e9s \u00e0 l'aide de la biblioth\u00e8que Matplotlib. Enfin, cette fonction retourne les graphiques affich\u00e9s.</p> <p>En r\u00e9sum\u00e9, ces deux fonctions permettent de visualiser les directions de mouvement \u00e0 partir de listes de directions selon X et Y.</p> maxiMini &amp; plot_directions<pre><code>def maxiMini(FX,FY):\n  maxi = 0\n  Mini = 0\n  for i in range(n):\n    for j in range(len(FX[0])):\n      fx , fy = FX[i][j] , FY[i][j]\n      if fx != float('inf') and fx != -float('inf') and fy != float('inf') and fy != -float('inf') and not isnan(fx) and not isnan(fy):\n        if fx&gt;maxi :\n          maxi = fx\n        if fy&gt;maxi :\n          maxi = fy\n        if fx&lt;Mini : \n          Mini = fx\n        if fy&lt;Mini :\n          Mini = fy\n\n  return maxi , Mini\n\ndef plot_directions(FX,FY):\n  fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15,15))\n  Z = [FX, FY]\n  text = ['Directions selon X', 'Directions selon Y']\n  maxi , Mini = maxiMini(FX,FY)\n\n  for ax, i in zip(axes.flat, range(2)):\n      im = ax.imshow(Z[i], interpolation=\"bicubic\", origin=\"upper\", vmin=Mini, vmax=maxi)\n      ax.title.set_text(text[i])\n\n  fig.subplots_adjust(right=0.8)\n  cbar_ax = fig.add_axes([0.85, 0.35, 0.05, 0.3])\n  fig.colorbar(im, cax=cbar_ax)\n\n  plt.show()\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#exit","title":"Exit","text":"<p>Ce code d\u00e9finit une classe <code>Exit</code> qui repr\u00e9sente une sortie. La classe poss\u00e8de un constructeur (init) qui prend en argument une position, une largeur et une hauteur de la sortie. La position est un tuple de deux \u00e9l\u00e9ments repr\u00e9sentant les coordonn\u00e9es (x, y) du coin sup\u00e9rieur gauche de la sortie.</p> <p>Le constructeur initialise les attributs position, width et height de la classe avec les valeurs pass\u00e9es en argument.</p> Exit<pre><code>class Exit:\n\n    def __init__(self,position,width,height):\n\n        self.position = position\n        self.width = width\n        self.height = height\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#obstacle","title":"Obstacle","text":"<p>La classe <code>Obstacle</code> a pour but de repr\u00e9senter un obstacle dans une simulation. Elle poss\u00e8de trois attributs : position, width et height, qui correspondent respectivement \u00e0 la position de l'obstacle et \u00e0 sa largeur et hauteur.</p> <p>La m\u00e9thode repr de la classe est une m\u00e9thode sp\u00e9ciale qui renvoie une cha\u00eene de caract\u00e8res repr\u00e9sentant l'objet. Dans ce cas pr\u00e9cis, elle renvoie une cha\u00eene de caract\u00e8res contenant la position de l'obstacle ainsi que les coordonn\u00e9es de ses coins (en supposant que la position correspond au coin en bas \u00e0 gauche).</p> Obstacle<pre><code>class Obstacle():\n\n    def __init__(self, position,width,height):\n\n        self.position=position\n        self.width=width\n        self.height=height\n\n    def __repr__(self):\n        return 'Obstacle'+'\\n'+'DL:'+str(self.position)+'DR:'+str((self.position[0]+self.width,self.position[1]))+'UR:'+str((self.position[0]+self.width,self.position[1]+self.height))+'UL:'+str((self.position[0]+self.width,self.position[1]))\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#obstacle_cir","title":"Obstacle_Cir","text":"<p>Ce code d\u00e9finit une classe <code>Obstacle_Cir</code> qui repr\u00e9sente un obstacle circulaire.</p> <p>La classe a un constructeur init qui prend deux param\u00e8tres, position et rayon, qui sont utilis\u00e9s pour initialiser les attributs de l'objet. L'attribut position est un tuple qui repr\u00e9sente la position du centre de l'obstacle sur l'espace de simulation et l'attribut rayon est un nombre flottant qui repr\u00e9sente le rayon de l'obstacle.</p> Obstacle_Cir<pre><code>class Obstacle_Cir():\n\n    def __init__(self, position,rayon):\n        self.position=position\n        self.rayon=rayon\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#fast-marching","title":"Fast Marching","text":"<p>PriorityQueue</p> <p>Cette classe est une impl\u00e9mentation d'une file de priorit\u00e9 (ou heap) en utilisant la biblioth\u00e8que heapq.</p> <p>init(self) : Constructeur de la classe qui initialise la file de priorit\u00e9 et un index pour suivre l'\u00e9l\u00e9ment courant.</p> <p>pop(self) : Cette m\u00e9thode supprime et renvoie l'\u00e9l\u00e9ment le plus petit de la file de priorit\u00e9.</p> <p>remove(self, nodeId) : Cette m\u00e9thode prend un noeud (identifi\u00e9 par nodeId) en entr\u00e9e et supprime cet \u00e9l\u00e9ment de la file de priorit\u00e9.</p> <p>iter(self) : Cette m\u00e9thode renvoie l'it\u00e9rateur sur l'instance de la file de priorit\u00e9.</p> <p>str(self) : Cette m\u00e9thode renvoie une repr\u00e9sentation sous forme de cha\u00eene de la file de priorit\u00e9.</p> <p>append(self, node) : Cette m\u00e9thode ajoute un \u00e9l\u00e9ment dans la file de priorit\u00e9.</p> <p>contains(self, key) : Cette m\u00e9thode renvoie True si la cl\u00e9 est pr\u00e9sente dans la file de priorit\u00e9, False sinon.</p> <p>eq(self, other) : Cette m\u00e9thode v\u00e9rifie si deux files de priorit\u00e9 sont \u00e9gales.</p> <p>getitem(self, nodeId) : Cette m\u00e9thode renvoie l'\u00e9l\u00e9ment correspondant \u00e0 l'ID du n\u0153ud donn\u00e9.</p> <p>clear(self) : Cette m\u00e9thode supprime tous les \u00e9l\u00e9ments de la file de priorit\u00e9.</p> <p>len(self) : Cette m\u00e9thode renvoie la longueur de la file de priorit\u00e9.</p> <p>next = next : Cette m\u00e9thode est utilis\u00e9e pour rendre la file de priorit\u00e9 iterable.</p> <pre><code>class PriorityQueue():\n\n\n    def __init__(self):\n        self.queue = []\n        self.current = 0\n\n    def pop(self):\n        return heapq.heappop(self.queue)\n\n    def remove(self, nodeId):\n        for i in range(len(self.queue)):\n            if self.queue[i][1]==nodeId:\n                self.queue.pop(i)\n                break;\n\n    def __iter__(self):\n        return self\n\n    def __str__(self):\n        return 'PQ:[%s]'%(', '.join([str(i) for i in self.queue]))\n\n    def append(self, node):\n        heapq.heappush(self.queue,node)\n\n    def __contains__(self, key):\n        self.current = 0\n        return key in [n for _,n in self.queue]\n\n    def __eq__(self, other):\n        self.curent = 0\n        return self == other\n\n    def __getitem__(self, nodeId):\n        for element in self.queue:\n            if element[1]==nodeId:\n                return element\n        return None\n\n    def clear(self):\n        self.queue = []\n\n    def __len__(self):\n        return len(self.queue)\n\n    __next__ = next\n</code></pre> <p>GridGraph</p> <p>Ce code d\u00e9finit une classe <code>GridGraph</code> qui repr\u00e9sente une grille. Cette grille est utilis\u00e9e pour simuler un environnement dans lequel une ou plusieurs entit\u00e9s se d\u00e9placent, en utilisant un algorithme de calcul de chemin pour d\u00e9terminer le chemin optimal entre deux points.</p> <p>La classe est initialis\u00e9e avec deux param\u00e8tres, size_scene qui est un tuple repr\u00e9sentant la taille de la sc\u00e8ne (la grille) en unit\u00e9s arbitraires, et precision qui d\u00e9termine le nombre de subdivisions dans la grille. La pr\u00e9cision est utilis\u00e9e pour d\u00e9finir la taille de chaque case dans la grille.</p> <p>La grille est mod\u00e9lis\u00e9e par deux matrices, indicator_map et distances. indicator_map est initialis\u00e9e avec des valeurs de 1 pour chaque case de la grille, et sera modifi\u00e9e plus tard pour inclure des obstacles et des sorties. distances est initialis\u00e9e avec des valeurs inf pour chaque case de la grille.</p> <p>La m\u00e9thode get_neighbours est utilis\u00e9e pour renvoyer les voisins d'un n\u0153ud donn\u00e9, repr\u00e9sent\u00e9 par un tuple d'entiers (x, y) indiquant les coordonn\u00e9es du n\u0153ud sur la grille.</p> <p>La m\u00e9thode to_node est utilis\u00e9e pour convertir des coordonn\u00e9es r\u00e9elles en coordonn\u00e9es de n\u0153uds sur la grille.</p> <p>La m\u00e9thode prepare_graph_for_fast_marching est utilis\u00e9e pour modifier indicator_map en y ajoutant des obstacles et des sorties, afin de pr\u00e9parer la grille pour l'algorithme de calcul de chemin. Les obstacles sont d\u00e9finis comme des rectangles ou des cercles, repr\u00e9sent\u00e9s par des objets Obstacle ou ObstacleCir, et les sorties sont repr\u00e9sent\u00e9es par des objets Exit.</p> <pre><code>class GridGraph:\n\n    global OBSTACLE\n    global EXIT\n    OBSTACLE = 0\n    EXIT = 2\n\n    def __init__(self,size_scene,precision):\n        self.precision = precision\n        self.horizontal_size = int(size_scene[0]*precision)+1\n        self.vertical_size = int(size_scene[1]*precision)+1\n        self.indicator_map = numpy.ones((self.vertical_size,self.horizontal_size))\n        self.distances = numpy.ones((self.vertical_size,self.horizontal_size))*float('inf')\n\n    def get_neighbours(self,node):\n        result = {};\n        if node[1]&lt;self.horizontal_size-1:\n            result['x+1']=(node[0],node[1]+1);\n        if node[1]&gt;0:\n            result['x-1']=(node[0],node[1]-1);\n        if node[0]&lt;self.vertical_size-1:\n            result['y+1']=(node[0]+1,node[1]);\n        if node[0]&gt;0:\n            result['y-1']=(node[0]-1,node[1]);\n        return result;\n\n    def to_node(self,coordinates):\n        return (int(coordinates[1]*self.precision),int(coordinates[0]*self.precision))\n\n    def prepare_graph_for_fast_marching(self,obstacles, obstacles_cir, exits):\n        for obstacle in obstacles:\n            dl = (obstacle.position[0],obstacle.position[1])\n            ur = (obstacle.position[0]+obstacle.width,obstacle.position[1]+obstacle.height)\n\n            for x in range(self.to_node(dl)[0]+1,self.to_node(ur)[0]):\n                for y in range(self.to_node(dl)[1]+1,self.to_node(ur)[1]):\n                    if x&gt;=0 and x&lt;self.indicator_map.shape[0] and y&gt;=0 and y&lt;self.indicator_map.shape[1]:\n                        self.indicator_map[x,y]=OBSTACLE\n\n        for obstacle_cir in obstacles_cir:\n            dl = (obstacle_cir.position[0] - obstacle_cir.rayon , obstacle_cir.position[1] - obstacle_cir.rayon)\n            ur = (obstacle_cir.position[0] + obstacle_cir.rayon , obstacle_cir.position[1] + obstacle_cir.rayon)\n\n            for x in range(self.to_node(dl)[0]+1,self.to_node(ur)[0]):\n                for y in range(self.to_node(dl)[1]+1,self.to_node(ur)[1]):\n                    if x&gt;=0 and x&lt;self.indicator_map.shape[0] and y&gt;=0 and y&lt;self.indicator_map.shape[1]:\n                        if (x/self.precision - obstacle_cir.position[1])**2 + (y/self.precision - obstacle_cir.position[0])**2 &lt;= obstacle_cir.rayon**2:\n                            self.indicator_map[x,y]=OBSTACLE\n\n        for exit_ in exits:\n            dl = (exit_.position[0],exit_.position[1])\n            ur = (exit_.position[0]+exit_.width,exit_.position[1]+exit_.height)\n            for x in range(self.to_node(dl)[0],self.to_node(ur)[0]+1):\n                for y in range(self.to_node(dl)[1],self.to_node(ur)[1]+1):\n                    if x&gt;=0 and x&lt;self.indicator_map.shape[0] and y&gt;=0 and y&lt;self.indicator_map.shape[1]:\n                        self.indicator_map[x,y]=EXIT\n</code></pre> <p>fast_marching_method</p> <p>Le code prend en entr\u00e9e un graphe et un point de d\u00e9part et retourne une carte de distance de tous les n\u0153uds du graphe au point de d\u00e9part.</p> <p>Le code commence par d\u00e9finir une fonction calculus_distance qui prend en entr\u00e9e un n\u0153ud, un graphe et des poids et renvoie la distance de ce n\u0153ud au point de d\u00e9part en utilisant la m\u00e9thode de marche rapide. Cette m\u00e9thode calcule la distance en utilisant la distance aux n\u0153uds voisins pond\u00e9r\u00e9e par des poids qui d\u00e9pendent de la g\u00e9om\u00e9trie du probl\u00e8me.</p> <p>Ensuite, le code initialise une file de priorit\u00e9 frontier, qui contiendra les n\u0153uds \u00e0 explorer, et une liste explored qui contiendra les n\u0153uds d\u00e9j\u00e0 explor\u00e9s. Les poids initiaux des n\u0153uds sont stock\u00e9s dans weights. Les points d'arriv\u00e9e sont trouv\u00e9s dans la carte indicator_map et ajout\u00e9s \u00e0 la file de priorit\u00e9 avec une distance initiale de 0. Les poids des points d'arriv\u00e9e sont \u00e9galement initialis\u00e9s \u00e0 0.</p> <p>La boucle principale commence avec l'extraction d'un n\u0153ud de la file de priorit\u00e9 frontier. La distance \u00e0 ce n\u0153ud est stock\u00e9e dans weights. Les voisins du n\u0153ud sont explor\u00e9s, et si un voisin n'a pas d\u00e9j\u00e0 \u00e9t\u00e9 explor\u00e9 et appartient \u00e0 la grille (indiqu\u00e9 par la carte indicator_map), sa distance au point de d\u00e9part est calcul\u00e9e en utilisant la m\u00e9thode calculus_distance. Si le voisin n'est pas d\u00e9j\u00e0 dans la file de priorit\u00e9, il est ajout\u00e9 avec sa nouvelle distance, sinon, si sa distance calcul\u00e9e est inf\u00e9rieure \u00e0 sa distance actuelle, sa distance et sa priorit\u00e9 dans la file de priorit\u00e9 sont mises \u00e0 jour. Les n\u0153uds explor\u00e9s sont ajout\u00e9s \u00e0 la liste explored.</p> <p>Une fois la file de priorit\u00e9 vid\u00e9e, la carte de distance est stock\u00e9e dans la variable distances de l'objet graphe et renvoy\u00e9e.</p> <pre><code>def fast_marching_method(graph,start):\n\n    def calculus_distance(node,graph,weights):\n        neighbours = graph.get_neighbours(node);\n        if 'y-1' in neighbours :\n            if 'y+1' in neighbours:\n                x1 = min(weights[neighbours['y-1']],weights[neighbours['y+1']]);\n            else :\n                x1 = weights[neighbours['y-1']];\n        else :\n            if 'y+1' in neighbours:\n                x1 = weights[neighbours['y+1']];\n        if 'x-1' in neighbours:\n            if 'x+1' in neighbours:\n                x2 = min(weights[neighbours['x-1']],weights[neighbours['x+1']]);\n            else :\n                x2 = weights[neighbours['x-1']];\n        else :\n            if 'x+1' in neighbours:\n                x2 = weights[neighbours['x+1']];\n\n        if 2*h**2-(x1-x2)**2&gt;=0:\n            return (x1+x2+(2*h**2-(x1-x2)**2)**0.5)/2\n        else:\n            return min(x1,x2)+h\n\n\n    frontier = PriorityQueue();\n    weights = graph.distances;\n\n    explored = []\n\n    goals = numpy.where(graph.indicator_map==2)\n    goals_x = goals[0]\n    goals_y = goals[1]\n    for i in range(goals_x.size):\n        frontier.append([0,(goals_x[i],goals_y[i])])\n        weights[(goals_x[i],goals_y[i])] = 0\n\n\n    while frontier:\n        node = frontier.pop();\n        explored.append(node[1])\n        #if node[1]==start:\n        #   return weights\n        neighbours = graph.get_neighbours(node[1]);\n        for neighbour in neighbours.values():\n            if neighbour not in explored and graph.indicator_map[neighbour]:\n                if not neighbour in frontier:\n                    frontier.append([calculus_distance(neighbour,graph,weights),neighbour])\n                    weights[neighbour]=calculus_distance(neighbour,graph,weights)\n                elif weights[neighbour] &gt; calculus_distance(neighbour,graph,weights):\n                    frontier[neighbour][0]=calculus_distance(neighbour,graph,weights)\n                    weights[neighbour]=calculus_distance(neighbour,graph,weights)\n    graph.distances = weights\n</code></pre> <p>adjust_FM</p> <p>Ce code permet d'ajuster les fronts d'onde g\u00e9n\u00e9r\u00e9s par la m\u00e9thode de Fast Marching.</p> <p>Le code commence par initialiser deux listes vides, Lx_gauche et Lx_droite. Ces listes vont contenir les coordonn\u00e9es des points du front d'onde qui sont \u00e0 gauche ou \u00e0 droite d'un point infini ou ind\u00e9fini.</p> <p>Ensuite, le code parcourt les fronts d'onde et ajoute les coordonn\u00e9es des points \u00e0 la liste Lx_gauche ou Lx_droite si ces points sont \u00e0 gauche ou \u00e0 droite d'un point infini ou ind\u00e9fini. Il en fait de m\u00eame pour les coordonn\u00e9es des points du front d'onde qui sont en haut ou en bas d'un point infini ou ind\u00e9fini, qu'il ajoute aux listes Ly_haut et Ly_bas.</p> <p>Enfin, le code remplace les valeurs des points des fronts d'onde contenus dans les listes Lx_gauche, Lx_droite, Ly_haut et Ly_bas par les valeurs de leurs voisins les plus proches, en parcourant les listes et en acc\u00e9dant aux valeurs des tableaux FX et FY correspondant aux fronts d'onde en question.</p> <pre><code>def adjust_FM():\n\n    Lx_gauche = []\n    Lx_droite = []\n\n    for i in range(1,n):\n      for j in range(1,len(FX[0])-1):\n\n        u , v = FX[i][j] , FX[i][j+1]\n\n        if u == float('inf') or u == -float('inf'):\n          if v != float('inf') and v != -float('inf') and not isnan(v):\n            Lx_gauche.append((i,j))\n\n        if v == float('inf') or v == -float('inf'):\n          if u != float('inf') and u != -float('inf') and not isnan(u):\n            Lx_droite.append((i,j+1))\n\n    for cellule in Lx_gauche:\n      i, j = cellule\n      FX[i][j] = FX[i][j+1]\n\n    for cellule in Lx_droite:\n      i, j = cellule\n      FX[i][j] = FX[i][j-1]\n\n    Ly_haut = []\n    Ly_bas = []\n\n    for i in range(1,n-1):\n      for j in range(1,len(FY[0])):\n\n        u , v = FY[i][j] , FY[i+1][j]\n\n        if u == float('inf') or u == -float('inf'):\n          if v != float('inf') and v != -float('inf') and not isnan(v):\n            Ly_haut.append((i,j))\n\n        if v == float('inf') or v == -float('inf'):\n          if u != float('inf') and u != -float('inf') and not isnan(u):\n            Ly_bas.append((i+1,j))\n\n\n    for cellule in Ly_haut:\n      i, j = cellule\n      FY[i][j] = FY[i+1][j]\n\n    for cellule in Ly_bas:\n      i, j = cellule\n      FY[i][j] = FY[i-1][j]\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#myagent","title":"MyAgent","text":"<p>myAgent</p> <p>Ce code d\u00e9finit la classe <code>myAgent</code>, qui repr\u00e9sente un agent dans notre environnement de simulation. Chaque instance de cette classe contient les attributs suivants :</p> <p>position: un vecteur 2D repr\u00e9sentant la position de l'agent dans l'environnement.</p> <p>speed: un vecteur 2D repr\u00e9sentant la vitesse actuelle de l'agent.</p> <p>D_S: un vecteur 2D repr\u00e9sentant la direction d\u00e9sir\u00e9e de l'agent (c'est-\u00e0-dire la direction vers laquelle il souhaite se d\u00e9placer).</p> <p>size: la taille de l'agent.</p> <p>has_reached_exit: un bool\u00e9en qui indique si l'agent a atteint la sortie ou non.</p> <p>near_to_exit: un bool\u00e9en qui indique si l'agent est proche de la sortie ou non.</p> <p>masse: la masse de l'agent.</p> <p>color: la couleur de l'agent.</p> <p>La classe myAgent contient \u00e9galement plusieurs m\u00e9thodes :</p> <p>desired_direction: Cette m\u00e9thode calcule la direction d\u00e9sir\u00e9e de l'agent en fonction de la position actuelle de l'agent dans l'environnement et de la carte de flux (contenue dans les matrices FX et FY).</p> <p>update_D_S: Cette m\u00e9thode met \u00e0 jour le vecteur D_S en appelant la m\u00e9thode desired_direction.</p> <p>update_Speed: Cette m\u00e9thode met \u00e0 jour la vitesse de l'agent en fonction d'un vecteur de vitesse donn\u00e9 en argument.</p> <p>reach_exit: Cette m\u00e9thode v\u00e9rifie si l'agent a atteint l'une des sorties de l'environnement et met \u00e0 jour l'attribut has_reached_exit en cons\u00e9quence.</p> <p>update_Position: Cette m\u00e9thode met \u00e0 jour la position de l'agent en fonction d'un vecteur de position donn\u00e9 en argument et appelle la m\u00e9thode reach_exit pour mettre \u00e0 jour l'attribut has_reached_exit.</p> <pre><code>class myAgent():\n\n    def __init__(self, position):\n        self.position = numpy.array(position)\n        self.speed = (0,0)\n        self.D_S = (0,0)\n        self.size = 0.2\n        self.has_reached_exit = False\n        self.near_to_exit = False\n        self.masse = 80\n        self.color = 'red'\n\n    def desired_direction(self):\n        x, y = self.position\n        a, b = size_scene\n        n , m = int(x/h) , int((b-y)/h)\n        if n &lt; 0 : n = 0\n        if m &lt; 0 : m = 0\n        if n &gt; len(FX[0])-1 : n = len(FX[0])-1\n        if m &gt; len(FX)-1 : m = len(FX)-1\n        v = numpy.array((FX[m][n], FY[m][n]))\n        if norm(v)==0: return numpy.array((0,0))\n        return v / norm(v)\n\n    def update_D_S(self):\n        self.D_S = self.desired_direction()\n\n    def update_Speed(self, v):\n        self.speed = (v[0],v[1])\n\n    def reach_exit(self):\n        for ex in exits:\n            d , _ = distance_vecteur_obs(self.position , self.size, ex)\n            if d &lt;= 0.2:\n                self.has_reached_exit = True\n                break\n\n    def update_Position(self, q):\n        self.position = q\n        self.reach_exit()\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#fonctions","title":"Fonctions","text":"<p>f_motrice</p> <p>La fonction <code>f_motrice(agent)</code> calcule la force motrice qui sera appliqu\u00e9e \u00e0 l'agent.</p> <p>Elle prend en entr\u00e9e l'objet agent qui doit poss\u00e9der au moins un attribut D_S (vecteur unitaire repr\u00e9sentant la direction d\u00e9sir\u00e9e par l'agent) et speed (vecteur vitesse de l'agent).</p> <p>La force motrice est calcul\u00e9e comme suit :</p> <ul> <li> <p>Le coefficient de relaxation tau est d\u00e9fini \u00e0 0.5.</p> </li> <li> <p>La force motrice est donn\u00e9e par l'expression : (2 x direction d\u00e9sir\u00e9e - vitesse courante) / tau</p> </li> <li> <p>Le r\u00e9sultat est un vecteur qui repr\u00e9sente la force motrice \u00e0 appliquer \u00e0 l'agent.</p> </li> </ul> <p>La force motrice est la force qui pousse l'agent \u00e0 suivre la direction d\u00e9sir\u00e9e, en prenant en compte sa vitesse courante pour \u00e9viter les changements brutaux de direction. Elle permet de mod\u00e9liser le comportement des agents qui avancent dans une direction donn\u00e9e tout en essayant de minimiser les changements de direction brusques.</p> <pre><code>#force motrice\ndef f_motrice(agent):\n    tau = 0.5\n    return (numpy.array(agent.D_S)*2 - numpy.array(agent.speed))/tau\n</code></pre> <p>dist &amp; distance_vecteur_obj &amp; distance_vecteur_obs_cir &amp; distance_vecteur_obs</p> <p>Ces fonctions sont toutes des fonctions de calcul de distance entre deux points ou un point et un obstacle.</p> <ul> <li> <p>La fonction <code>dist(p1, p2)</code> prend deux points p1 et p2 et retourne la norme de leur diff\u00e9rence. Cette norme est calcul\u00e9e en utilisant la fonction numpy.array() pour cr\u00e9er des tableaux numpy \u00e0 partir des points, puis en calculant la diff\u00e9rence entre ces tableaux \u00e0 l'aide de l'op\u00e9rateur - et en utilisant la fonction norm() pour calculer la norme.</p> </li> <li> <p>La fonction <code>distance_vecteur_obj(q1, q2, r1, r2)</code> prend deux points q1 et q2, ainsi que deux rayons r1 et r2 et calcule la distance entre ces deux objets. La distance est calcul\u00e9e comme la distance entre q1 et q2 moins la somme des rayons r1 et r2. La fonction renvoie \u00e9galement le vecteur normalis\u00e9 allant de q2 \u00e0 q1.</p> </li> <li> <p>La fonction <code>distance_vecteur_obs_cir(q, r, obstacle)</code> prend un point q, un rayon r et un objet circulaire obstacle (repr\u00e9sent\u00e9 par sa position et son rayon) et calcule la distance entre le point et l'obstacle. La distance est calcul\u00e9e comme la distance entre le point et le centre de l'obstacle, moins la somme des rayons. La fonction renvoie \u00e9galement le vecteur normalis\u00e9 allant du centre de l'obstacle \u00e0 q.</p> </li> <li> <p>La fonction <code>distance_vecteur_obs(q, r, obstacle)</code> prend un point q, un rayon r et un obstacle rectangulaire obstacle (repr\u00e9sent\u00e9 par sa position, sa largeur et sa hauteur) et calcule la distance entre le point et l'obstacle. La distance est calcul\u00e9e comme la distance entre q et le point de l'obstacle le plus proche de q. Ce point est calcul\u00e9 en projetant q sur le rectangle et en s\u00e9lectionnant le point projet\u00e9 qui est le plus proche de q. La fonction renvoie \u00e9galement le vecteur normalis\u00e9 allant du point le plus proche de q sur l'obstacle \u00e0 q.</p> </li> </ul> <pre><code>def dist(p1,p2):\n    return norm(numpy.array(p1)-numpy.array(p2))\n\ndef distance_vecteur_obj(q1, q2, r1, r2):\n    d = dist(q1, q2)\n\n    n = -(numpy.array(q2) - numpy.array(q1))/d\n\n    d = d - (r1 + r2)\n\n    return d , n\n\ndef distance_vecteur_obs_cir(q , r, obstacle):\n    [a0, b0], rayon = obstacle.position, obstacle.rayon\n    x , y = q\n\n    d = ((x-a0)**2 + (y-b0)**2)**0.5 \n    n = -(numpy.array(obstacle.position) - numpy.array(q))/d\n    d = d - (rayon + r)\n\n    return d , n\n\ndef distance_vecteur_obs(q , r, obstacle):\n    [a0, b0], L, l = obstacle.position, obstacle.width, obstacle.height\n    a1, b1 = a0 + L , b0 + l\n    x , y = q\n    point = []\n\n    if x&lt;=a0:\n      if y&gt;=b1:\n        point = [a0, b1]\n\n      elif b0&lt;y&lt;b1:\n        point = [a0, y]\n\n      else:\n        point = [a0, b0]\n\n    elif a0&lt;x&lt;a1:\n      if y&gt;=b1:\n        point = [x, b1]\n\n      elif b0&lt;y&lt;b1:\n        point = [x, b1]\n\n      else:\n        point = [x, b0]\n\n    else:\n      if y&gt;=b1:\n        point = [a1, b1]\n\n      elif b0&lt;y&lt;b1:\n        point = [a1, y]\n\n      else:\n        point = [a1, b0]\n\n    d = dist(point , q)\n    n = (numpy.array(q) - numpy.array(point))/d\n\n    return d - r , n\n</code></pre> <p>matrice_normals</p> <p>Cette fonction <code>matrice_normals(q, R)</code> calcule les vecteurs normaux pour chaque collision possible entre les agents et les obstacles dans un environnement donn\u00e9.</p> <p>La fonction prend en entr\u00e9e deux listes : q qui est la liste des positions des agents et R qui est la liste des rayons de chaque agent.</p> <p>La fonction retourne une matrice numpy, Normals, qui contient les vecteurs normaux de chaque collision, o\u00f9 chaque ligne repr\u00e9sente un vecteur normal pour un choc possible et chaque colonne repr\u00e9sente un agent (donc 2*m colonnes pour m agents). La fonction retourne \u00e9galement une liste, agents_en_chocs, qui contient les indices des agents impliqu\u00e9s dans au moins une collision.</p> <p>La fonction parcourt tous les agents et v\u00e9rifie s'il y a une collision avec un autre agent ou un obstacle. Si une collision est d\u00e9tect\u00e9e, la fonction calcule le vecteur normal correspondant \u00e0 cette collision \u00e0 l'aide de distance_vecteur_obj() pour une collision entre deux agents, distance_vecteur_obs() pour une collision entre un agent et un obstacle rectangulaire et distance_vecteur_obs_cir() pour une collision entre un agent et un obstacle circulaire.</p> <p>Les vecteurs normaux sont stock\u00e9s dans la matrice Normals et les indices des agents impliqu\u00e9s dans des collisions sont stock\u00e9s dans la liste agents_en_chocs.</p> <p>En fin de parcours, la fonction renvoie la matrice Normals et la liste agents_en_chocs.</p> <pre><code>def matrice_normals(q, R):\n\n    Normals = []\n    agents_en_chocs = []\n    m = len(q)\n\n    #chocs agents\n    for i in range(m):\n\n        N = numpy.zeros(2*m)\n\n        for j in range(m):\n          if j != i:\n            d , n = distance_vecteur_obj(q[i], q[j], R[i], R[j])\n            if d &lt;= 0.2:\n              N[2*i], N[2*i+1], N[2*j], N[2*j+1] = n[0], n[1], -n[0], -n[1]\n\n        if not all(v == 0 for v in N):\n          Normals.append(N)\n          agents_en_chocs.append(i)\n\n    #chocs obstacle\n    for obstacle in obstacles:\n\n        N = numpy.zeros(2*m)\n\n        for i in range(m):\n          d , n = distance_vecteur_obs(q[i] , R[i], obstacle)\n          if d &lt;= 0.2:\n            N[2*i], N[2*i+1] = n[0], n[1]\n            if N[2*i] != 0 or N[2*i+1] != 0:\n              agents_en_chocs.append(i)\n\n        if not all(v == 0 for v in N):\n          Normals.append(N)\n\n    #chocs obstacle circulaire\n    for obstacle in obstacles_cir:\n\n        N = numpy.zeros(2*m)\n\n        for i in range(m):\n          d , n = distance_vecteur_obs_cir(q[i] , R[i], obstacle)\n          if d &lt;= .2:\n            N[2*i], N[2*i+1] = n[0], n[1]\n            if N[2*i] != 0 or N[2*i+1] != 0:\n              agents_en_chocs.append(i)\n\n        if not all(v == 0 for v in N):\n          Normals.append(N)\n\n    return numpy.array(Normals) , agents_en_chocs\n</code></pre> <p>detection_de_chocs</p> <p>La fonction <code>detection_de_chocs(Q, R)</code> qui prend en entr\u00e9e deux listes Q et R contenant respectivement les positions et les rayons de tous les agents et qui renvoie True si deux agents ou un agent et un obstacle se trouvent \u00e0 une distance inf\u00e9rieure \u00e0 une marge de collision marge, et False sinon.</p> <p>La fonction parcourt d'abord tous les obstacles rectangulaires et circulaires stock\u00e9s dans les variables obstacles et obstacles_cir, respectivement, pour v\u00e9rifier s'il y a une collision entre l'agent et l'un de ces obstacles en comparant les coordonn\u00e9es de l'agent \u00e0 celles des coins de l'obstacle et \u00e0 la distance de l'agent au centre de l'obstacle. Ensuite, la fonction compare la distance entre l'agent courant et tous les autres agents pour v\u00e9rifier s'il y a une collision entre eux.</p> <p>Si une collision est d\u00e9tect\u00e9e, la fonction retourne True, sinon elle retourne False.</p> <pre><code>def detection_de_chocs(Q, R):\n\n  m = len(agents)\n\n  for i in range(m):\n    [x , y], r = Q[i], R[i]\n    marge = .2\n\n    #chocs obstacle\n    for obstacle in obstacles:\n        [a0, b0], L, l = obstacle.position, obstacle.width, obstacle.height\n        a1, b1 = a0 + L , b0 + l\n\n        if a0&lt;=x&lt;=a1 and b0-r-marge&lt;=y&lt;=b1+r+marge: return True\n        if b0&lt;=y&lt;=b1 and a0-r-marge&lt;=x&lt;=a1+r+marge: return True\n\n    for obst in obstacles_cir:\n        [a0, b0], rayon = obst.position, obst.rayon\n        d = ((x - a0)**2 + (y - b0)**2)**0.5\n        if d - (rayon+r) &lt; 2 : return True\n\n    #chocs agents\n    for j in range(m):\n      if j != i:\n        if dist(Q[i], Q[j]) - (R[i]+R[j]) &lt;= marge: return True\n\n  return False\n</code></pre> <p>predict_position2</p> <p>La fonction <code>predict_position2(V)</code> permet de pr\u00e9dire la position des agents \u00e0 l'instant suivant en fonction de leur vitesse actuelle et leur vitesse future, ainsi que de leur position actuelle. Elle prend en entr\u00e9e une liste V de la vitesse de chaque agent (vecteur de dimension 2 pour chaque agent) \u00e0 l'instant actuel.</p> <p>Le premier \u00e9l\u00e9ment de la fonction convertit la liste V en un tableau V_future de dimension p x 2 o\u00f9 p est le nombre d'agents dans la simulation. Chaque ligne de V_future contient la vitesse future d'un agent sous la forme d'un vecteur de dimension 2.</p> <p>Le deuxi\u00e8me \u00e9l\u00e9ment de la fonction cr\u00e9e un tableau V_passe de dimension m x 2, o\u00f9 m est le nombre total d'agents dans la simulation. Chaque ligne de V_passe contient la vitesse actuelle de chaque agent sous la forme d'un vecteur de dimension 2.</p> <pre><code>def predict_position2(V):\n  p = int(len(V)/2)\n  V_future =  numpy.array([ numpy.array([V[2*j], V[2*j+1]]) for j in range(p) ])\n  V_passe =   numpy.array([ numpy.array(agent.speed) for agent in agents ])\n\n  return [numpy.array(agent.position) + dt*(V_future[agents.index(agent)] + V_passe[agents.index(agent)])/2 for agent in agents]\n</code></pre> <p>correction_vitesses</p> <p>Cette fonction prend en entr\u00e9e la vitesse actuelle de chaque agent, la force ext\u00e9rieure appliqu\u00e9e \u00e0 chaque agent et le coefficient de restitution entre les agents. Elle calcule ensuite la nouvelle vitesse pour chaque agent en fonction des chocs d\u00e9tect\u00e9s en appelant la fonction matrice_normals qui retourne la matrice des normales pour chaque agent en collision avec un autre agent ou un obstacle.</p> <p>Dans la premi\u00e8re partie de la fonction, la fonction predict_position2 est appel\u00e9e pour pr\u00e9dire la position future des agents. Ensuite, la fonction detection_de_chocs est appel\u00e9e pour v\u00e9rifier s'il y a collision entre les agents et les obstacles.</p> <p>Si une collision est d\u00e9tect\u00e9e, la fonction calcule la matrice de masse M pour chaque agent et la matrice de normales C_N pour chaque collision. Ensuite, elle calcule la matrice U en multipliant la transpos\u00e9e de C_N avec C_N. Cette matrice est utilis\u00e9e pour calculer la matrice de contrainte P.</p> <pre><code>def correction_vitesses(V, Pext, K_n):\n    V, Pext = numpy.array(V), numpy.array(Pext)\n    p = len(agents)\n    agents_en_chocs = []\n\n    q = predict_position2(V)\n    R = [agent.size for agent in agents]\n\n    if detection_de_chocs(q, R):\n        # Matrice Masse\n        M = numpy.zeros((2*p, 2*p))\n        for i in range(p):\n            M[2*i][2*i] = agents[i].masse\n            M[2*i+1][2*i+1] = agents[i].masse\n\n        # Matrice Normales\n        C_N , agents_en_chocs = matrice_normals(q, R)\n\n        U = dot(C_N.transpose(), C_N)\n\n        P = matrix(numpy.array(M) + 0.5 * K_n * U , tc='d')\n        q = matrix(numpy.array(dot(M - 0.5 * K_n * U , V) + dt * Pext), tc='d')\n        G = matrix(numpy.array(C_N), tc='d')\n        h = matrix(numpy.array(numpy.zeros(len(C_N))), tc='d')\n\n        solvers.options['show_progress'] = False\n\n        return list(solvers.qp(P,-q,-G,h)['x']) , agents_en_chocs\n\n    else:\n        return V , agents_en_chocs\n</code></pre> <p>matrice_DistancesEtNormaux &amp; matrice_DistancesEtNormaux_danger</p> <p>Ces deux fonctions g\u00e9n\u00e8rent une matrice de distances et une matrice de normales entre les agents (ou les dangers) du sc\u00e9nario.</p> <p>La fonction <code>matrice_DistancesEtNormaux(agents)</code> prend en entr\u00e9e une liste d'objets agents et renvoie une matrice de distance matrice_distance et une matrice de normales matrice_normaux. Les matrices sont carr\u00e9es et de taille \u00e9gale au nombre d'agents dans la liste agents. La matrice de distance matrice_distance contient les distances entre chaque paire d'agents, et la matrice de normales matrice_normaux contient les normales correspondantes.</p> <p>La fonction <code>matrice_DistancesEtNormaux_danger(agents)</code> prend en entr\u00e9e une liste d'objets agents et renvoie une matrice de distance matrice_distance et une matrice de normales matrice_normaux entre chaque agent de la liste et le danger Dangers[0]. La matrice de distance matrice_distance contient les distances entre chaque agent et le danger, et la matrice de normales matrice_normaux contient les normales correspondantes.</p> <pre><code>def matrice_DistancesEtNormaux(agents):\n    N_ind = len(agents)\n    matrice_distance = numpy.zeros((N_ind, N_ind))\n    matrice_normaux = numpy.zeros((N_ind, N_ind,2))\n    for i in range(N_ind):\n        for j in range(N_ind):\n            if i &gt; j:\n                d, n = distance_vecteur_obj(agents[i].position, agents[j].position, agents[i].size, agents[j].size)\n                matrice_distance[i][j] = d\n                matrice_distance[j][i] = d\n                matrice_normaux[i][j] = n\n                matrice_normaux[j][i] = -n\n    return matrice_distance , matrice_normaux\n\ndef matrice_DistancesEtNormaux_danger(agents):\n    N_ind = len(agents)\n    matrice_distance = numpy.zeros(N_ind)\n    matrice_normaux = numpy.zeros((N_ind, 2))\n    for i in range(N_ind):\n        d = dist(Dangers[0], agents[i].position)\n        n = norm(numpy.array(Dangers[0]) - numpy.array(agents[i].position))\n        matrice_distance[i] = d\n        matrice_normaux[i] = n\n    return matrice_distance , matrice_normaux\n</code></pre>"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#configuration","title":"Configuration","text":"<pre><code>a , b , eps = 10 , 10 , 0.2\nsize_scene = (a,b)\n\nobstacles = [Obstacle((0,0),a,eps), Obstacle((0,eps),eps,b-eps), Obstacle((eps,b-eps),a-eps,eps), Obstacle((a-eps, eps),eps, b-2*eps)]\n\nexits = [Exit((4,a-eps), 1, eps)]\n\nobstacles_cir = []\n\ndraw(exits, obstacles, obstacles_cir, size_scene, [], 0, 'gemoetrie.png', play=True)\n</code></pre> Output"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#champs-de-directions","title":"Champs de directions","text":"<pre><code>h = .5 #pas de discritisation du FAst Marching\n\ngraph = GridGraph(size_scene,1/h)\n\ngraph.prepare_graph_for_fast_marching(obstacles, obstacles_cir, exits)\n\nfast_marching_method(graph, (0,0))\n</code></pre> <pre><code>d = graph.distances\nd_tr = []\nn = len(d)\n\nfor i in range(n):\n    d_tr.append(d[n-i-1])\n\nFY, FX = numpy.gradient(numpy.array(d_tr))\n\nFX = -FX\n\nadjust_FM()\n</code></pre> Output"},{"location":"projects/Reciprocal-n-body-Collision-Avoidance/#simulation","title":"Simulation","text":"<pre><code>N_pop = 10\ntemps_de_sim = 1*60 #secondes\ndt = 5e-2\nN_iter = int(temps_de_sim / dt)\n\nagents = generate_indiv(N_pop)\n\ndraw(exits, obstacles, obstacles_cir, size_scene, agents, 0, 'config_init.png', play=True)\n</code></pre> Output <pre><code>K_n = 0\n\nR = [agent.size for agent in agents]\n\n!mkdir DossierImages\nfor image in os.listdir('DossierImages'):\n    os.remove('DossierImages/' + image)\n\nfor n in tqdm(range(N_iter)):\n\n    if len(agents)==0:break\n\n    V_avant_correction = []\n    P = []\n    matrice_distance , matrice_normaux = matrice_DistancesEtNormaux(agents)\n\n    for agent in agents:\n\n        agent.update_D_S()\n        p_ext = f_motrice(agent)\n        vi = agent.speed + dt*p_ext/agent.masse\n        V_avant_correction.extend(vi)\n        P.extend(p_ext)\n\n    V_new , agents_en_chocs = correction_vitesses(V_avant_correction, P, K_n)\n    q = predict_position2(V_new)\n\n    for agent in agents:\n        k = agents.index(agent)\n        agent.update_Speed([V_new[2*k] , V_new[2*k+1]])\n        agent.update_Position(q[k])\n\n    for agent in agents:\n        if agent.has_reached_exit: agents.remove(agent)\n\n    path = 'DossierImages/simulation' + str(n) + '.jpg'\n    draw(exits, obstacles, obstacles_cir, size_scene, agents,round(n*dt, 2), savepath=path, play = False)\n\nprint('Simulation finished.')\nrecord_video(speed = 25)\n</code></pre> Output"},{"location":"projects/abstractive%20summarization/","title":"Abstractive Summarization","text":""},{"location":"projects/abstractive%20summarization/#introduction","title":"Introduction","text":"<p><code>Abstractive Summarization</code> est une t\u00e2che du Natural Language Processing (NLP) qui vise \u00e0 g\u00e9n\u00e9rer un r\u00e9sum\u00e9 concis d'un texte source. Contrairement au <code>extractive summarization</code>, Abstractive Summarization ne se contente pas de copier les phrases importantes du texte source, mais peut \u00e9galement en cr\u00e9er de nouvelles qui sont pertinentes, ce qui peut \u00eatre consid\u00e9r\u00e9 comme une paraphrase. Abstractive Summarization donne lieu \u00e0 un certain nombre d'applications dans diff\u00e9rents domaines, des livres et de la litt\u00e9rature, \u00e0 la science et \u00e0 la R&amp;D, \u00e0 la recherche financi\u00e8re et \u00e0 l'analyse de documents juridiques.</p> <p>Jusqu'\u00e0 pr\u00e9sent, l'approche la plus r\u00e9cente et la plus efficace en mati\u00e8re de Abstractive Summarization consiste \u00e0 utiliser des mod\u00e8les de transformation sp\u00e9cifiquement adapt\u00e9s \u00e0 un ensemble de donn\u00e9es de r\u00e9sum\u00e9. Dans cette \u00e9tude, nous d\u00e9montrons comment vous pouvez facilement r\u00e9sumer un texte \u00e0 l'aide d'un mod\u00e8le puissant en quelques \u00e9tapes simples. Tout d'abord, nous utiliserons deux mod\u00e8les qui sont d\u00e9j\u00e0 pr\u00e9-entra\u00een\u00e9s, de sorte qu'aucun entrainnement suppl\u00e9mentaire n'est n\u00e9cessaire, puis nous affinerons l'un de ces deux mod\u00e8les sur notre base de donn\u00e9es.</p> <p>Sans plus attendre, commen\u00e7ons !</p>"},{"location":"projects/abstractive%20summarization/#importer-les-donnees","title":"Importer les donn\u00e9es","text":"<pre><code>import pandas as pd\ndata = pd.read_json(\"/content/sample_data/AgrSmall.json\")\ndata.head()\n</code></pre>"},{"location":"projects/abstractive%20summarization/#utilisation-de-transformer-bart-large-cnn-t5-base","title":"Utilisation de transformer <code>bart-large-cnn</code> &amp; <code>t5-base</code>","text":""},{"location":"projects/abstractive%20summarization/#installer-la-bibliotheque-transformers","title":"Installer la biblioth\u00e8que Transformers","text":"<p>La biblioth\u00e8que que nous allons utiliser est Transformers par Huggingface.</p> <p>Pour installer des transformateurs, il suffit d'ex\u00e9cuter cette cellule :</p> <pre><code>pip install transformers\n</code></pre> <p>Note</p> <p>Transformers n\u00e9cessite l'installation pr\u00e9alable de Pytorch. Si vous n'avez pas encore install\u00e9 Pytorch, rendez-vous sur le site officiel de Pytorch et suivez les instructions pour l'installer.</p>"},{"location":"projects/abstractive%20summarization/#importer-les-bibliotheques","title":"Importer les biblioth\u00e8ques","text":"<p>Apr\u00e8s avoir install\u00e9 transformers avec succ\u00e8s, nous pouvons maintenant commencer \u00e0 l'importer dans votre script Python. Nous pouvons \u00e9galement importer <code>os</code> afin de d\u00e9finir la variable d'environnement \u00e0 utiliser par le GPU \u00e0 l'\u00e9tape suivante.</p> <pre><code>from transformers import pipeline\nimport os\n</code></pre> <p>Maintenant, nous sommes pr\u00eats \u00e0 s\u00e9lectionner the summarization model \u00e0 utiliser. Huggingface fournit deux summarization models puissants \u00e0 utiliser : <code>BART</code> (bart-large-cnn) et <code>t5</code> (t5-small, t5-base, t5-large, t5-3b, t5-11b). Pour en savoir plus sur ces mod\u00e8les veuillez consulter leurs documents officiels (document BART, document t5).</p> <p>Pour utiliser le mod\u00e8le BART, qui est form\u00e9 sur le CNN/Daily Mail News Dataset, nous avons utilis\u00e9s directement les param\u00e8tres par d\u00e9faut via le module int\u00e9gr\u00e9 Huggingface pipeline :</p> <pre><code>summarizer = pipeline(\"summarization\")\n</code></pre> <p>Pour utiliser le mod\u00e8le t5 (par exemple t5-base), qui est entra\u00een\u00e9 sur c4 Common Crawl web corpus, nous avons proc\u00e9d\u00e9 comme suit :</p> <pre><code>summarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", framework=\"tf\")\n</code></pre> <p>Pour plus d'informations, veuillez vous r\u00e9f\u00e9rer \u00e0 la Huggingface documentation.</p>"},{"location":"projects/abstractive%20summarization/#entrer-le-texte-a-resumer","title":"Entrer le texte \u00e0 r\u00e9sumer","text":"<p>Maintenant que notre mod\u00e8le est pr\u00eat, nous pouvons commencer \u00e0 choisir les textes que nous voulons r\u00e9sumer. Nous proposons de choisir les 4 premiers abstracts dans notre base de donn\u00e9es :</p> <p>Nous d\u00e9finissons nos variables :</p> <pre><code>text_1 = data[\"abstracts\"][0]\nprint(text_1)\n</code></pre> Output text_1 <p>Most people in rural areas in South Africa (SA) rely on untreated drinking groundwater sources and pit latrine sanitations. A minimum basic sanitation facility should enable safe and appropriate removal of human waste, and although pit latrines provide this, they are still contamination concerns. Pit latrine sludge in SA is mostly emptied and disposed off-site as waste or buried in-situ. Despite having knowledge of potential sludge benefits, most communities in SA are reluctant to use it. This research captured social perceptions regarding latrine sludge management in Monontsha village in the Free State Province of SA through key informant interviews and questionnaires. A key informant interview and questionnaire was done in Monontsha, SA. Eighty participants, representing 5% of all households, were selected. Water samples from four boreholes and four rivers were analyzed for faecal coliforms and E.coli bacteria. On average, five people in a household were sharing a pit latrine. Eighty-three percent disposed filled pit latrines while 17% resorted to closing the filled latrines. Outbreaks of diarrhoea (69%) and cholera (14%) were common. Sixty percent were willing to use treated faecal sludge in agriculture. The binary logistic regression model indicated that predictor variables significantly (p \u02c2 0.05) described water quality, faecal sludge management, sludge application in agriculture and biochar adaption. Most drinking water sources in the study had detections \u02c2 1 CFU/100 mL. It is therefore imperative to use both qualitative surveys and analytical data. Awareness can go a long way to motivate individuals to adopt to a new change. View Full-Text</p> <pre><code>text_2 = data[\"abstracts\"][1]\nprint(text_2)\n</code></pre> Output text_2 <p>The aim of this study was to highlight the importance of socioeconomic and psychosocial factors in the adoption of sustainable agricultural practices (SAPs) in banana farm production. To this end, data from 300 randomly selected farm households from Pakistan were collected through a structured self-report questionnaire. Using logistic regression (LR) and structural equation modeling (SEM), socioeconomic and psychosocial effects were evaluated. The results show that economic status, watching agricultural training programs, newspaper and radio awareness campaigns, participation in extension programs, perceptions of sustainable agriculture and the feasibility of SAPs were significant factors in farmers\u2019 adoption of sustainable agriculture practices. Also, consistent with the theory of planned behavior (TPB), all its dimensions (attitude, subjective norms and perceived behavioral control) affected the adoption of SAPs. This finding highlights the importance of socioeconomic and psychosocial factors in promoting sustainable agricultural practice among banana production farmers. This is the first study which attempts to provide empirical evidence using a robust procedure (two models\u2014LR and SEM). The practical implication is that, when socioeconomic and psychosocial factors are well supported by satisfactory policy measures, SAP adoption is more than likely, which eventually increases farmers\u2019 adaptive capacity to the changing environment. Ultimately, this leads to sustainable banana production, which has great potential to contribute towards poverty eradication. View Full-Text</p> <pre><code>text_3 = data[\"abstracts\"][2]\nprint(text_3)\n</code></pre> Output text_3 <p>Urban agriculture and gardening provide many health benefits, but the soil is sometimes at risk of heavy metal and metalloid (HMM) contamination. HMM, such as lead and arsenic, can result in adverse health effects for humans. Gardeners may face exposure to these contaminants because of their regular contact with soil and consumption of produce grown in urban areas. However, there is a lack of research regarding whether differential exposure to HMM may be attributed to differential knowledge of exposure sources. In 2018, industrial slag and hazardous levels of soil contamination were detected in West Atlanta. We conducted community-engaged research through surveys and follow-up interviews to understand awareness of slag, HMM in soil, and potential remediation options. Home gardeners were more likely to recognize HMM health effects and to cite health as a significant benefit of gardening than community gardeners. In terms of knowledge, participants were concerned about the potential health effects of contaminants in soil yet unconcerned with produce in their gardens. Gardeners\u2019 knowledge on sources of HMM exposure and methods for remediation were low and varied based on racial group. View Full-Text</p> <pre><code>text_4 = data[\"abstracts\"][3]\nprint(text_4)\n</code></pre> Output text_4 <p>Waste management has become pertinent in urban regions, along with rapid population growth. The current ways of managing waste, such as refuse collection and recycling, are failing to minimise waste in cities. With urban populations growing worldwide, there is the challenge of increased pressure to import food from rural areas. Urban agriculture not only presents an opportunity to explore other means of sustainable food production, but for managing organic waste in cities. However, this opportunity is not taken advantage of. Besides, there is a challenge of mixed reactions from urban planners and policymakers concerning the challenges and benefits presented by using organic waste in urban agriculture. The current paper explores the perceived challenges and opportunities for organic waste utilisation and management through urban agriculture in the Durban South Basin in eThekwini Municipality in KwaZulu-Natal (KZN) Province of South Africa. It is anticipated that this information will be of use to the eThekwini Municipality, policymakers, researchers, urban agriculture initiatives, households and relevant stakeholders in the study areas and similar contexts globally. Two hundred (200) households involved in any urban farming activity and ten (10) key informants (six (6) staff from the Cleaning and Solid Waste Unit of the eThekwini Municipality and four (4) from the urban agricultural initiative) were selected using convenient sampling. Descriptive statistics and inductive thematic analysis were used to analyse data. The significant perceived challenges and risks associated with the utilisation of organic waste through urban agriculture included lack of a supporting policy, climatic variation, lack of land tenure rights, soil contamination and food safety concerns. Qualitative data further showed that the difficulty in segregating waste, water scarcity, difficulty in accessing inputs, limited transportation of organic waste, inadequate handling and treatment of organic waste, and being a health hazard were some important challenges. On the other hand, the significant perceived benefits associated with the utilisation of organic waste through urban agriculture were enhanced food and nutrition security, and opportunities for business incubation. Other important benefits established through qualitative data were an improved market expansion for farmers and improved productivity. Overall, despite the perceived challenges and risks, there is an opportunity to manage organic waste through urban agriculture. It is imperative for an integrated policy encompassing the food, climate and waste management to be developed to support this strategy. All stakeholders\u2014the government, municipal authorities and urban agricultural initiatives should also, guided by the policy, support urban farmers, for example, through pieces of training on how to properly manage and recycle organic waste, land distribution, inputs availability and water usage rights among other things. View Full-Text</p>"},{"location":"projects/abstractive%20summarization/#generation-de-resume","title":"G\u00e9n\u00e9ration de r\u00e9sum\u00e9","text":"<p>Enfin, nous pouvons commencer \u00e0 r\u00e9sumer les textes entr\u00e9s. Ici, nous d\u00e9clarons la longueur minimale et la longueur maximale que nous souhaitons pour la sortie des r\u00e9sum\u00e9s, et nous d\u00e9sactivons \u00e9galement l'\u00e9chantillonnage pour g\u00e9n\u00e9rer des r\u00e9sum\u00e9s fixes. Nous pouvons le faire en ex\u00e9cutant les commandes suivantes :</p> <pre><code>summary_text_1 = summarizer(text, max_length=100, min_length=5, do_sample=False)[0]['summary_text']\nprint(summary_text_1)\n</code></pre> <p>Voil\u00e0 ! Nous obtenons le r\u00e9sum\u00e9 de premier texte :</p> Output <p>Most people in rural areas in South Africa rely on untreated drinking groundwater sources and pit latrine sanitations . Outbreaks of diarrhoea (69%) and cholera (14%) were common. Sixty percent were willing to use treated faecal sludge in agriculture .</p> <pre><code>summary_text_2 = summarizer(text_2, max_length=100, min_length=5, do_sample=False)[0]['summary_text']\nprint(summary_text_2)\n</code></pre> <p>Voil\u00e0 ! Nous obtenons le r\u00e9sum\u00e9 de deuxi\u00e8me texte :</p> Output <p>The aim of this study was to highlight the importance of socioeconomic and psychosocial factors in the adoption of sustainable agricultural practices (SAPs) in banana farm production . Economic status, watching agricultural training programs, newspaper and radio awareness campaigns, perceptions of sustainable agriculture and the feasibility of SAPs were significant factors .</p> <pre><code>summary_text_3 = summarizer(text_3, max_length=100, min_length=5, do_sample=False)[0]['summary_text']\nprint(summary_text_3)\n</code></pre> <p>Voil\u00e0 ! Nous obtenons le r\u00e9sum\u00e9 de troisi\u00e8me texte :</p> Output <p>Heavy metal and metalloid (HMM) contamination can result in adverse health effects for humans . In 2018, industrial slag and hazardous levels of soil contamination were detected in West Atlanta . Home gardeners were more likely to recognize HMM health effects than community gardeners .</p> <pre><code>summary_text_4 = summarizer(text_4, max_length=100, min_length=5, do_sample=False)[0]['summary_text']\nprint(summary_text_4)\n</code></pre> <p>Voil\u00e0 ! Nous obtenons le r\u00e9sum\u00e9 de quatri\u00e8me texte :</p> Output <p>Waste management has become pertinent in urban regions, along with rapid population growth . The current ways of managing waste, such as refuse collection and recycling, are failing to minimise waste in cities . With urban populations growing worldwide, there is the challenge of increased pressure to import food from rural areas .</p>"},{"location":"projects/abstractive%20summarization/#fine-tuning-simplet5","title":"Fine-tuning SimpleT5","text":"<pre><code>!pip install simplet5\n</code></pre> <pre><code>import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\npath = \"/content/sample_data/AgrSmall.json\"\ndf = pd.read_json(path)\ndf.head()\n</code></pre> <pre><code># simpleT5 expects dataframe to have 2 columns: \"source_text\" and \"target_text\"\ndf = df.rename(columns={\"titles\":\"target_text\", \"abstracts\":\"source_text\"})\ndf = df[['source_text', 'target_text']]\n\n# T5 model expects a task related prefix: since it is a summarization task, we will add a prefix \"summarize: \"\ndf['source_text'] = \"summarize: \" + df['source_text']\ndf\n</code></pre> <pre><code>train_df, test_df = train_test_split(df, test_size=0.2)\ntrain_df.shape, test_df.shape\n</code></pre> <pre><code>from simplet5 import SimpleT5\n\nmodel = SimpleT5()\nmodel.from_pretrained(model_type=\"t5\", model_name=\"t5-base\")\nmodel.train(train_df=train_df[:3000],\n            eval_df=test_df[:100], \n            source_max_token_len=128, \n            target_max_token_len=50, \n            batch_size=8, max_epochs=3, use_gpu=True)\n</code></pre> <pre><code># let's load the trained model for inferencing:\nmodel.load_model(\"t5\",\"/content/outputs/simplet5-epoch-0-train-loss-2.806-val-loss-2.5596\", use_gpu=True)\n\ntext_1 = data[\"abstracts\"][0]\ntext_2 = data[\"abstracts\"][1]\ntext_3 = data[\"abstracts\"][2]\ntext_4 = data[\"abstracts\"][3]\n</code></pre> <pre><code>model.predict(text_1)\n</code></pre> Output <p>['latrine sludge management in Monontsha, Free State Province of South Africa. Key informant interviews and questionnaires']</p> <pre><code>model.predict(text_2)\n</code></pre> Output <p>['sustainable agriculture practices among banana production farmers in Pakistan: Evidence from LR and SEM']</p> <pre><code>model.predict(text_3)\n</code></pre> Output <p>['soil contamination from industrial slag and hazardous levels of metalloid (HMM) contamination in West Atlanta, Georgia. Community-engaged research']</p> <pre><code>model.predict(text_4)\n</code></pre> Output <p>['challenges and opportunities for organic waste utilisation and management through urban agriculture in the Durban South Basin, KwaZulu-Natal Province of South Africa']</p>"},{"location":"projects/big%20data%20for%20iot/","title":"Big-Data For IOT","text":"<p>Membres du groupe</p> <ul> <li>Hermann Agossou</li> <li>Abdellatif BELMADY</li> <li>Fatine BOUSSATTINE</li> <li>Hamza HAJJINI</li> <li>Salma KHMASSI</li> <li>Mohamed Lamine BAMBA</li> <li>Hamza Dribine</li> </ul>"},{"location":"projects/big%20data%20for%20iot/#introduction","title":"Introduction","text":"<p>Ce projet a pour but de pr\u00e9senter les concepts cl\u00e9s du <code>Big Data</code> et de <code>l'IoT</code>, ainsi que leur importance dans le monde actuel. Il a \u00e9galement explor\u00e9 les diff\u00e9rentes approches et outils utilis\u00e9s pour g\u00e9rer ces donn\u00e9es massives, les enjeux et les d\u00e9fis li\u00e9s \u00e0 leur utilisation, les applications de l'IA dans le Big Data et l'IoT, et les perspectives futures de ces technologies.</p>"},{"location":"projects/big%20data%20for%20iot/#definition-du-big-data-et-de-liot","title":"D\u00e9finition du Big Data et de l'IoT","text":"<p>Info</p> <p>Pr\u00e9sentation de ces deux concepts cl\u00e9s et de leur importance dans le monde actuel.</p> <p><code>L'internet des objets (IoT)</code> a gagn\u00e9 en utilisation et en popularit\u00e9 au cours de la derni\u00e8re d\u00e9cennie, indiquant de nouvelles orientations productives et passionnantes pour toute une g\u00e9n\u00e9ration de dispositifs d'information. Les concepts fondamentaux de l'IoT ont \u00e9t\u00e9 invent\u00e9s par Kevin Ashton en 1999, lorsqu'il a introduit la communication entre appareils \u00e0 une \u00e9chelle plus large que celle qui \u00e9tait possible auparavant. Atzori et al. ont depuis d\u00e9clar\u00e9 que \"l'IoT est le r\u00e9sultat de la convergence de trois visions : orient\u00e9e vers les objets, orient\u00e9e vers l'internet et orient\u00e9e vers la s\u00e9mantique\". En termes de s\u00e9mantique sp\u00e9cifiquement, l'IoT est un \"r\u00e9seau mondial d'objets interconnect\u00e9s\". L'IoT peut \u00eatre d\u00e9fini comme \"une infrastructure de r\u00e9seau mondial dynamique, en tant que telle, elle peut identifier, contr\u00f4ler et surveiller chaque objet sur terre via l'internet selon un protocole d'accord sp\u00e9cifique, et par l'interconnexion de choses physiques et virtuelles bas\u00e9e sur l'interop\u00e9rabilit\u00e9 des technologies de l'information et de la communication\". L'objectif principal de l'IoT est d'aider \u00e0 partager des informations en temps r\u00e9el par le biais d'acteurs autonomes en r\u00e9seau. La figure 1 explique le concept de l'IoT. Un capteur dot\u00e9 de capacit\u00e9s de calcul intelligentes est plac\u00e9 \u00e0 un endroit o\u00f9 se trouve une connexion Internet. Ce capteur sera capable de communiquer avec n'importe quoi, \u00e0 tout moment et de n'importe quel endroit du r\u00e9seau. Les syst\u00e8mes de collecte de donn\u00e9es localisent et transf\u00e8rent les donn\u00e9es par le biais d'un grand nombre de ces dispositifs de communication au sein de l'infrastructure IoT, ce qui facilite le processus de collecte des donn\u00e9es. Plusieurs solutions de communication, telles que WIFI, ZigBee, Bluetooth et GSM, permettent l'interconnexion de dispositifs utilisant divers r\u00e9seaux d'acc\u00e8s, notamment l'identification par radiofr\u00e9quence (RFID), les dispositifs dot\u00e9s de capteurs sans fil et tout objet intelligent connect\u00e9 \u00e0 l'internet par IP physique.</p> <p>De nos jours, d'\u00e9normes volumes de donn\u00e9es sont g\u00e9n\u00e9r\u00e9s par l'IoT. Ces donn\u00e9es, souvent appel\u00e9es <code>big data</code>, font r\u00e9f\u00e9rence \u00e0 une grande \u00e9chelle de donn\u00e9es qui exige de nouvelles architectures et technologies pour la gestion des donn\u00e9es (capture et traitement) afin de permettre l'extraction de valeur pour une meilleure compr\u00e9hension et prise de d\u00e9cision. Le big data se caract\u00e9rise par diverses propri\u00e9t\u00e9s de haut volume, de haute v\u00e9locit\u00e9, de haute vari\u00e9t\u00e9 et de haute v\u00e9racit\u00e9. D'ici 2020, l'IoT devrait connecter 50 milliards de dispositifs ou plus, en raison de l'afflux consid\u00e9rable de nouveaux objets intelligents et de l'augmentation exponentielle de la demande de leurs services.</p> <p> <p></p> <p>Fig. 1. Internet of things concept.</p> <p></p> <p>R\u00e9cemment, <code>l'IoT</code> a \u00e9t\u00e9 appliqu\u00e9 dans les environnements intelligents, qui permettent aux utilisateurs de mieux comprendre et contr\u00f4ler leur environnement gr\u00e2ce \u00e0 une gamme de dispositifs interconnect\u00e9s. Dans les applications d'environnement intelligent, l'IoT est employ\u00e9 pour construire un r\u00e9seau de surveillance \u00e9cologique complet, \u00e0 plusieurs niveaux et enti\u00e8rement couvert, qui peut \u00eatre r\u00e9alis\u00e9 en utilisant l'int\u00e9gration de capteurs \u00e0 tous les niveaux en tirant parti de l'IoT avec des informations spatiales et temporelles, et en construisant une plate-forme massive avec un centre de donn\u00e9es et un support de service unifi\u00e9. La technologie IoT et son int\u00e9gration avec le big data ont \u00e9t\u00e9 largement appliqu\u00e9es dans divers domaines tels que les villes intelligentes, les soins de sant\u00e9 intelligents, les syst\u00e8mes d'alerte intelligents et la gestion des catastrophes. Par cons\u00e9quent, la construction et l'application de l'IoT et du big data dans les domaines environnementaux sont devenues une mesure cruciale, notamment pour le d\u00e9veloppement, la promotion et la gestion d'un nouvel environnement strat\u00e9gique dans l'industrie.</p>"},{"location":"projects/big%20data%20for%20iot/#exemples-concrets-dutilisation-du-big-data-et-de-liot","title":"Exemples concrets d'utilisation du Big Data et de l'IoT","text":""},{"location":"projects/big%20data%20for%20iot/#les-voitures-intelligentes","title":"Les voitures intelligentes","text":"<p>Les voitures intelligentes utilisent l\u2019IoT pour \u00e9changer des informations li\u00e9es au fonctionnement et l\u2019environnement de la voitures, tel que l\u2019emplacement, la vitesse, la dynamique\u2026. Grace \u00e0 l\u2019IoT, on peut d\u00e9terminer l\u2019itin\u00e9raire le plus optimale, aussi, on peut localiser une place libre dans un parking. De plus, Il peut aider dans la r\u00e9paration et l\u2019entretien des v\u00e9hicules, en fait, il informe l\u2019utilisateur de la date de maintenance pr\u00e9vue, et il aide dans la r\u00e9paration avec une direction ad\u00e9quate. Ainsi, il permet aux voitures de faire des taches lourdes comme \u00e9viter les collisions et arr\u00eater le trafic inutile.</p> <p>Ces voitures intelligentes sont \u00e9quip\u00e9es de cam\u00e9ras et de capteurs qui peuvent collecter des donn\u00e9es sur l'environnement de la voiture. Cela peut inclure des \u00e9l\u00e9ments tels que les sch\u00e9mas de circulation, les conditions m\u00e9t\u00e9orologiques et m\u00eame l'emplacement et la vitesse des autres v\u00e9hicules dans la r\u00e9gion. Ce qui conduit \u00e0 la collecte d\u2019un volume important de donn\u00e9es. </p>"},{"location":"projects/big%20data%20for%20iot/#les-villes-intelligentes","title":"Les villes intelligentes","text":"<p>Les villes intelligentes utilisent l\u2019IoT sur plusieurs aspects tel que : les transports automatiques, les syst\u00e8mes intelligents de gestion de l\u2019\u00e9nergie et de distribution de l\u2019eau, la s\u00e9curit\u00e9 urbaine et la surveillance de l\u2019environnement. Ces villes utilisent l\u2019IoT et le Big Data pour collecter et analyser des donn\u00e9es provenant de diverses sources, telles que des capteurs et des cam\u00e9ras installer partout dans la ville, afin de r\u00e9soudre les probl\u00e8mes rencontr\u00e9s par les citoyens, nous citons comme exemples :  </p> <p>\u2022   Les syst\u00e8mes intelligents de gestion du trafic qui utilisent les donn\u00e9es des capteurs de trafic pour optimiser la circulation et r\u00e9duire les embouteillages.</p> <p>\u2022   Les syst\u00e8mes d'\u00e9clairage intelligents qui utilisent des donn\u00e9es provenant de capteurs pour ajuster la luminosit\u00e9 et la synchronisation des lampadaires.</p> <p>\u2022   Les syst\u00e8mes intelligents de gestion des d\u00e9chets qui utilisent les donn\u00e9es de capteurs de niveau de d\u00e9chets pour optimiser les itin\u00e9raires de collecte des ordures.</p> <p>\u2022   Les syst\u00e8mes de stationnement intelligents qui utilisent les donn\u00e9es fournies par des capteurs pour guider les conducteurs vers les places de stationnement disponibles et r\u00e9duire les embouteillages.</p> <p>\u2022   Les syst\u00e8mes de surveillance de la qualit\u00e9 de l'air et de l'eau qui utilisent des capteurs IoT pour d\u00e9tecter et alerter les responsables de la ville des dangers potentiels. </p> <p>Certains rapports estiment que les villes intelligentes peuvent g\u00e9n\u00e9rer jusqu'\u00e0 t\u00e9rabytes de donn\u00e9es par jour, ce volume de donn\u00e9es est en constante augmentation en raison de la croissance de l'Internet des objets (IoT) et de la 5G.</p>"},{"location":"projects/big%20data%20for%20iot/#la-domotique","title":"La domotique","text":"<p>Les syst\u00e8mes domotiques ou les maisons intelligentes contient des appareilles qui fonctionnent \u00e0 base de l\u2019IoT, comme les climatiseurs, les lumi\u00e8res et les ventilateurs. Cela donne la possibilit\u00e9 \u00e0 l\u2019utilisateur de contr\u00f4ler sa maison \u00e0 une distance \u00e9tendue, en fait, il peut contr\u00f4ler la temp\u00e9rature, l\u2019\u00e9clairage, la gestion de l\u2019\u00e9nergie, l\u2019expansion, le syst\u00e8me de s\u00e9curit\u00e9, et l\u2019acc\u00e8s \u00e0 distance.</p> <p>La domotique utilise des capteurs, des actionneurs, des r\u00e9seaux de communication et des syst\u00e8mes de contr\u00f4le pour automatiser les t\u00e2ches m\u00e9nag\u00e8res et am\u00e9liorer le confort et la s\u00e9curit\u00e9 des r\u00e9sidents. La domotique utilise les technologies du Big Data, et des algorithmes d\u2019analyse des donn\u00e9es pour pr\u00e9voir les besoins futurs et anticiper les probl\u00e8mes. Par exemple, en utilisant des donn\u00e9es sur les tendances de consommation d'\u00e9nergie, les syst\u00e8mes de domotique peuvent ajuster automatiquement les param\u00e8tres de chauffage et de climatisation pour r\u00e9duire la consommation d'\u00e9nergie.</p> <p>En conclusion, la domotique et le BIG Data sont \u00e9troitement li\u00e9s car ces derniers permettent de collecter, stocker et utiliser des donn\u00e9es pour am\u00e9liorer les performances des syst\u00e8mes de domotique en termes de confort, s\u00e9curit\u00e9 et \u00e9conomie d'\u00e9nergie.</p>"},{"location":"projects/big%20data%20for%20iot/#les-appareils-portables","title":"Les appareils portables","text":"<p>De nos jours, l\u2019IoT a \u00e9t\u00e9 int\u00e9gr\u00e9 dans la plupart des appareils portable, ces derni\u00e8res contient des cam\u00e9ras, des capteurs de son, les r\u00e9seaux et la connexion \u00e0 internet, qui utilisent pour collecter certaines informations sur l\u2019utilisateurs, notamment : </p> <p>\u2022   <code>Les donn\u00e9es de localisation</code> : les smartphones utilisent des technologies comme GPS, Wi-Fi et les r\u00e9seaux cellulaires pour d\u00e9terminer la position de l'utilisateur.</p> <p>\u2022   <code>Les donn\u00e9es de navigation</code> : les smartphones enregistrent les sites web et les applications que l'utilisateur a visit\u00e9s.</p> <p>\u2022   <code>Les donn\u00e9es de contacts</code> : les smartphones stockent les informations de contact de l'utilisateur, comme les num\u00e9ros de t\u00e9l\u00e9phone et les adresses e-mail.</p> <p>\u2022   <code>Les donn\u00e9es de messages</code> : les smartphones peuvent stocker les messages texte et les conversations de messagerie instantan\u00e9e de l'utilisateur.</p> <p>\u2022   <code>Les donn\u00e9es de m\u00e9dias</code> : les smartphones peuvent stocker les photos, les vid\u00e9os et les fichiers audio pris ou enregistr\u00e9s par l'utilisateur.</p> <p>Les rapports informent que aujourd\u2019hui les serveurs de Facebook doivent analyser tous les demi-heure l\u2019\u00e9quivalent de 105 To de donn\u00e9es (Botton \u2018\u2019j\u2019aime\u2019\u2019, photos, requ\u00eate \u2026 ).</p>"},{"location":"projects/big%20data%20for%20iot/#approches-et-outils-pour-gerer-le-big-data-et-liot","title":"Approches et outils pour g\u00e9rer le Big Data et l'IoT","text":"<p>Info</p> <p>Pr\u00e9sentation des diff\u00e9rents approches et outils utilis\u00e9s pour g\u00e9rer et analyser le Big Data et l'IoT, tels que les plateformes de gestion de donn\u00e9es, les outils d'analyse de donn\u00e9es en temps r\u00e9el, etc.</p> <p>Le Big Data et l'IoT (Internet des objets) sont deux domaines qui ont connu une croissance explosive ces derni\u00e8res ann\u00e9es et qui continuent de se d\u00e9velopper rapidement. Le Big Data fait r\u00e9f\u00e9rence \u00e0 l'ensemble des donn\u00e9es g\u00e9n\u00e9r\u00e9es par les entreprises, les organisations et les individus, tandis que l'IoT d\u00e9signe l'ensemble des objets connect\u00e9s \u00e0 Internet qui sont capables de collecter et de transmettre des donn\u00e9es. La gestion de ces deux domaines peut \u00eatre complexe, mais il existe plusieurs approches et outils qui peuvent aider les entreprises \u00e0 y parvenir.</p> <p>Une approche courante pour g\u00e9rer le Big Data consiste \u00e0 utiliser des technologies de gestion de donn\u00e9es distribu\u00e9es, telles que Hadoop ou Spark. Ces technologies permettent de traiter de grandes quantit\u00e9s de donn\u00e9es de mani\u00e8re efficace et \u00e0 bas co\u00fbt en r\u00e9partissant le travail sur plusieurs n\u0153uds de calcul.</p> <p>Il est \u00e9galement possible de g\u00e9rer le Big Data en utilisant des bases de donn\u00e9es en m\u00e9moire, comme Redis ou Memcached, qui permettent de traiter les donn\u00e9es de mani\u00e8re plus rapide que les bases de donn\u00e9es traditionnelles. Cependant, ces bases de donn\u00e9es sont g\u00e9n\u00e9ralement moins adapt\u00e9es aux grands volumes de donn\u00e9es et ne conviennent pas toujours \u00e0 tous les types de donn\u00e9es.</p> <p>Pour g\u00e9rer l'IoT, il est courant d'utiliser des plateformes de gestion de l'IoT, telles que AWS IoT ou Azure IoT, qui permettent de collecter, de stocker et de traiter les donn\u00e9es provenant d'objets connect\u00e9s. Ces plateformes offrent \u00e9galement des outils pour la gestion de l'IoT, tels que la gestion des appareils, la s\u00e9curit\u00e9 et la conformit\u00e9.</p> <p>On note \u00e9galement l'utilisation de capteurs (par exemple, capteurs de temp\u00e9rature, de mouvement, de pression) ainsi que des protocoles de communication sans fil (par exemple, Bluetooth, Wi-Fi, LTE).Ces appareils permettent de collecter des donn\u00e9es environnementales ou de contr\u00f4ler des objets physiques \u00e0 distance. Pour cela, ils utilisent des protocoles qui permettent \u00e0 diff\u00e9rents appareils de communiquer entre eux et de se connecter \u00e0 Internet. Ils sont souvent utilis\u00e9s pour la communication entre appareils IoT.</p> <p>En conclusion, il existe de nombreux approches et outils pour g\u00e9rer le Big Data et l'IoT. Le choix de la solution d\u00e9pend de l'environnement de l'entreprise et de ses besoins en mati\u00e8re de traitement de donn\u00e9es. Il est important de prendre le temps de bien comprendre les options disponibles et de choisir la solution qui convient le mieux \u00e0 l'entreprise afin de maximiser l'efficacit\u00e9 et l'efficience de la gestion des donn\u00e9es.</p>"},{"location":"projects/big%20data%20for%20iot/#enjeux-et-defis-lies-au-big-data-et-a-liot","title":"Enjeux et d\u00e9fis li\u00e9s au Big Data et \u00e0 l'IoT","text":"<p>Info</p> <p>Le recours au big data s'av\u00e8re ainsi substantiel pour l'exploitation et le traitement des vastes quantit\u00e9s de donn\u00e9es collect\u00e9es par les dispositifs connect\u00e9s (iot), dont les enjeux sont list\u00e9s ci-dessous :</p>"},{"location":"projects/big%20data%20for%20iot/#1-confidentialite-et-securite","title":"1. Confidentialit\u00e9 et s\u00e9curit\u00e9","text":"<p>Les donn\u00e9es collect\u00e9es par les objets connect\u00e9s peuvent \u00eatre utilis\u00e9es pour suivre les activit\u00e9s des personnes, \u00e0 savoir des comptes utilisateurs, de consommateurs. Pourtant, elles peuvent \u00eatre utilis\u00e9es \u00e0 des fins malveillantes ou sans le consentement des personnes concern\u00e9es. De plus, lesdits objets  peuvent \u00eatre la cible de diff\u00e9rentes formes d'attaques, comme les attaques de d\u00e9ni de service, les attaques de fuites de donn\u00e9es ou les attaques de piratage, et par cons\u00e9quent, la gestion de la s\u00e9curit\u00e9 des donn\u00e9es massives et confidentielles demeure un d\u00e9fi en raison de la quantit\u00e9 de donn\u00e9es \u00e0 prot\u00e9ger et des risques potentiels pouvant affecter les donn\u00e9es.</p>"},{"location":"projects/big%20data%20for%20iot/#2-varietes-de-donnees","title":"2. Vari\u00e9t\u00e9s de donn\u00e9es","text":"<p>Les donn\u00e9es massives collect\u00e9es via les appareils connect\u00e9s peuvent \u00eatre de diff\u00e9rents types (structur\u00e9es, non structur\u00e9es, semi-structur\u00e9es) et provenir de diff\u00e9rentes sources. Par exemple, la plupart des donn\u00e9es collect\u00e9es peuvent \u00eatre sous format d'images, de fichiers audio, de documents, de fichiers texte, etc. qui ne sont pas structur\u00e9es et ne se trouvent pas dans des bases de donn\u00e9es. Il sera donc difficile d'extraire et d'analyser par la suite toutes ces donn\u00e9es non structur\u00e9es.</p>"},{"location":"projects/big%20data%20for%20iot/#3-la-vitesse-de-gestion-des-megadonnees","title":"3. La vitesse de gestion des m\u00e9gadonn\u00e9es","text":"<p>Ceci est consid\u00e9r\u00e9 comme un enjeu crucial vu que les donn\u00e9es massives collect\u00e9es sur Internet peuvent \u00eatre g\u00e9n\u00e9r\u00e9es et mises \u00e0 jour tr\u00e8s rapidement. Cela peut rendre difficile le traitement en temps r\u00e9el des donn\u00e9es et l'obtention de r\u00e9sultats rapides. Par exemple, si les donn\u00e9es sont utilis\u00e9es pour prendre des d\u00e9cisions commerciales importantes, il est crucial d'avoir acc\u00e8s \u00e0 des donn\u00e9es \u00e0 jour et de pouvoir traiter rapidement ces donn\u00e9es pour obtenir des r\u00e9sultats en temps opportun.</p>"},{"location":"projects/big%20data%20for%20iot/#4-stockage-et-infrastructure-des-donnees","title":"4. Stockage et infrastructure des donn\u00e9es","text":"<p>Le stockage et l'infrastructure des donn\u00e9es sont des enjeux importants pour l'usage du big data au service de l'IoT car celui-ci implique la collecte et le traitement de grandes quantit\u00e9s de donn\u00e9es en temps r\u00e9el, qui peuvent provenir de diff\u00e9rents types de capteurs et de dispositifs connect\u00e9s. Ces donn\u00e9es peuvent \u00eatre utilis\u00e9es pour diverses fins, telles que l'optimisation de la production, l'am\u00e9lioration de la maintenance pr\u00e9ventive ou l'analyse de la performance des syst\u00e8mes. Par cons\u00e9quent, la gestion efficace de ces donn\u00e9es repose sur une infrastructure de stockage et de traitement de donn\u00e9es ad\u00e9quates ( bases de donn\u00e9es distribu\u00e9es, syst\u00e8mes de fichiers distribu\u00e9s, \u2026).</p>"},{"location":"projects/big%20data%20for%20iot/#applications-de-lia-dans-le-big-data-et-liot","title":"Applications de l'IA dans le Big Data et l'IoT","text":"<p>Info</p> <p>Pr\u00e9sentation des diff\u00e9rentes applications de l'intelligence artificielle dans le Big Data et l'IoT, ainsi que leur impact sur l'analyse et la prise de d\u00e9cision.</p> <p>L'intelligence artificielle (IA) est de plus en plus utilis\u00e9e pour traiter les donn\u00e9es massives g\u00e9n\u00e9r\u00e9es par les objets connect\u00e9s dans l'Internet des objets (IoT). La combinaison de l'IA et du Big Data permet d'optimiser les processus d'analyse et de pr\u00e9diction, offrant ainsi de nouvelles possibilit\u00e9s pour les entreprises et les organisations.</p> <p>Une des principales applications de l'IA dans le Big Data et l'IoT est l'analyse pr\u00e9dictive. Les mod\u00e8les de pr\u00e9diction bas\u00e9s sur l'IA peuvent \u00eatre utilis\u00e9s pour pr\u00e9voir la maintenance des \u00e9quipements, la consommation d'\u00e9nergie ou encore les tendances de vente. Cela permet aux entreprises de planifier efficacement leur maintenance et de maximiser leur rendement. En outre, cela permet d'anticiper les besoins en consommation d'\u00e9nergie et de planifier la production d'\u00e9nergie en cons\u00e9quence. Les tendances de vente peuvent \u00e9galement \u00eatre pr\u00e9vues pour adapter les strat\u00e9gies de marketing et de production.</p> <p>La maintenance pr\u00e9ventive est une autre application importante de l'IA dans le Big Data et l'IoT. Les capteurs int\u00e9gr\u00e9s dans les \u00e9quipements industriels peuvent collecter des donn\u00e9es en temps r\u00e9el sur leur performance. L'IA peut ensuite \u00eatre utilis\u00e9e pour d\u00e9tecter les anomalies et les signes de d\u00e9t\u00e9rioration, permettant ainsi une maintenance pr\u00e9ventive pour \u00e9viter les pannes. Cela permet aux entreprises de r\u00e9duire les co\u00fbts li\u00e9s aux pannes inattendues et de maximiser la disponibilit\u00e9 de leurs \u00e9quipements. Cela contribue \u00e9galement \u00e0 la s\u00e9curit\u00e9 des employ\u00e9s en r\u00e9duisant les risques d'accidents li\u00e9s \u00e0 des \u00e9quipements d\u00e9fectueux.</p> <p>L'IA peut \u00e9galement \u00eatre utilis\u00e9e pour optimiser les r\u00e9seaux de transport et de distribution d'\u00e9nergie. Les donn\u00e9es recueillies par les objets connect\u00e9s peuvent \u00eatre utilis\u00e9es pour planifier les itin\u00e9raires de transport les plus efficaces, ou encore pour r\u00e9guler la production d'\u00e9nergie \u00e9olienne et solaire. Cela permet d'optimiser les itin\u00e9raires de transport, de r\u00e9duire les co\u00fbts de transport et d'am\u00e9liorer la qualit\u00e9 des services de transport. L'IA peut \u00e9galement \u00eatre utilis\u00e9e pour r\u00e9guler la production d'\u00e9nergie renouvelable en fonction des besoins en \u00e9nergie pour maximiser l'utilisation des ressources.</p> <p>Enfin, l'IA peut \u00eatre utilis\u00e9e pour am\u00e9liorer la qualit\u00e9 de vie des individus. Les objets connect\u00e9s peuvent collecter des donn\u00e9es sur les habitudes de vie des individus, permettant ainsi une meilleure compr\u00e9hension de leurs besoins. L'IA peut \u00eatre utilis\u00e9e pour d\u00e9velopper des solutions personnalis\u00e9es en mati\u00e8re de sant\u00e9, de logement ou encore de consommation d'\u00e9nergie. Cela permet de cr\u00e9er des environnements de vie plus confortables et plus sains pour les individus.</p>"},{"location":"projects/big%20data%20for%20iot/#perspectives-futures-du-big-data-et-de-liot","title":"Perspectives futures du Big Data et de l'IoT","text":"<p>Info</p> <p>Pr\u00e9sentation des tendances et perspectives futures du Big Data et de l'IoT, ainsi que leur impact sur les entreprises et la soci\u00e9t\u00e9 en g\u00e9n\u00e9ral.</p> <p>L\u2019internet des objets est l\u2019une des innovations qui fa\u00e7onneront fortement notre avenir. Grace \u00e0 son fort progr\u00e8s au cours du temps, il serait possible de connecter la majorit\u00e9 des appareils qui nous entourent et ainsi exploiter le Big Data partag\u00e9 dans tous les aspects de notre vie. Voici les principales fa\u00e7ons dont l\u2019IOT et le Big Data impacteront les entreprises en particulier et la soci\u00e9t\u00e9 en g\u00e9n\u00e9ral :</p>"},{"location":"projects/big%20data%20for%20iot/#marketing-personnalise","title":"Marketing personnalis\u00e9","text":"<p>Gr\u00e2ce aux donn\u00e9es g\u00e9n\u00e9r\u00e9es par les appareils interconnect\u00e9s, il serait possible de cibler le bon public et de lui transmettre le bon message au moment le plus id\u00e9al. Ainsi, les gens recevront toute sorte de publicit\u00e9 ou promotion qui correspond parfaitement \u00e0 leurs comportements d\u2019achat et \u00e0 leurs int\u00e9r\u00eats, ce qui rend les chances de se rapprocher d\u2019un client plus probables, certaines et m\u00eame inimaginables.  D\u2019ailleurs, les entreprises d\u2019aujourd\u2019hui essaient de tirer profit au maximum de l\u2019ensemble des technologies \u00e9mergentes afin d\u2019augmenter les r\u00e9sultats et d\u00e9velopper des campagnes marketing tr\u00e8s efficace capables de bien g\u00e9rer le budget qui leur est d\u00e9di\u00e9.</p>"},{"location":"projects/big%20data%20for%20iot/#villes-intelligentes","title":"Villes intelligentes","text":"<p>L\u2019IOT et le Big Data participeront fortement \u00e0 la modernisation de nos villes via l\u2019adoption de certaines appareils interconnect\u00e9s capables de collecter un maximum de donn\u00e9es en temps r\u00e9el et l\u2019application majeure de l\u2019intelligence artificielle dans le but de rendre les technologies existantes plus intelligentes et ad\u00e9quates. Ainsi, la ville de demain sera \u00e9quip\u00e9e par des contr\u00f4leurs du trafic servant \u00e0 la pr\u00e9diction du danger sur la route, des routes solaires contenant des panneaux photovolta\u00efques pour avertir les conducteurs en cas d\u2019obstacle ou animal, des arr\u00eats de bus intelligents qui activent et d\u00e9sactivent le chauffage et la climatisation de fa\u00e7on automatique\u2026</p>"},{"location":"projects/big%20data%20for%20iot/#prise-de-decision-amelioree","title":"Prise de d\u00e9cision am\u00e9lior\u00e9e","text":"<p>L\u2019acc\u00e8s en temps r\u00e9el \u00e0 un maximum d\u2019informations tangibles permettra aux entreprises et aux d\u00e9tenteurs de magasin de prendre la bonne d\u00e9cision, d\u2019anticiper les risques les plus mena\u00e7ants et d\u2019\u00e9conomiser les d\u00e9penses. Ils sauront interpr\u00e9ter et surveiller l\u2019ensemble des donn\u00e9es r\u00e9colt\u00e9es par les capteurs IOT pour d\u00e9duire le bon volume \u00e0 produire, les types de produits les plus vendus, la saisonnalit\u00e9 des ventes\u2026, ce qui conduira \u00e0 une efficacit\u00e9 accrue, \u00e0 des couts op\u00e9rationnels r\u00e9duits et \u00e0 un retour sur investissement plus \u00e9lev\u00e9.</p>"},{"location":"projects/big%20data%20for%20iot/#chaine-dapprovisionnement-optimisee","title":"Chaine d\u2019approvisionnement optimis\u00e9e","text":"<p>La mise en \u0153uvre de l\u2019IOT et du Big Data permettra de bien contr\u00f4ler le flux du produit : de l\u2019approvisionnement en mati\u00e8res premi\u00e8res jusqu\u2019\u00e0 la distribution du produit final. En connectant les processus et les personnes, il serait possible de mesurer les informations collect\u00e9es, de les \u00e9changer et de les analyser par des tableaux de bord afin de prendre des d\u00e9cisions proactives bas\u00e9es sur les donn\u00e9es et superviser la chaine d\u2019approvisionnement dans sa totalit\u00e9.</p>"},{"location":"projects/big%20data%20for%20iot/#organisations-et-systemes-de-sante-developpes","title":"Organisations et syst\u00e8mes de sant\u00e9 d\u00e9velopp\u00e9s","text":"<p>Les soins pour les patients peuvent \u00eatre, gr\u00e2ce \u00e0 la m\u00e9decine de pr\u00e9cision favoris\u00e9e par l\u2019IOT et le Big Data, consid\u00e9rablement am\u00e9lior\u00e9s comme leurs qualit\u00e9s de vie. Il serait possible de collecter un maximum de donn\u00e9es sur leurs programmes de m\u00e9dicament via des capteurs ou montres intelligents sans n\u00e9cessit\u00e9 de recourir constamment aux analyses et aux m\u00e9decins. De plus, il serait possible de localiser avec un simple clic les h\u00f4pitaux et les ambulances qui sont les plus proches, de pr\u00e9dire avec pr\u00e9cision les maladies et de d\u00e9velopper de nouveaux m\u00e9dicaments en se basant sur l\u2019analyse des donn\u00e9es cliniques.</p>"},{"location":"projects/big%20data%20for%20iot/#agriculture-connectee","title":"Agriculture connect\u00e9e","text":"<p>Le Big Data collect\u00e9 via les tracteurs, animaux, drones et machines de r\u00e9colte connect\u00e9s permettra aux agriculteurs dans le futur proche d\u2019am\u00e9liorer le rendement de leurs terres et fermes. Ils seront capables d\u2019acc\u00e9der en temps r\u00e9el aux informations qui lui sont assez importantes, d\u2019anticiper les maladies des cultures pour faire les pr\u00e9cautions n\u00e9cessaires et d\u2019optimiser l\u2019irrigation et l\u2019emploi des fertilisants. D\u2019o\u00f9 une agriculture future \u00e9cologique, \u00e9conome et de haute pr\u00e9cision.</p>"},{"location":"projects/big%20data%20for%20iot/#gestion-de-transport-amelioree","title":"Gestion de transport am\u00e9lior\u00e9e","text":"<p>L\u2019IOT et le Big Data jouent un r\u00f4le important pour les diff\u00e9rents types de syst\u00e8mes de transport : maritime, a\u00e9rien, ferroviaire et routier. Ils permettront de garantir un transport de services et biens s\u00e9curis\u00e9, de coordonner efficacement l\u2019exp\u00e9dition et d\u2019assurer en permanence la connectivit\u00e9 r\u00e9seau sur les routes. De plus, ils serviront \u00e0 anticiper la maintenance et l\u2019entretien des \u00e9quipements, \u00e0 contr\u00f4ler toute pollution d\u00e9gag\u00e9e des moyens de transport et \u00e0 r\u00e9duire le recrutement des chauffeurs \u00e0 cause des v\u00e9hicules autonomes. Ainsi, la gestion du transport de demain serait plus simple, efficace et s\u00e9curis\u00e9e.</p>"},{"location":"projects/big%20data%20for%20iot/#consommation-energetique-optimisee","title":"Consommation \u00e9nerg\u00e9tique optimis\u00e9e","text":"<p>Gr\u00e2ce \u00e0 la collecte instantan\u00e9e en temps r\u00e9el des donn\u00e9es li\u00e9es \u00e0 la consommation et aux pertes \u00e9nerg\u00e9tiques, il serait possible d\u2019identifier l\u2019ensemble des comportements \u00e0 optimiser et \u00e9viter le gaspillage des ressources. De plus, les consommateurs particuliers ou entreprises disposeront d\u2019algorithmes leur permettant de pr\u00e9dire leur consommation \u00e9nerg\u00e9tique d\u00e9pendamment d\u2019appareils ou machines utilis\u00e9es, de r\u00e9duire leurs d\u00e9penses et d\u2019am\u00e9liorer le confort logement. Ainsi, les comportements \u00e9nerg\u00e9tiques futurs seraient plus sobres et r\u00e9pondent \u00e0 la neutralit\u00e9 carbone et aux enjeux \u00e9nerg\u00e9tiques les plus complexes. </p>"},{"location":"projects/big%20data%20for%20iot/#metiers-nouveaux","title":"M\u00e9tiers nouveaux","text":"<p>Gr\u00e2ce \u00e0 l\u2019\u00e9volution remarquable de l\u2019impl\u00e9mentation de l\u2019IOT et de l\u2019exploitation du Big Data, les m\u00e9tiers d\u2019avenir seront focalis\u00e9s sur tout ce qui est digitalisation et intelligence artificielle. Voici quelques exemples des m\u00e9tiers les plus incontournables dans le futur proche : Data Engineer, ing\u00e9nieur DevOps/Cloud, architecte Big Data, Data Analyst, Data Scientist, Tech Lead Big Data\u2026</p>"},{"location":"projects/big%20data%20for%20iot/#conclusion","title":"Conclusion","text":"<p>Info</p> <p>Synth\u00e8se des principaux points abord\u00e9s dans l'expos\u00e9 et \u00e9ventuelles r\u00e9flexions sur l'avenir du Big Data et de l'IoT.</p> <p>En conclusion, il est clair que le Big Data et l'IoT ont un impact significatif sur les entreprises et la soci\u00e9t\u00e9 en g\u00e9n\u00e9ral. Les avanc\u00e9es technologiques en cours permettront de collecter et de traiter des volumes encore plus importants de donn\u00e9es, offrant ainsi de nouvelles opportunit\u00e9s pour optimiser les processus d'analyse et de pr\u00e9diction. Cependant, il est important de noter que ces technologies posent \u00e9galement des d\u00e9fis en mati\u00e8re de s\u00e9curit\u00e9 et de confidentialit\u00e9 des donn\u00e9es. Il est donc crucial de continuer \u00e0 d\u00e9velopper des approches et des outils pour g\u00e9rer efficacement ces donn\u00e9es massives tout en prot\u00e9geant les int\u00e9r\u00eats des utilisateurs.</p>"},{"location":"projects/boston%20datasets/","title":"Boston Dataset","text":""},{"location":"projects/boston%20datasets/#bibliotheques","title":"Biblioth\u00e8ques","text":"<p>Tout d'abord, ex\u00e9cutons la cellule ci-dessous pour importer tous les paquets dont vous aurez besoin au cours de cette \u00e9tude.</p> <ul> <li> <p>pandas est une biblioth\u00e8que \u00e9crite pour le langage de programmation Python permettant la manipulation et l'analyse des donn\u00e9es.</p> </li> <li> <p>numpy est une biblioth\u00e8que pour langage de programmation Python, destin\u00e9e \u00e0 manipuler des matrices ou tableaux multidimensionnels ainsi que des fonctions math\u00e9matiques op\u00e9rant sur ces tableaux.</p> </li> <li> <p>matplotlib est une biblioth\u00e8que du langage de programmation Python destin\u00e9e \u00e0 tracer et visualiser des donn\u00e9es sous forme de graphiques.</p> </li> <li> <p>seaborn est une biblioth\u00e8que de visualisation Python bas\u00e9e sur matplotlib. Elle fournit une interface de haut niveau pour dessiner des graphiques statistiques attrayants.</p> </li> <li> <p>keras est l'API de haut niveau de TensorFlow.</p> </li> <li> <p>sklearn est une biblioth\u00e8que libre Python destin\u00e9e \u00e0 l'apprentissage automatique. </p> </li> <li>pickle est principalement utilis\u00e9 pour s\u00e9rialiser et d\u00e9s\u00e9rialiser une structure objet Python. En d'autres termes, c'est le processus de conversion d'un objet Python en un flux d'octets pour le stocker dans un fichier/base de donn\u00e9es, maintenir l'\u00e9tat du programme entre les sessions ou transporter des donn\u00e9es sur le r\u00e9seau.</li> </ul> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom keras import layers\nimport seaborn as sns\nimport pickle\nfrom sklearn import svm\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\n</code></pre>"},{"location":"projects/boston%20datasets/#etude-exploratoire-des-donnees","title":"Etude exploratoire des donn\u00e9es","text":""},{"location":"projects/boston%20datasets/#definition-des-colonnes","title":"D\u00e9finition des colonnes","text":"<p>Dans le domaine de la science des donn\u00e9es, la premi\u00e8re chose \u00e0 faire est de bien comprendre les donn\u00e9es, ainsi et dans ce m\u00eame sens, nous avons d\u00e9fini les colonnes comme suit :</p> <ul> <li> <p><code>CRIM</code>: per capita crime rate by town.</p> </li> <li> <p><code>ZN</code>: proportion of residential land zoned for lots over 25,000 sq.ft.</p> </li> <li> <p><code>INDUS</code>: proportion of non-retail business acres per town.</p> </li> <li> <p><code>CHAS</code>: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).</p> </li> <li> <p><code>NOX</code>: nitric oxides concentration (parts per 10 million).</p> </li> <li> <p><code>RM</code>: average number of rooms per dwelling.</p> </li> <li> <p><code>AGE</code>: proportion of owner-occupied units built prior to 1940.</p> </li> <li> <p><code>DIS</code>: weighted distances to five Boston employment centres.</p> </li> <li> <p><code>RAD</code>: index of accessibility to radial highways.</p> </li> <li> <p><code>TAX</code>: full-value property-tax rate per $10,000.</p> </li> <li> <p><code>PTRATIO</code>: pupil-teacher ratio by town.</p> </li> <li> <p><code>B</code>: 1000(Bk - 0.63)^2 where Bk is the proportion of black people by town.</p> </li> <li> <p><code>LSTAT</code>: % lower status of the population.</p> </li> <li> <p><code>MEDV</code>: our Target, Median value of owner-occupied homes in $1000's</p> </li> </ul>"},{"location":"projects/boston%20datasets/#feature-engineering","title":"Feature engineering","text":"<p><pre><code># Importer le dataset\nfrom sklearn.datasets import load_boston\nboston = load_boston()\n</code></pre> <pre><code># Afficher les \u00e9\u00e9ments cl\u00e9s du dataset\nboston.keys()\n</code></pre></p> Output <p>dict_keys(['data', 'target', 'feature_names', 'DESCR', 'filename', 'data_module'])</p> <pre><code>## Afficher la description du dataset\nprint(boston.DESCR)\n</code></pre> Output <p>.. _boston_dataset:</p> <p>Boston house prices dataset</p> <p>Data Set Characteristics: </p> <pre><code>:Number of Instances: 506\n\n:Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n\n:Attribute Information (in order):\n    - CRIM     per capita crime rate by town\n    - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n    - INDUS    proportion of non-retail business acres per town\n    - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n    - NOX      nitric oxides concentration (parts per 10 million)\n    - RM       average number of rooms per dwelling\n    - AGE      proportion of owner-occupied units built prior to 1940\n    - DIS      weighted distances to five Boston employment centres\n    - RAD      index of accessibility to radial highways\n    - TAX      full-value property-tax rate per $10,000\n    - PTRATIO  pupil-teacher ratio by town\n    - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\n    - LSTAT    % lower status of the population\n    - MEDV     Median value of owner-occupied homes in $1000's\n\n:Missing Attribute Values: None\n\n:Creator: Harrison, D. and Rubinfeld, D.L.\n</code></pre> <p>This is a copy of UCI ML housing dataset. https://archive.ics.uci.edu/ml/machine-learning-databases/housing/</p> <p>This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.</p> <p>The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic prices and the demand for clean air', J. Environ. Economics &amp; Management, vol.5, 81-102, 1978.   Used in Belsley, Kuh &amp; Welsch, 'Regression diagnostics ...', Wiley, 1980.   N.B. Various transformations are used in the table on pages 244-261 of the latter.</p> <p>The Boston house-price data has been used in many machine learning papers that address regression problems.   </p> <p>.. topic:: References</p> <ul> <li>Belsley, Kuh &amp; Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.</li> <li>Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.</li> </ul> <pre><code># Afficher le contenu des features \nprint(boston.data)\n</code></pre> Output <p>[[6.3200e-03 1.8000e+01 2.3100e+00 ... 1.5300e+01 3.9690e+02 4.9800e+00]</p> <p>[2.7310e-02 0.e+00 7.0700e+00 ... 1.7800e+01 3.9690e+02 9.1400e+00]</p> <p>[2.7290e-02 0.e+00 7.0700e+00 ... 1.7800e+01 3.9283e+02 4.0300e+00]</p> <p>...</p> <p>[6.0760e-02 0.e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 5.6400e+00]</p> <p>[1.0959e-01 0.e+00 1.1930e+01 ... 2.1000e+01 3.9345e+02 6.4800e+00]</p> <p>[4.7410e-02 0.e+00 1.1930e+01 ... 2.1000e+01 3.9690e+02 7.8800e+00]]</p> <pre><code># Afficher le contenu du label\nprint(boston.target)\n</code></pre> Output <p>[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50. 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20. 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2 9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5. 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7. 8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9 22.  11.9]</p> <pre><code># Afficher les noms des features\nprint(boston.feature_names)\n</code></pre> Output <p>['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO' 'B' 'LSTAT']</p> <p><pre><code># Transformer le boston dataset en Data Frame\ndataset = pd.DataFrame(boston.data,columns=boston.feature_names)\n</code></pre> <pre><code># Afficher les 5 premi\u00e8res lignes du dataset\ndataset.head(5)\n</code></pre></p> Output CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT 0 0.00632 18.0 2.31 0.0 0.538 6.575 65.2 4.0900 1.0 296.0 15.3 396.90 4.98 1 0.02731 0.0 7.07 0.0 0.469 6.421 78.9 4.9671 2.0 242.0 17.8 396.90 9.14 2 0.02729 0.0 7.07 0.0 0.469 7.185 61.1 4.9671 2.0 242.0 17.8 392.83 4.03 3 0.03237 0.0 2.18 0.0 0.458 6.998 45.8 6.0622 3.0 222.0 18.7 394.63 2.94 4 0.06905 0.0 2.18 0.0 0.458 7.147 54.2 6.0622 3.0 222.0 18.7 396.90 5.33 <p><pre><code># Ajouter le label au dataset et lui nommer \"Price\"\ndataset['MEDV'] = boston.target\n</code></pre> <pre><code># Afficher quelques informations de la data\ndataset.info()\n</code></pre></p> Output <p><code>&lt;class 'pandas.core.frame.DataFrame'&gt;</code></p> <p>RangeIndex: 506 entries, 0 to 505</p> <p>Data columns (total 14 columns):</p> # Column Non-Null Count Dtype 0 CRIM 506 non-null float64 1 ZN 506 non-null float64 2 INDUS 506 non-null float64 3 CHAS 506 non-null float64 4 NOX 506 non-null float64 5 RM 506 non-null float64 6 AGE 506 non-null float64 7 DIS 506 non-null float64 8 RAD 506 non-null float64 9 TAX 506 non-null float64 10 PTRATIO 506 non-null float64 11 B 506 non-null float64 12 LSTAT 506 non-null float64 13 MEDV 506 non-null float64 <p>dtypes: float64(14)</p> <p>memory usage: 55.5 KB</p> <ul> <li>Le Dataset contient 506 lignes et 14 colonnes.</li> <li>toutes les colonnes sont de type float64.</li> </ul> <pre><code># Afficher une description statistique de la dataset\ndataset.describe()\n</code></pre> Output CRIM ZN INDUS CHAS NOX RM AGE DIS RAD TAX PTRATIO B LSTAT MEDV count 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 506.00 mean 3.61 11.36 11.13 0.06 0.55 6.28 68.57 3.79 9.54 408.23 18.45 356.67 12.65 22.53 std 8.60 23.32 6.86 0.25 0.11 0.70 28.14 2.10 8.70 168.53 2.16 91.29 7.14 9.19 min 0.006 0.00 0.46 0.00 0.38 3.56 2.90 1.12 1.00 187.00 12.60 0.32 1.73 5.00 25% 0.08 0.00 5.19 0.00 0.44 5.88 45.02 2.10 4.00 279.00 17.40 375.37 6.95 17.02 50% 0.25 0.00 9.69 0.00 0.53 6.20 77.50 3.20 5.00 330.00 19.05 391.44 11.36 21.20 75% 3.67 12.50 18.10 0.00 0.62 6.62 94.07 5.18 24.00 666.00 20.20 396.22 16.95 25.00 max 88.97 100.00 27.74 1.00 0.87 8.78 100.00 12.12 24.00 711.00 22.00 396.90 37.97 50.00 <pre><code># Afficher les valeurs NaN\ndataset.isnull().sum()\n</code></pre> Output Column Number of NaN CRIM 0 ZN 0 INDUS 0 CHAS 0 NOX 0 RM 0 AGE 0 DIS 0 RAD 0 TAX 0 PTRATIO 0 B 0 LSTAT 0 MEDV 0 <p>dtype: int64</p> <p>Note</p> <p>Nous notons que le dataset ne contient pas de valeurs <code>NaN</code>.</p>"},{"location":"projects/boston%20datasets/#vizualisation-des-donnees","title":"Vizualisation des donn\u00e9es","text":""},{"location":"projects/boston%20datasets/#matrice-de-correlation","title":"Matrice de corr\u00e9lation","text":"<p>La matrice de corr\u00e9lation indique les valeurs de corr\u00e9lation, qui mesurent le degr\u00e9 de relation lin\u00e9aire entre chaque paire de variables. Les valeurs de corr\u00e9lation peuvent \u00eatre comprises entre -1 et +1. Si les deux variables ont tendance \u00e0 augmenter et \u00e0 diminuer en m\u00eame temps, la valeur de corr\u00e9lation est positive. Lorsqu'une variable augmente alors que l'autre diminue, la valeur de corr\u00e9lation est n\u00e9gative.</p> <pre><code># Afficher la matrice de corr\u00e9lation\nmatriceCorr = data.corr().round(1)\nsns.heatmap(data=matriceCorr, annot = True)\n</code></pre> Output <p></p> <p>Note</p> <p>Nous notons qu'il y a plusieurs correlations entre les colonnes, mais nous n'allons pas prendre en consid\u00e9ration ces corr\u00e9lations pour l'instant parce que les r\u00e9seaux de neuronnes peuvent d\u00e9tecter les corr\u00e9lations ainsi les traiter. </p>"},{"location":"projects/boston%20datasets/#representations-des-colonnes-deux-a-deux","title":"Repr\u00e9sentations des colonnes deux \u00e0 deux","text":"<pre><code># Afficher les repr\u00e9sentations des colonnes deux \u00e0 deux\nsns.pairplot(dataset)\n</code></pre> Output <pre><code># Afficher \"MEDV\" en fonction de \"CRIM\"\nplt.scatter(dataset['CRIM'],dataset['MEDV'])\nplt.xlabel(\"Crime Rate\")\nplt.ylabel(\"Medv\")\n</code></pre> Output <pre><code># Afficher \"RM\" en fonction de \"MEDV\"\nplt.scatter(dataset['RM'],dataset['MEDV'])\nplt.xlabel(\"RM\")\nplt.ylabel(\"Medv\")\n</code></pre> Output <pre><code># Tracer les donn\u00e9es et l'ajustement d'un mod\u00e8le de r\u00e9gression lin\u00e9aire MEDV=f(RM)\nsns.regplot(x=\"RM\",y=\"MEDV\",data=dataset)\n</code></pre> Output <pre><code># Tracer les donn\u00e9es et l'ajustement d'un mod\u00e8le de r\u00e9gression lin\u00e9aire MEDV=f(LSTAT)\nsns.regplot(x=\"LSTAT\",y=\"MEDV\",data=dataset)\n</code></pre> Output <pre><code># Tracer les donn\u00e9es et l'ajustement d'un mod\u00e8le de r\u00e9gression lin\u00e9aire MEDV=f(CHAS)\nsns.regplot(x=\"CHAS\",y=\"MEDV\",data=dataset)\n</code></pre> Output <pre><code># Tracer les donn\u00e9es et l'ajustement d'un mod\u00e8le de r\u00e9gression lin\u00e9aire MEDV=f(PTRATIO)\nsns.regplot(x=\"PTRATIO\",y=\"MEDV\",data=dataset)\n</code></pre> Output"},{"location":"projects/boston%20datasets/#implementation-des-modeles","title":"Impl\u00e9mentation des mod\u00e8les","text":""},{"location":"projects/boston%20datasets/#preparation-des-des-vecteurs-dentrainement","title":"Pr\u00e9paration des des vecteurs d'entrainement","text":"<p>Maintenant nous allons impl\u00e9menter et entrainer plusieurs mod\u00e8les de machine learning afin de choisir le meilleur, mais avant nous devons d\u00e9finir les features, le target et d\u00e9composer le dataset en data d'entrainement et data du test.  </p> <p><pre><code># D\u00e9finir les features\nX = dataset.drop('MEDV', axis=1)\n\n# D\u00e9finir le target\ny = dataset['MEDV']\n</code></pre> <pre><code># D\u00e9composer la data en 80% pour l'entrainement et 20% pour le test\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n</code></pre> <pre><code># Afficher la taille de X_train, X_test, y_train, y_test\nprint(\"la taille de X_train est :\", X_train.shape)\nprint(\"la taille de X_test est :\", X_test.shape)\nprint(\"la taille de y_train est :\", y_train.shape)\nprint(\"la taille de y_test est :\", y_test.shape)\n</code></pre></p> Output <p>la taille de X_train est : (404, 13)</p> <p>la taille de X_test est : (102, 13)</p> <p>la taille de y_train est : (404,)</p> <p>la taille de y_test est : (102,)</p> <pre><code># Norrmalisation des donn\u00e9es en utilisant le StandardScaler (x-mean)/(std)\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.transform(X_test)\n</code></pre>"},{"location":"projects/boston%20datasets/#reseaux-de-neurones-denses-dnn","title":"R\u00e9seaux de neurones denses DNN","text":"<p><pre><code>num_layer1 = 50\nnum_layer2 = 50\n\nmodel = keras.models.Sequential(name='DNN')\nmodel.add(layers.Input((13,), name=\"Couche_in\"))\nmodel.add(layers.Dense(num_layer1, activation='relu', name='Couche_cachee1'))\nmodel.add(layers.Dense(num_layer2, activation='relu', name='Couche_cachee2'))\nmodel.add(layers.Dense(1, name='Couche_out'))\n</code></pre> <pre><code>model.compile(optimizer='adam',\n              loss='mse',\n              metrics=['mae'])\n</code></pre> <pre><code>model.summary()\n</code></pre></p> Output <p>Model: \"DNN\"</p> Layer (type) Output Shape Param # Couche_cachee1 (Dense) (None, 50) 700 Couche_cachee2 (Dense) (None, 50) 2550 Couche_out (Dense) (None, 1) 51 <p>Total params: 3,301</p> <p>Trainable params: 3,301</p> <p>Non-trainable params: 0</p> <pre><code># Lancer l'entrainement du mod\u00e8le\nhist = model.fit(X_train,\n                 y_train,\n                 epochs=400,\n                 batch_size=50)\n</code></pre> Output <p>Epoch 1/400 9/9 [==============================] - 1s 4ms/step - loss: 557.3136 - mae: 21.6968</p> <p>Epoch 2/400 9/9 [==============================] - 0s 3ms/step - loss: 520.2143 - mae: 20.8262</p> <p>Epoch 3/400 9/9 [==============================] - 0s 3ms/step - loss: 475.9985 - mae: 19.7651</p> <p>Epoch 4/400 9/9 [==============================] - 0s 3ms/step - loss: 423.2747 - mae: 18.4109</p> <p>Epoch 5/400 9/9 [==============================] - 0s 3ms/step - loss: 361.1457 - mae: 16.7136</p> <p>Epoch 6/400 9/9 [==============================] - 0s 3ms/step - loss: 289.6600 - mae: 14.6173</p> <p>Epoch 7/400 9/9 [==============================] - 0s 3ms/step - loss: 219.4651 - mae: 12.2325</p> <p>Epoch 8/400 9/9 [==============================] - 0s 3ms/step - loss: 158.8683 - mae: 10.0692</p> <p>Epoch 9/400 9/9 [==============================] - 0s 3ms/step - loss: 116.7818 - mae: 8.3857</p> <p>Epoch 10/400 9/9 [==============================] - 0s 3ms/step - loss: 91.9504 - mae: 7.3596</p> <p>Epoch 11/400 9/9 [==============================] - 0s 3ms/step - loss: 76.5844 - mae: 6.6405</p> <p>Epoch 12/400 9/9 [==============================] - 0s 8ms/step - loss: 62.4096 - mae: 5.9445</p> <p>Epoch 13/400 9/9 [==============================] - 0s 3ms/step - loss: 49.9997 - mae: 5.3151</p> <p>Epoch 14/400 9/9 [==============================] - 0s 3ms/step - loss: 40.8705 - mae: 4.8252</p> <p>Epoch 15/400 9/9 [==============================] - 0s 3ms/step - loss: 34.1865 - mae: 4.4059</p> <p>Epoch 16/400 9/9 [==============================] - 0s 3ms/step - loss: 29.6209 - mae: 4.0728</p> <p>Epoch 17/400 9/9 [==============================] - 0s 3ms/step - loss: 26.3418 - mae: 3.8037</p> <p>Epoch 18/400 9/9 [==============================] - 0s 3ms/step - loss: 24.0514 - mae: 3.6174</p> <p>Epoch 19/400 9/9 [==============================] - 0s 3ms/step - loss: 22.3640 - mae: 3.4849</p> <p>Epoch 20/400 9/9 [==============================] - 0s 3ms/step - loss: 21.0404 - mae: 3.3751</p> <p>Epoch 21/400 9/9 [==============================] - 0s 3ms/step - loss: 20.0787 - mae: 3.2945</p> <p>Epoch 22/400 9/9 [==============================] - 0s 4ms/step - loss: 19.1893 - mae: 3.2271</p> <p>Epoch 23/400 9/9 [==============================] - 0s 3ms/step - loss: 18.4744 - mae: 3.1858</p> <p>Epoch 24/400 9/9 [==============================] - 0s 3ms/step - loss: 17.9731 - mae: 3.1562</p> <p>Epoch 25/400 9/9 [==============================] - 0s 3ms/step - loss: 17.4404 - mae: 3.0923</p> <p>Epoch 26/400 9/9 [==============================] - 0s 3ms/step - loss: 16.9731 - mae: 3.0298</p> <p>Epoch 27/400 9/9 [==============================] - 0s 3ms/step - loss: 16.6027 - mae: 2.9926</p> <p>Epoch 28/400 9/9 [==============================] - 0s 3ms/step - loss: 16.2943 - mae: 2.9884</p> <p>Epoch 29/400 9/9 [==============================] - 0s 3ms/step - loss: 16.1183 - mae: 2.9904</p> <p>Epoch 30/400 9/9 [==============================] - 0s 3ms/step - loss: 15.8298 - mae: 2.9535</p> <p>Epoch 31/400 9/9 [==============================] - 0s 3ms/step - loss: 15.4369 - mae: 2.8914</p> <p>Epoch 32/400 9/9 [==============================] - 0s 3ms/step - loss: 15.2457 - mae: 2.8531</p> <p>Epoch 33/400 9/9 [==============================] - 0s 3ms/step - loss: 15.0859 - mae: 2.8292</p> <p>Epoch 34/400 9/9 [==============================] - 0s 3ms/step - loss: 14.8123 - mae: 2.8021</p> <p>Epoch 35/400 9/9 [==============================] - 0s 2ms/step - loss: 14.7016 - mae: 2.8349</p> <p>Epoch 36/400 9/9 [==============================] - 0s 3ms/step - loss: 14.7392 - mae: 2.8583</p> <p>Epoch 37/400 9/9 [==============================] - 0s 3ms/step - loss: 14.4040 - mae: 2.7936</p> <p>Epoch 38/400 9/9 [==============================] - 0s 3ms/step - loss: 14.1673 - mae: 2.7549</p> <p>Epoch 39/400 9/9 [==============================] - 0s 3ms/step - loss: 14.0135 - mae: 2.7394</p> <p>Epoch 40/400 9/9 [==============================] - 0s 3ms/step - loss: 13.7766 - mae: 2.7193</p> <p>Epoch 41/400 9/9 [==============================] - 0s 3ms/step - loss: 13.6497 - mae: 2.7049</p> <p>Epoch 42/400 9/9 [==============================] - 0s 3ms/step - loss: 13.8148 - mae: 2.7279</p> <p>Epoch 43/400 9/9 [==============================] - 0s 3ms/step - loss: 13.5806 - mae: 2.7368</p> <p>Epoch 44/400 9/9 [==============================] - 0s 4ms/step - loss: 13.3692 - mae: 2.6903</p> <p>Epoch 45/400 9/9 [==============================] - 0s 3ms/step - loss: 13.1967 - mae: 2.6587</p> <p>Epoch 46/400 9/9 [==============================] - 0s 3ms/step - loss: 13.0199 - mae: 2.6454</p> <p>Epoch 47/400 9/9 [==============================] - 0s 3ms/step - loss: 13.0109 - mae: 2.6521</p> <p>Epoch 48/400 9/9 [==============================] - 0s 3ms/step - loss: 12.9398 - mae: 2.6408</p> <p>Epoch 49/400 9/9 [==============================] - 0s 3ms/step - loss: 12.8580 - mae: 2.6236</p> <p>Epoch 50/400 9/9 [==============================] - 0s 3ms/step - loss: 12.8581 - mae: 2.6218</p> <p>Epoch 51/400 9/9 [==============================] - 0s 3ms/step - loss: 12.7277 - mae: 2.6095</p> <p>Epoch 52/400 9/9 [==============================] - 0s 3ms/step - loss: 12.5262 - mae: 2.5825</p> <p>Epoch 53/400 9/9 [==============================] - 0s 3ms/step - loss: 12.5404 - mae: 2.5921</p> <p>Epoch 54/400 9/9 [==============================] - 0s 3ms/step - loss: 12.3580 - mae: 2.5644</p> <p>Epoch 55/400 9/9 [==============================] - 0s 3ms/step - loss: 12.2630 - mae: 2.5534</p> <p>Epoch 56/400 9/9 [==============================] - 0s 3ms/step - loss: 12.1893 - mae: 2.5394</p> <p>Epoch 57/400 9/9 [==============================] - 0s 4ms/step - loss: 12.0945 - mae: 2.5230</p> <p>Epoch 58/400 9/9 [==============================] - 0s 3ms/step - loss: 12.1561 - mae: 2.5299</p> <p>Epoch 59/400 9/9 [==============================] - 0s 3ms/step - loss: 12.0405 - mae: 2.5175</p> <p>Epoch 60/400 9/9 [==============================] - 0s 3ms/step - loss: 12.0079 - mae: 2.4976</p> <p>Epoch 61/400 9/9 [==============================] - 0s 3ms/step - loss: 11.8621 - mae: 2.4903</p> <p>Epoch 62/400 9/9 [==============================] - 0s 3ms/step - loss: 11.7536 - mae: 2.4790</p> <p>Epoch 63/400 9/9 [==============================] - 0s 3ms/step - loss: 11.8308 - mae: 2.4806</p> <p>Epoch 64/400 9/9 [==============================] - 0s 3ms/step - loss: 11.8091 - mae: 2.4820</p> <p>Epoch 65/400 9/9 [==============================] - 0s 3ms/step - loss: 11.6384 - mae: 2.4957</p> <p>Epoch 66/400 9/9 [==============================] - 0s 3ms/step - loss: 11.8385 - mae: 2.5424</p> <p>Epoch 67/400 9/9 [==============================] - 0s 4ms/step - loss: 11.7600 - mae: 2.5212</p> <p>Epoch 68/400 9/9 [==============================] - 0s 3ms/step - loss: 11.4665 - mae: 2.4539</p> <p>Epoch 69/400 9/9 [==============================] - 0s 3ms/step - loss: 11.4085 - mae: 2.4327</p> <p>Epoch 70/400 9/9 [==============================] - 0s 3ms/step - loss: 11.3790 - mae: 2.4286</p> <p>Epoch 71/400 9/9 [==============================] - 0s 4ms/step - loss: 11.2816 - mae: 2.4209</p> <p>Epoch 72/400 9/9 [==============================] - 0s 4ms/step - loss: 11.2071 - mae: 2.4173</p> <p>Epoch 73/400 9/9 [==============================] - 0s 3ms/step - loss: 11.1422 - mae: 2.4088</p> <p>Epoch 74/400 9/9 [==============================] - 0s 3ms/step - loss: 11.0773 - mae: 2.4023</p> <p>Epoch 75/400 9/9 [==============================] - 0s 3ms/step - loss: 11.0161 - mae: 2.3964</p> <p>Epoch 76/400 9/9 [==============================] - 0s 4ms/step - loss: 11.0054 - mae: 2.3888</p> <p>Epoch 77/400 9/9 [==============================] - 0s 3ms/step - loss: 10.8978 - mae: 2.3807</p> <p>Epoch 78/400 9/9 [==============================] - 0s 3ms/step - loss: 10.8926 - mae: 2.3930</p> <p>Epoch 79/400 9/9 [==============================] - 0s 3ms/step - loss: 10.9182 - mae: 2.3996</p> <p>Epoch 80/400 9/9 [==============================] - 0s 3ms/step - loss: 10.9850 - mae: 2.4115</p> <p>Epoch 81/400 9/9 [==============================] - 0s 3ms/step - loss: 11.0064 - mae: 2.3867</p> <p>Epoch 82/400 9/9 [==============================] - 0s 3ms/step - loss: 11.1898 - mae: 2.3889</p> <p>Epoch 83/400 9/9 [==============================] - 0s 3ms/step - loss: 10.7470 - mae: 2.3746</p> <p>Epoch 84/400 9/9 [==============================] - 0s 3ms/step - loss: 10.8092 - mae: 2.4083</p> <p>Epoch 85/400 9/9 [==============================] - 0s 3ms/step - loss: 10.5877 - mae: 2.3942</p> <p>Epoch 86/400 9/9 [==============================] - 0s 4ms/step - loss: 10.5039 - mae: 2.3632</p> <p>Epoch 87/400 9/9 [==============================] - 0s 3ms/step - loss: 10.5263 - mae: 2.3636</p> <p>Epoch 88/400 9/9 [==============================] - 0s 3ms/step - loss: 10.4007 - mae: 2.3452</p> <p>Epoch 89/400 9/9 [==============================] - 0s 3ms/step - loss: 10.3052 - mae: 2.3390</p> <p>Epoch 90/400 9/9 [==============================] - 0s 3ms/step - loss: 10.2830 - mae: 2.3430</p> <p>Epoch 91/400 9/9 [==============================] - 0s 3ms/step - loss: 10.2626 - mae: 2.3305</p> <p>Epoch 92/400 9/9 [==============================] - 0s 3ms/step - loss: 10.2998 - mae: 2.3301</p> <p>Epoch 93/400 9/9 [==============================] - 0s 3ms/step - loss: 10.3857 - mae: 2.3660</p> <p>Epoch 94/400 9/9 [==============================] - 0s 3ms/step - loss: 10.2242 - mae: 2.3430</p> <p>Epoch 95/400 9/9 [==============================] - 0s 3ms/step - loss: 10.0685 - mae: 2.3185</p> <p>Epoch 96/400 9/9 [==============================] - 0s 3ms/step - loss: 10.0650 - mae: 2.3192</p> <p>Epoch 97/400 9/9 [==============================] - 0s 3ms/step - loss: 10.0117 - mae: 2.3269</p> <p>Epoch 98/400 9/9 [==============================] - 0s 3ms/step - loss: 10.0123 - mae: 2.3178</p> <p>Epoch 99/400 9/9 [==============================] - 0s 3ms/step - loss: 9.9383 - mae: 2.3025</p> <p>Epoch 100/400 9/9 [==============================] - 0s 4ms/step - loss: 9.8653 - mae: 2.2933</p> <p>Epoch 101/400 9/9 [==============================] - 0s 3ms/step - loss: 9.9191 - mae: 2.3033</p> <p>Epoch 102/400 9/9 [==============================] - 0s 3ms/step - loss: 9.8622 - mae: 2.2823</p> <p>Epoch 103/400 9/9 [==============================] - 0s 3ms/step - loss: 9.7497 - mae: 2.2569</p> <p>Epoch 104/400 9/9 [==============================] - 0s 3ms/step - loss: 9.6942 - mae: 2.2639</p> <p>Epoch 105/400 9/9 [==============================] - 0s 4ms/step - loss: 9.6776 - mae: 2.2588</p> <p>Epoch 106/400 9/9 [==============================] - 0s 3ms/step - loss: 9.7455 - mae: 2.2674</p> <p>Epoch 107/400 9/9 [==============================] - 0s 3ms/step - loss: 9.5815 - mae: 2.2458</p> <p>Epoch 108/400 9/9 [==============================] - 0s 3ms/step - loss: 9.5837 - mae: 2.2518</p> <p>Epoch 109/400 9/9 [==============================] - 0s 3ms/step - loss: 9.4691 - mae: 2.2334</p> <p>Epoch 110/400 9/9 [==============================] - 0s 3ms/step - loss: 9.4230 - mae: 2.2271</p> <p>Epoch 111/400 9/9 [==============================] - 0s 3ms/step - loss: 9.4083 - mae: 2.2276</p> <p>Epoch 112/400 9/9 [==============================] - 0s 3ms/step - loss: 9.3655 - mae: 2.2257</p> <p>Epoch 113/400 9/9 [==============================] - 0s 3ms/step - loss: 9.3588 - mae: 2.2105</p> <p>Epoch 114/400 9/9 [==============================] - 0s 3ms/step - loss: 9.6419 - mae: 2.2598</p> <p>Epoch 115/400 9/9 [==============================] - 0s 3ms/step - loss: 9.5963 - mae: 2.2624</p> <p>Epoch 116/400 9/9 [==============================] - 0s 3ms/step - loss: 9.4118 - mae: 2.2251</p> <p>Epoch 117/400 9/9 [==============================] - 0s 3ms/step - loss: 9.2462 - mae: 2.2159</p> <p>Epoch 118/400 9/9 [==============================] - 0s 3ms/step - loss: 9.2559 - mae: 2.2230</p> <p>Epoch 119/400 9/9 [==============================] - 0s 3ms/step - loss: 9.1834 - mae: 2.2073</p> <p>Epoch 120/400 9/9 [==============================] - 0s 3ms/step - loss: 9.1216 - mae: 2.1961</p> <p>Epoch 121/400 9/9 [==============================] - 0s 4ms/step - loss: 9.1227 - mae: 2.1902</p> <p>Epoch 122/400 9/9 [==============================] - 0s 3ms/step - loss: 9.1087 - mae: 2.1876</p> <p>Epoch 123/400 9/9 [==============================] - 0s 4ms/step - loss: 9.1089 - mae: 2.1849</p> <p>Epoch 124/400 9/9 [==============================] - 0s 3ms/step - loss: 9.0926 - mae: 2.1861</p> <p>Epoch 125/400 9/9 [==============================] - 0s 3ms/step - loss: 9.2096 - mae: 2.2124</p> <p>Epoch 126/400 9/9 [==============================] - 0s 4ms/step - loss: 9.0495 - mae: 2.1710</p> <p>Epoch 127/400 9/9 [==============================] - 0s 3ms/step - loss: 8.9340 - mae: 2.1624</p> <p>Epoch 128/400 9/9 [==============================] - 0s 4ms/step - loss: 8.8782 - mae: 2.1619</p> <p>Epoch 129/400 9/9 [==============================] - 0s 3ms/step - loss: 8.8453 - mae: 2.1571</p> <p>Epoch 130/400 9/9 [==============================] - 0s 4ms/step - loss: 8.9253 - mae: 2.1674</p> <p>Epoch 131/400 9/9 [==============================] - 0s 5ms/step - loss: 8.8694 - mae: 2.1647</p> <p>Epoch 132/400 9/9 [==============================] - 0s 4ms/step - loss: 8.7110 - mae: 2.1455</p> <p>Epoch 133/400 9/9 [==============================] - 0s 4ms/step - loss: 8.7117 - mae: 2.1463</p> <p>Epoch 134/400 9/9 [==============================] - 0s 3ms/step - loss: 8.7079 - mae: 2.1490</p> <p>Epoch 135/400 9/9 [==============================] - 0s 4ms/step - loss: 8.6802 - mae: 2.1438</p> <p>Epoch 136/400 9/9 [==============================] - 0s 3ms/step - loss: 8.6549 - mae: 2.1312</p> <p>Epoch 137/400 9/9 [==============================] - 0s 3ms/step - loss: 8.5795 - mae: 2.1202</p> <p>Epoch 138/400 9/9 [==============================] - 0s 3ms/step - loss: 8.5459 - mae: 2.1143</p> <p>Epoch 139/400 9/9 [==============================] - 0s 3ms/step - loss: 8.5602 - mae: 2.1233</p> <p>Epoch 140/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4806 - mae: 2.1126</p> <p>Epoch 141/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4711 - mae: 2.1127</p> <p>Epoch 142/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4310 - mae: 2.1130</p> <p>Epoch 143/400 9/9 [==============================] - 0s 3ms/step - loss: 8.3803 - mae: 2.1100</p> <p>Epoch 144/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4019 - mae: 2.1182</p> <p>Epoch 145/400 9/9 [==============================] - 0s 3ms/step - loss: 8.5072 - mae: 2.1415</p> <p>Epoch 146/400 9/9 [==============================] - 0s 3ms/step - loss: 8.4077 - mae: 2.1234</p> <p>Epoch 147/400 9/9 [==============================] - 0s 3ms/step - loss: 8.3219 - mae: 2.1120</p> <p>Epoch 148/400 9/9 [==============================] - 0s 3ms/step - loss: 8.2850 - mae: 2.1045</p> <p>Epoch 149/400 9/9 [==============================] - 0s 3ms/step - loss: 8.2003 - mae: 2.0864</p> <p>Epoch 150/400 9/9 [==============================] - 0s 3ms/step - loss: 8.3044 - mae: 2.1012</p> <p>Epoch 151/400 9/9 [==============================] - 0s 3ms/step - loss: 8.1278 - mae: 2.0764</p> <p>Epoch 152/400 9/9 [==============================] - 0s 3ms/step - loss: 8.1840 - mae: 2.0984</p> <p>Epoch 153/400 9/9 [==============================] - 0s 3ms/step - loss: 8.0466 - mae: 2.0698</p> <p>Epoch 154/400 9/9 [==============================] - 0s 3ms/step - loss: 8.0476 - mae: 2.0702</p> <p>Epoch 155/400 9/9 [==============================] - 0s 3ms/step - loss: 8.0402 - mae: 2.0748</p> <p>Epoch 156/400 9/9 [==============================] - 0s 3ms/step - loss: 7.9566 - mae: 2.0641</p> <p>Epoch 157/400 9/9 [==============================] - 0s 3ms/step - loss: 7.9516 - mae: 2.0667</p> <p>Epoch 158/400 9/9 [==============================] - 0s 3ms/step - loss: 7.9795 - mae: 2.0733</p> <p>Epoch 159/400 9/9 [==============================] - 0s 4ms/step - loss: 7.8663 - mae: 2.0591</p> <p>Epoch 160/400 9/9 [==============================] - 0s 3ms/step - loss: 7.8300 - mae: 2.0529</p> <p>Epoch 161/400 9/9 [==============================] - 0s 3ms/step - loss: 7.8782 - mae: 2.0532</p> <p>Epoch 162/400 9/9 [==============================] - 0s 3ms/step - loss: 7.7560 - mae: 2.0371</p> <p>Epoch 163/400 9/9 [==============================] - 0s 3ms/step - loss: 7.9327 - mae: 2.0501</p> <p>Epoch 164/400 9/9 [==============================] - 0s 3ms/step - loss: 8.0039 - mae: 2.0472</p> <p>Epoch 165/400 9/9 [==============================] - 0s 4ms/step - loss: 7.8326 - mae: 2.0383</p> <p>Epoch 166/400 9/9 [==============================] - 0s 3ms/step - loss: 7.7433 - mae: 2.0366</p> <p>Epoch 167/400 9/9 [==============================] - 0s 3ms/step - loss: 7.7063 - mae: 2.0403</p> <p>Epoch 168/400 9/9 [==============================] - 0s 4ms/step - loss: 7.6165 - mae: 2.0247</p> <p>Epoch 169/400 9/9 [==============================] - 0s 3ms/step - loss: 7.6203 - mae: 2.0237</p> <p>Epoch 170/400 9/9 [==============================] - 0s 4ms/step - loss: 7.7583 - mae: 2.0332</p> <p>Epoch 171/400 9/9 [==============================] - 0s 4ms/step - loss: 7.7060 - mae: 2.0474</p> <p>Epoch 172/400 9/9 [==============================] - 0s 4ms/step - loss: 7.7214 - mae: 2.0453</p> <p>Epoch 173/400 9/9 [==============================] - 0s 4ms/step - loss: 7.5782 - mae: 2.0151</p> <p>Epoch 174/400 9/9 [==============================] - 0s 3ms/step - loss: 7.4870 - mae: 1.9941</p> <p>Epoch 175/400 9/9 [==============================] - 0s 3ms/step - loss: 7.4292 - mae: 1.9942</p> <p>Epoch 176/400 9/9 [==============================] - 0s 3ms/step - loss: 7.4034 - mae: 1.9908</p> <p>Epoch 177/400 9/9 [==============================] - 0s 3ms/step - loss: 7.3374 - mae: 1.9794</p> <p>Epoch 178/400 9/9 [==============================] - 0s 3ms/step - loss: 7.3651 - mae: 1.9837</p> <p>Epoch 179/400 9/9 [==============================] - 0s 3ms/step - loss: 7.3334 - mae: 1.9801</p> <p>Epoch 180/400 9/9 [==============================] - 0s 3ms/step - loss: 7.2986 - mae: 1.9715</p> <p>Epoch 181/400 9/9 [==============================] - 0s 3ms/step - loss: 7.3080 - mae: 1.9842</p> <p>Epoch 182/400 9/9 [==============================] - 0s 3ms/step - loss: 7.2384 - mae: 1.9710</p> <p>Epoch 183/400 9/9 [==============================] - 0s 3ms/step - loss: 7.2382 - mae: 1.9695</p> <p>Epoch 184/400 9/9 [==============================] - 0s 4ms/step - loss: 7.1499 - mae: 1.9672</p> <p>Epoch 185/400 9/9 [==============================] - 0s 4ms/step - loss: 7.2522 - mae: 1.9746</p> <p>Epoch 186/400 9/9 [==============================] - 0s 3ms/step - loss: 7.1246 - mae: 1.9721</p> <p>Epoch 187/400 9/9 [==============================] - 0s 3ms/step - loss: 7.0991 - mae: 1.9624</p> <p>Epoch 188/400 9/9 [==============================] - 0s 4ms/step - loss: 7.0756 - mae: 1.9483</p> <p>Epoch 189/400 9/9 [==============================] - 0s 3ms/step - loss: 7.1697 - mae: 1.9584</p> <p>Epoch 190/400 9/9 [==============================] - 0s 4ms/step - loss: 6.9426 - mae: 1.9408</p> <p>Epoch 191/400 9/9 [==============================] - 0s 3ms/step - loss: 7.0492 - mae: 1.9498</p> <p>Epoch 192/400 9/9 [==============================] - 0s 3ms/step - loss: 6.9617 - mae: 1.9392</p> <p>Epoch 193/400 9/9 [==============================] - 0s 3ms/step - loss: 6.9713 - mae: 1.9391</p> <p>Epoch 194/400 9/9 [==============================] - 0s 3ms/step - loss: 6.9681 - mae: 1.9466</p> <p>Epoch 195/400 9/9 [==============================] - 0s 3ms/step - loss: 7.0815 - mae: 1.9378</p> <p>Epoch 196/400 9/9 [==============================] - 0s 3ms/step - loss: 6.9769 - mae: 1.9339</p> <p>Epoch 197/400 9/9 [==============================] - 0s 4ms/step - loss: 6.8727 - mae: 1.9210</p> <p>Epoch 198/400 9/9 [==============================] - 0s 3ms/step - loss: 6.8014 - mae: 1.9227</p> <p>Epoch 199/400 9/9 [==============================] - 0s 3ms/step - loss: 6.7703 - mae: 1.9244</p> <p>Epoch 200/400 9/9 [==============================] - 0s 3ms/step - loss: 6.8127 - mae: 1.9195</p> <p>Epoch 201/400 9/9 [==============================] - 0s 3ms/step - loss: 6.7469 - mae: 1.9105</p> <p>Epoch 202/400 9/9 [==============================] - 0s 3ms/step - loss: 6.7515 - mae: 1.9144</p> <p>Epoch 203/400 9/9 [==============================] - 0s 3ms/step - loss: 6.6946 - mae: 1.9044</p> <p>Epoch 204/400 9/9 [==============================] - 0s 4ms/step - loss: 6.6362 - mae: 1.8985</p> <p>Epoch 205/400 9/9 [==============================] - 0s 4ms/step - loss: 6.6175 - mae: 1.8955</p> <p>Epoch 206/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5702 - mae: 1.8874</p> <p>Epoch 207/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5716 - mae: 1.8900</p> <p>Epoch 208/400 9/9 [==============================] - 0s 4ms/step - loss: 6.5384 - mae: 1.8846</p> <p>Epoch 209/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5449 - mae: 1.8830</p> <p>Epoch 210/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5513 - mae: 1.8749</p> <p>Epoch 211/400 9/9 [==============================] - 0s 4ms/step - loss: 6.4929 - mae: 1.8735</p> <p>Epoch 212/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5068 - mae: 1.8747</p> <p>Epoch 213/400 9/9 [==============================] - 0s 3ms/step - loss: 6.5305 - mae: 1.8740</p> <p>Epoch 214/400 9/9 [==============================] - 0s 6ms/step - loss: 6.5346 - mae: 1.8997</p> <p>Epoch 215/400 9/9 [==============================] - 0s 5ms/step - loss: 6.4906 - mae: 1.8849</p> <p>Epoch 216/400 9/9 [==============================] - 0s 4ms/step - loss: 6.4162 - mae: 1.8608</p> <p>Epoch 217/400 9/9 [==============================] - 0s 3ms/step - loss: 6.3261 - mae: 1.8522</p> <p>Epoch 218/400 9/9 [==============================] - 0s 3ms/step - loss: 6.2750 - mae: 1.8420</p> <p>Epoch 219/400 9/9 [==============================] - 0s 3ms/step - loss: 6.2780 - mae: 1.8364</p> <p>Epoch 220/400 9/9 [==============================] - 0s 2ms/step - loss: 6.2991 - mae: 1.8530</p> <p>Epoch 221/400 9/9 [==============================] - 0s 2ms/step - loss: 6.2668 - mae: 1.8361</p> <p>Epoch 222/400 9/9 [==============================] - 0s 2ms/step - loss: 6.2077 - mae: 1.8355</p> <p>Epoch 223/400 9/9 [==============================] - 0s 3ms/step - loss: 6.1889 - mae: 1.8245</p> <p>Epoch 224/400 9/9 [==============================] - 0s 2ms/step - loss: 6.2081 - mae: 1.8289</p> <p>Epoch 225/400 9/9 [==============================] - 0s 2ms/step - loss: 6.1629 - mae: 1.8108</p> <p>Epoch 226/400 9/9 [==============================] - 0s 2ms/step - loss: 6.1450 - mae: 1.8226</p> <p>Epoch 227/400 9/9 [==============================] - 0s 2ms/step - loss: 6.1505 - mae: 1.8359</p> <p>Epoch 228/400 9/9 [==============================] - 0s 2ms/step - loss: 6.1221 - mae: 1.8270</p> <p>Epoch 229/400 9/9 [==============================] - 0s 3ms/step - loss: 6.1809 - mae: 1.8272</p> <p>Epoch 230/400 9/9 [==============================] - 0s 3ms/step - loss: 6.0162 - mae: 1.8011</p> <p>Epoch 231/400 9/9 [==============================] - 0s 3ms/step - loss: 6.1452 - mae: 1.8393</p> <p>Epoch 232/400 9/9 [==============================] - 0s 3ms/step - loss: 6.0985 - mae: 1.8124</p> <p>Epoch 233/400 9/9 [==============================] - 0s 2ms/step - loss: 6.4570 - mae: 1.8844</p> <p>Epoch 234/400 9/9 [==============================] - 0s 1ms/step - loss: 6.2272 - mae: 1.8489</p> <p>Epoch 235/400 9/9 [==============================] - 0s 2ms/step - loss: 6.0741 - mae: 1.8166</p> <p>Epoch 236/400 9/9 [==============================] - 0s 4ms/step - loss: 6.0031 - mae: 1.8197</p> <p>Epoch 237/400 9/9 [==============================] - 0s 2ms/step - loss: 5.9739 - mae: 1.8037</p> <p>Epoch 238/400 9/9 [==============================] - 0s 2ms/step - loss: 6.0253 - mae: 1.8145</p> <p>Epoch 239/400 9/9 [==============================] - 0s 2ms/step - loss: 5.9134 - mae: 1.7873</p> <p>Epoch 240/400 9/9 [==============================] - 0s 4ms/step - loss: 5.8683 - mae: 1.7957</p> <p>Epoch 241/400 9/9 [==============================] - 0s 2ms/step - loss: 5.8370 - mae: 1.7853</p> <p>Epoch 242/400 9/9 [==============================] - 0s 2ms/step - loss: 5.6954 - mae: 1.7598</p> <p>Epoch 243/400 9/9 [==============================] - 0s 3ms/step - loss: 5.7053 - mae: 1.7696</p> <p>Epoch 244/400 9/9 [==============================] - 0s 2ms/step - loss: 5.6565 - mae: 1.7627</p> <p>Epoch 245/400 9/9 [==============================] - 0s 2ms/step - loss: 5.7158 - mae: 1.7734</p> <p>Epoch 246/400 9/9 [==============================] - 0s 3ms/step - loss: 5.6415 - mae: 1.7482</p> <p>Epoch 247/400 9/9 [==============================] - 0s 2ms/step - loss: 5.6077 - mae: 1.7508</p> <p>Epoch 248/400 9/9 [==============================] - 0s 2ms/step - loss: 5.7397 - mae: 1.7653</p> <p>Epoch 249/400 9/9 [==============================] - 0s 3ms/step - loss: 5.6152 - mae: 1.7499</p> <p>Epoch 250/400 9/9 [==============================] - 0s 2ms/step - loss: 5.6300 - mae: 1.7422</p> <p>Epoch 251/400 9/9 [==============================] - 0s 3ms/step - loss: 5.5146 - mae: 1.7228</p> <p>Epoch 252/400 9/9 [==============================] - 0s 2ms/step - loss: 5.5786 - mae: 1.7403</p> <p>Epoch 253/400 9/9 [==============================] - 0s 4ms/step - loss: 5.5123 - mae: 1.7385</p> <p>Epoch 254/400 9/9 [==============================] - 0s 3ms/step - loss: 5.4784 - mae: 1.7380</p> <p>Epoch 255/400 9/9 [==============================] - 0s 2ms/step - loss: 5.5062 - mae: 1.7488</p> <p>Epoch 256/400 9/9 [==============================] - 0s 2ms/step - loss: 5.5507 - mae: 1.7410</p> <p>Epoch 257/400 9/9 [==============================] - 0s 3ms/step - loss: 5.4626 - mae: 1.7239</p> <p>Epoch 258/400 9/9 [==============================] - 0s 2ms/step - loss: 5.4174 - mae: 1.7266</p> <p>Epoch 259/400 9/9 [==============================] - 0s 2ms/step - loss: 5.4086 - mae: 1.7221</p> <p>Epoch 260/400 9/9 [==============================] - 0s 2ms/step - loss: 5.4384 - mae: 1.7349</p> <p>Epoch 261/400 9/9 [==============================] - 0s 2ms/step - loss: 5.3345 - mae: 1.7105</p> <p>Epoch 262/400 9/9 [==============================] - 0s 2ms/step - loss: 5.4374 - mae: 1.7372</p> <p>Epoch 263/400 9/9 [==============================] - 0s 2ms/step - loss: 5.3719 - mae: 1.7141</p> <p>Epoch 264/400 9/9 [==============================] - 0s 3ms/step - loss: 5.3888 - mae: 1.7084</p> <p>Epoch 265/400 9/9 [==============================] - 0s 2ms/step - loss: 5.3843 - mae: 1.7203</p> <p>Epoch 266/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2937 - mae: 1.6940</p> <p>Epoch 267/400 9/9 [==============================] - 0s 3ms/step - loss: 5.4328 - mae: 1.7181</p> <p>Epoch 268/400 9/9 [==============================] - 0s 3ms/step - loss: 5.4531 - mae: 1.7435</p> <p>Epoch 269/400 9/9 [==============================] - 0s 3ms/step - loss: 5.3654 - mae: 1.7205</p> <p>Epoch 270/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2651 - mae: 1.6883</p> <p>Epoch 271/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2156 - mae: 1.6878</p> <p>Epoch 272/400 9/9 [==============================] - 0s 3ms/step - loss: 5.1566 - mae: 1.6785</p> <p>Epoch 273/400 9/9 [==============================] - 0s 2ms/step - loss: 5.1215 - mae: 1.6799</p> <p>Epoch 274/400 9/9 [==============================] - 0s 2ms/step - loss: 5.2469 - mae: 1.7029</p> <p>Epoch 275/400 9/9 [==============================] - 0s 2ms/step - loss: 5.2710 - mae: 1.7097</p> <p>Epoch 276/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2278 - mae: 1.7117</p> <p>Epoch 277/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2271 - mae: 1.6952</p> <p>Epoch 278/400 9/9 [==============================] - 0s 4ms/step - loss: 5.2615 - mae: 1.6881</p> <p>Epoch 279/400 9/9 [==============================] - 0s 3ms/step - loss: 5.0883 - mae: 1.6659</p> <p>Epoch 280/400 9/9 [==============================] - 0s 3ms/step - loss: 5.0631 - mae: 1.6695</p> <p>Epoch 281/400 9/9 [==============================] - 0s 2ms/step - loss: 5.0413 - mae: 1.6467</p> <p>Epoch 282/400 9/9 [==============================] - 0s 2ms/step - loss: 5.0614 - mae: 1.6541</p> <p>Epoch 283/400 9/9 [==============================] - 0s 3ms/step - loss: 5.2651 - mae: 1.6999</p> <p>Epoch 284/400 9/9 [==============================] - 0s 3ms/step - loss: 5.0937 - mae: 1.6658</p> <p>Epoch 285/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9900 - mae: 1.6483</p> <p>Epoch 286/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9686 - mae: 1.6482</p> <p>Epoch 287/400 9/9 [==============================] - 0s 2ms/step - loss: 4.9377 - mae: 1.6493</p> <p>Epoch 288/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9239 - mae: 1.6397</p> <p>Epoch 289/400 9/9 [==============================] - 0s 4ms/step - loss: 5.0049 - mae: 1.6458</p> <p>Epoch 290/400 9/9 [==============================] - 0s 3ms/step - loss: 5.0257 - mae: 1.6677</p> <p>Epoch 291/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9595 - mae: 1.6502</p> <p>Epoch 292/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8937 - mae: 1.6199</p> <p>Epoch 293/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8048 - mae: 1.6054</p> <p>Epoch 294/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8538 - mae: 1.6189</p> <p>Epoch 295/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8086 - mae: 1.6214</p> <p>Epoch 296/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9100 - mae: 1.6228</p> <p>Epoch 297/400 9/9 [==============================] - 0s 4ms/step - loss: 4.7689 - mae: 1.6057</p> <p>Epoch 298/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7895 - mae: 1.6120</p> <p>Epoch 299/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7679 - mae: 1.6074</p> <p>Epoch 300/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9302 - mae: 1.6508</p> <p>Epoch 301/400 9/9 [==============================] - 0s 4ms/step - loss: 4.8806 - mae: 1.6316</p> <p>Epoch 302/400 9/9 [==============================] - 0s 4ms/step - loss: 4.7871 - mae: 1.6054</p> <p>Epoch 303/400 9/9 [==============================] - 0s 4ms/step - loss: 4.7296 - mae: 1.6088</p> <p>Epoch 304/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8593 - mae: 1.6316</p> <p>Epoch 305/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8702 - mae: 1.6265</p> <p>Epoch 306/400 9/9 [==============================] - 0s 4ms/step - loss: 4.9289 - mae: 1.6436</p> <p>Epoch 307/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8258 - mae: 1.6364</p> <p>Epoch 308/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7715 - mae: 1.6131</p> <p>Epoch 309/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7257 - mae: 1.5808</p> <p>Epoch 310/400 9/9 [==============================] - 0s 3ms/step - loss: 4.9713 - mae: 1.6622</p> <p>Epoch 311/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7670 - mae: 1.6311</p> <p>Epoch 312/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7790 - mae: 1.6104</p> <p>Epoch 313/400 9/9 [==============================] - 0s 3ms/step - loss: 4.6748 - mae: 1.6186</p> <p>Epoch 314/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7386 - mae: 1.6191</p> <p>Epoch 315/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5862 - mae: 1.5769</p> <p>Epoch 316/400 9/9 [==============================] - 0s 3ms/step - loss: 4.6310 - mae: 1.5809</p> <p>Epoch 317/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8212 - mae: 1.6367</p> <p>Epoch 318/400 9/9 [==============================] - 0s 3ms/step - loss: 4.4685 - mae: 1.5482</p> <p>Epoch 319/400 9/9 [==============================] - 0s 3ms/step - loss: 4.6965 - mae: 1.5876</p> <p>Epoch 320/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7098 - mae: 1.5959</p> <p>Epoch 321/400 9/9 [==============================] - 0s 3ms/step - loss: 4.8441 - mae: 1.6635</p> <p>Epoch 322/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5366 - mae: 1.5945</p> <p>Epoch 323/400 9/9 [==============================] - 0s 3ms/step - loss: 4.7188 - mae: 1.5974</p> <p>Epoch 324/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5682 - mae: 1.5611</p> <p>Epoch 325/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5609 - mae: 1.5801</p> <p>Epoch 326/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5395 - mae: 1.5852</p> <p>Epoch 327/400 9/9 [==============================] - 0s 3ms/step - loss: 4.4885 - mae: 1.5625</p> <p>Epoch 328/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3885 - mae: 1.5423</p> <p>Epoch 329/400 9/9 [==============================] - 0s 4ms/step - loss: 4.5206 - mae: 1.5739</p> <p>Epoch 330/400 9/9 [==============================] - 0s 7ms/step - loss: 4.4114 - mae: 1.5382</p> <p>Epoch 331/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3323 - mae: 1.5197</p> <p>Epoch 332/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3240 - mae: 1.5208</p> <p>Epoch 333/400 9/9 [==============================] - 0s 3ms/step - loss: 4.4238 - mae: 1.5322</p> <p>Epoch 334/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3662 - mae: 1.5501</p> <p>Epoch 335/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3211 - mae: 1.5324</p> <p>Epoch 336/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2283 - mae: 1.5031</p> <p>Epoch 337/400 9/9 [==============================] - 0s 4ms/step - loss: 4.2960 - mae: 1.5352</p> <p>Epoch 338/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2662 - mae: 1.5223</p> <p>Epoch 339/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3856 - mae: 1.5406</p> <p>Epoch 340/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3143 - mae: 1.5513</p> <p>Epoch 341/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3948 - mae: 1.5666</p> <p>Epoch 342/400 9/9 [==============================] - 0s 3ms/step - loss: 4.3177 - mae: 1.5356</p> <p>Epoch 343/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2848 - mae: 1.5331</p> <p>Epoch 344/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2723 - mae: 1.5274</p> <p>Epoch 345/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2018 - mae: 1.5079</p> <p>Epoch 346/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2182 - mae: 1.5171</p> <p>Epoch 347/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2083 - mae: 1.5251</p> <p>Epoch 348/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2829 - mae: 1.5318</p> <p>Epoch 349/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1793 - mae: 1.4975</p> <p>Epoch 350/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1535 - mae: 1.5021</p> <p>Epoch 351/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1689 - mae: 1.4901</p> <p>Epoch 352/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1737 - mae: 1.5091</p> <p>Epoch 353/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2916 - mae: 1.5423</p> <p>Epoch 354/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2486 - mae: 1.5089</p> <p>Epoch 355/400 9/9 [==============================] - 0s 3ms/step - loss: 4.5061 - mae: 1.5545</p> <p>Epoch 356/400 9/9 [==============================] - 0s 4ms/step - loss: 4.1563 - mae: 1.5199</p> <p>Epoch 357/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1927 - mae: 1.5353</p> <p>Epoch 358/400 9/9 [==============================] - 0s 3ms/step - loss: 4.0238 - mae: 1.4803</p> <p>Epoch 359/400 9/9 [==============================] - 0s 3ms/step - loss: 4.2785 - mae: 1.5282</p> <p>Epoch 360/400 9/9 [==============================] - 0s 3ms/step - loss: 4.1957 - mae: 1.5044</p> <p>Epoch 361/400 9/9 [==============================] - 0s 3ms/step - loss: 4.0877 - mae: 1.5101</p> <p>Epoch 362/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9776 - mae: 1.4631</p> <p>Epoch 363/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9758 - mae: 1.4540</p> <p>Epoch 364/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9303 - mae: 1.4430</p> <p>Epoch 365/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9630 - mae: 1.4558</p> <p>Epoch 366/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8929 - mae: 1.4350</p> <p>Epoch 367/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9009 - mae: 1.4355</p> <p>Epoch 368/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9361 - mae: 1.4656</p> <p>Epoch 369/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9120 - mae: 1.4496</p> <p>Epoch 370/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8926 - mae: 1.4374</p> <p>Epoch 371/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8675 - mae: 1.4317</p> <p>Epoch 372/400 9/9 [==============================] - 0s 4ms/step - loss: 3.8442 - mae: 1.4272</p> <p>Epoch 373/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8265 - mae: 1.4365</p> <p>Epoch 374/400 9/9 [==============================] - 0s 3ms/step - loss: 3.7951 - mae: 1.4227</p> <p>Epoch 375/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8109 - mae: 1.4185</p> <p>Epoch 376/400 9/9 [==============================] - 0s 4ms/step - loss: 3.8171 - mae: 1.4315</p> <p>Epoch 377/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8079 - mae: 1.4224</p> <p>Epoch 378/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9359 - mae: 1.4343</p> <p>Epoch 379/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9052 - mae: 1.4712</p> <p>Epoch 380/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9682 - mae: 1.4686</p> <p>Epoch 381/400 9/9 [==============================] - 0s 4ms/step - loss: 3.8712 - mae: 1.4372</p> <p>Epoch 382/400 9/9 [==============================] - 0s 10ms/step - loss: 3.7983 - mae: 1.4193</p> <p>Epoch 383/400 9/9 [==============================] - 0s 16ms/step - loss: 3.7823 - mae: 1.4226</p> <p>Epoch 384/400 9/9 [==============================] - 0s 5ms/step - loss: 3.7303 - mae: 1.4140</p> <p>Epoch 385/400 9/9 [==============================] - 0s 4ms/step - loss: 3.7204 - mae: 1.4044</p> <p>Epoch 386/400 9/9 [==============================] - 0s 3ms/step - loss: 3.7432 - mae: 1.4152</p> <p>Epoch 387/400 9/9 [==============================] - 0s 3ms/step - loss: 3.7204 - mae: 1.4045</p> <p>Epoch 388/400 9/9 [==============================] - 0s 3ms/step - loss: 3.7163 - mae: 1.3980</p> <p>Epoch 389/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6538 - mae: 1.3896</p> <p>Epoch 390/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6510 - mae: 1.3874</p> <p>Epoch 391/400 9/9 [==============================] - 0s 3ms/step - loss: 3.9399 - mae: 1.4741</p> <p>Epoch 392/400 9/9 [==============================] - 0s 3ms/step - loss: 3.8155 - mae: 1.4265</p> <p>Epoch 393/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6893 - mae: 1.3884</p> <p>Epoch 394/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6876 - mae: 1.4176</p> <p>Epoch 395/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6896 - mae: 1.3905</p> <p>Epoch 396/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6180 - mae: 1.3828</p> <p>Epoch 397/400 9/9 [==============================] - 0s 3ms/step - loss: 3.5933 - mae: 1.3773</p> <p>Epoch 398/400 9/9 [==============================] - 0s 3ms/step - loss: 3.5719 - mae: 1.3750</p> <p>Epoch 399/400 9/9 [==============================] - 0s 3ms/step - loss: 3.5381 - mae: 1.3641</p> <p>Epoch 400/400 9/9 [==============================] - 0s 3ms/step - loss: 3.6085 - mae: 1.3688</p> <p><pre><code># Applique le mod\u00e8le sur la data du test\npred_test = model.predict(X_test)\npred_test.shape\n</code></pre> <pre><code># Evaluation du mod\u00e8le\nresult_test = model.evaluate(X_test, y_test, verbose=0)\nprint('MSE test', round(result_test[0],2))\nprint('MAE test', round(result_test[1],2))\n</code></pre></p> Output <p>MSE test 10.72</p> <p>MAE test 2.11</p>"},{"location":"projects/boston%20datasets/#support-vector-regression-svr","title":"Support Vector Regression SVR","text":"<pre><code># D\u00e9finir le mod\u00e8le\nmodel_SVR = svm.SVR()\n\n# Lancer l\u2019apprentissage\nmodel_SVR.fit(X_train,y_train)\n</code></pre>"},{"location":"projects/boston%20datasets/#regression-lineaire-lr","title":"R\u00e9gression Lin\u00e9aire LR","text":"<p><pre><code># D\u00e9finir le mod\u00e8le\nregression=LinearRegression()\n\n# Lancer l\u2019apprentissage\nregression.fit(X_train,y_train)\n</code></pre> <pre><code># Afficher les coefficients \nprint(regression.coef_)\n</code></pre></p> Output <p>[-1.00213533  0.69626862  0.27806485  0.7187384  -2.0223194   3.14523956 -0.17604788 -3.0819076   2.25140666 -1.76701378 -2.03775151  1.12956831 -3.61165842]</p> <pre><code># Afficher the intercept\nprint(regression.intercept_)\n</code></pre> Output <p>23.023938223938224</p> <pre><code># Sur quels param\u00e8tres le mod\u00e8le a entrainn\u00e9\nregression.get_params()\n</code></pre> Output <p>{'copy_X': True,</p> <p>'fit_intercept': True,</p> <p>'n_jobs': None,</p> <p>'normalize': 'deprecated',</p> <p>'positive': False}</p>"},{"location":"projects/ozone%20datasets/","title":"Ozone Dataset","text":""},{"location":"projects/ozone%20datasets/#introduction","title":"Introduction","text":"<p>Le jeu de donn\u00e9es contient 1464 observations (journali\u00e8res, du 01/04/1995 au 30/09/2002, \u00e0 Rennes).</p>"},{"location":"projects/ozone%20datasets/#preparation-des-donnees","title":"Pr\u00e9paration des donn\u00e9es","text":"<pre><code># Importer les biblioth\u00e8ques\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dropout\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.layers import Dense\nfrom sklearn.metrics import mean_squared_error\n</code></pre> <p>Lors de l'importation des donn\u00e9es, j'ai remplac\u00e9 la colonne index par la colonne des dates.</p> <p><pre><code># Importer le datasets + remplacer la colonne des indexes par celle des dates\nozone = pd.read_csv(\"ozone_complet.csv\", sep=\";\", index_col='Unnamed: 0')\n</code></pre> <pre><code># Lire les 5 premi\u00e8re lignes\nozone.head()\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#etude-exploratoire-des-donnees","title":"\u00c9tude exploratoire des donn\u00e9es","text":"<p><pre><code># Afficher quelques informations du dataset\nozone.info()\n</code></pre> <pre><code># Afficher quelques statistiques du dataset\nozone.describe()\n</code></pre> <pre><code># Analyse les distributions des donn\u00e9es\nozone.hist(bins=50, figsize=(20,15))\nplt.show()\n</code></pre></p> Output <p></p> <pre><code># Analyse des corr\u00e9lations\n\nmatriceCorr = ozone.corr().round(1)\nsns.heatmap(data=matriceCorr, annot = True)\n</code></pre> Output <p></p> <pre><code># Afficher le nombre des valeurs manquantes dans chaque colonne\nozone.isnull().sum()\n</code></pre> <p>J'ai ensuite remarqu\u00e9 qu'il y avait des valeurs manquantes dans l'ensemble de donn\u00e9es. Pour r\u00e9soudre ce probl\u00e8me, j'ai remplac\u00e9 ces valeurs par la moyenne en utilisant \u00ab SimpleImputer \u00bb.</p> <p><pre><code># Remplir les valeurs manquentes par la mayenne\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy=\"median\")\n</code></pre> <pre><code># Lancer l'entrainement de Imputer\nimputer.fit(ozone)\n</code></pre> <pre><code># Appliquer le mod\u00e8le Imputer sur le dataset ozone (la sortie est de type array)\nozone_complet = imputer.transform(ozone)\n</code></pre> <pre><code># Transformer le dataset (sortie de Imputer de type array) en data frame\nozone_complet = pd.DataFrame(ozone_complet, columns=ozone.columns)\n</code></pre> <pre><code># V\u00e9rifier qu'il n'ya plus de valeurs manquantes\nozone_complet.isnull().sum()\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#implementation-dun-modele-de-reseau-de-neurones","title":"Impl\u00e9mentation d\u2019un mod\u00e8le de r\u00e9seau de neurones","text":"<p><pre><code># Division de donn\u00e9es en donn\u00e9es d'entrainement, du test et de validation\n\nozone_complet = ozone_complet.sample(frac=1, axis=0)\n\ndata_train_valid = ozone_complet.sample(frac=0.85, axis=0)\ndata_test = ozone_complet.drop(data_train_valid.index)\ndata_train = data_train_valid.sample(frac=0.8, axis=0)\ndata_valid = data_train_valid.drop(data_train.index)\n\nx_train = data_train.drop('maxO3', axis=1)\ny_train = data_train['maxO3']\nprint('Dimensions de X train :', x_train.shape)\nprint('Dimensions de Y train :', y_train.shape)\n\nx_valid = data_valid.drop('maxO3', axis=1)\ny_valid = data_valid['maxO3']\nprint('Dimensions de X valid :', x_valid.shape)\nprint('Dimensions de Y valid :', y_valid.shape)\n\nx_test = data_test.drop('maxO3', axis=1)\ny_test = data_test['maxO3']\nprint('Dimensions de X test :', x_test.shape)\nprint('Dimensions de Y test :', y_test.shape)\n</code></pre> <pre><code># Normalisation des donn\u00e9es\n\nmin_x_train = x_train.min()\nmax_x_train = x_train.max()\n\nprint(\"Min de x_train :\", min_x_train)\nprint(\"Max de x_train :\", max_x_train)\n\nx_train_norm = (x_train-min_x_train)/(max_x_train-min_x_train)\nx_test_norm = (x_test-min_x_train)/(max_x_train-min_x_train)\nx_val_norm = (x_valid-min_x_train)/(max_x_train-min_x_train)\n</code></pre></p> <p>La structure du perceptron se compose d'une couche d'entr\u00e9e avec 22 neurones correspondant \u00e0 chacune des 22 features, de deux couches cach\u00e9es avec 5 neurones par chacune et d'une couche de sortie avec un seul neurone qui donnera la valeur pr\u00e9dite de <code>maxO3</code>. La <code>fonction ReLu</code> a \u00e9t\u00e9 choisie comme fonction d'activation pour chacune des trois couches, <code>mean square error</code> comme loss function, et l'algorithme <code>Adam optimizer</code> pour son adaptative learning rate and momentum.</p> <p><pre><code>## Impl\u00e9mentation de mod\u00e8le DNN\n\nmodel = Sequential()\nmodel.add(Dense(22, input_dim=np.shape(x_train)[1], activation = 'relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(5, activation = 'relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(5, activation = 'relu'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(1, activation = 'relu'))\n\nmodel.compile(loss = 'mean_squared_error', optimizer = 'adam', metrics=['mean_squared_error'])\n\nmodel.summary()\n</code></pre> <pre><code>callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=100)\n\nhist = model.fit(x_train_norm, y_train, epochs = 1000, batch_size = 9999, callbacks = callback)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\n\npred_train= model.predict(x_train_norm)\nprint(np.sqrt(mean_squared_error(y_train,pred_train)))\n\npred= model.predict(x_test_norm)\nprint(np.sqrt(mean_squared_error(y_test,pred)))\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#implementation-dune-regression-lineaire","title":"Impl\u00e9mentation d'une R\u00e9gression Lin\u00e9aire","text":"<p>J'ai \u00e9galement mis en \u0153uvre une r\u00e9gression lin\u00e9aire et j\u2019ai obtenu un score de 0,625 pour les donn\u00e9es de test et un score de 0,646 pour les donn\u00e9es de validation.</p> <p><pre><code>from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\n\nscore_test_lin_reg = lin_reg.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_lin_reg)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\n\nscore_valid_lin_reg = lin_reg.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_lin_reg)\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#implementation-dun-svr","title":"Impl\u00e9mentation d\u2019un SVR","text":"<p>Un SVR a \u00e9galement \u00e9t\u00e9 mis en place et a donn\u00e9 un score de 0,489 pour les donn\u00e9es de test et un score de 0,519 pour les donn\u00e9es de validation.</p> <p><pre><code>from sklearn.svm import SVR\n\nsvr = SVR()\nsvr.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\n\nscore_test_svr = svr.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_svr)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\n\nscore_valid_svr = svr.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_svr)\n</code></pre></p>"},{"location":"projects/ozone%20datasets/#conclusion","title":"Conclusion","text":"<p>Pour conclure, voici un tableau qui r\u00e9sume les diff\u00e9rents scores de tous les mod\u00e8les que j'ai mis en place :</p> Mod\u00e8le Score (test dataset) Score (validation dataset) R\u00e9seau de neurones (DNN) mean square error : 36.827398008235775 R\u00e9gression Lin\u00e9aire 0.6250066102296177 0.6463044934834267 SVM (SVR) 0.4895962389393179 0.5192747605192083"},{"location":"projects/projet%20R/","title":"Profilage des chauffeurs","text":"<p>Membres du groupe</p> <ul> <li>MOUHIHA Mohamed</li> </ul>"},{"location":"projects/projet%20R/#importer-les-packages","title":"Importer les packages","text":"<pre><code>library(sf)           # manipulation des donn\u00e9es spatiales\nlibrary(osmdata)      # extraction des donn\u00e9es OpenStreetMap\nlibrary(leaflet)      # visualisation interactive avec leaflet\nlibrary(mapsf)        # cartographie statistique\nlibrary(lubridate)    # manipulation des dates\nlibrary(tidyverse)    # m\u00e9ta-package d'Hadley Wickham\n</code></pre> <p><code>getwd()</code> est une fonction qui permet de r\u00e9cup\u00e9rer le chemin absolu du r\u00e9pertoire de travail actuel.</p> <pre><code>getwd()\n</code></pre> Output <p>[1] \"C:/Users/abdel/Documents\"</p>"},{"location":"projects/projet%20R/#importer-la-data","title":"Importer la data","text":"<ul> <li> <p>Le premier fichier, <code>casabound.geojson</code>, est lu \u00e0 l'aide de la fonction st_read() de la biblioth\u00e8que sf. Cette fonction est utilis\u00e9e pour lire des fichiers de donn\u00e9es spatiales tels que des fichiers shapefile, des fichiers GeoJSON, etc. Ici, il lit un fichier GeoJSON nomm\u00e9 \"casabound.geojson\" et stocke les donn\u00e9es dans un objet nomm\u00e9 casaBound.</p> </li> <li> <p>Le deuxi\u00e8me fichier, <code>heetchmarchcrop.Rds</code>, est lu \u00e0 l'aide de la fonction readRDS(). Cette fonction est utilis\u00e9e pour lire des fichiers de donn\u00e9es R sauvegard\u00e9s en utilisant la fonction saveRDS(). Ici, il lit un fichier RDS nomm\u00e9 heetchmarchcrop.Rds et stocke les donn\u00e9es dans un objet nomm\u00e9 heetchPoints.</p> </li> <li> <p>Le troisi\u00e8me fichier, <code>osmfeatures.Rds</code>, est \u00e9galement lu \u00e0 l'aide de la fonction readRDS(). Comme le deuxi\u00e8me fichier, il s'agit d'un fichier RDS et est lu dans un objet nomm\u00e9 osmFeatures.</p> </li> </ul> <pre><code>casaBound &lt;- st_read(\"DATA/casabound.geojson\")\nheetchPoints &lt;- readRDS(\"DATA/heetchmarchcrop.Rds\")\nosmFeatures &lt;- readRDS(\"DATA/osmfeatures.Rds\")\n</code></pre> Output <p></p>"},{"location":"projects/projet%20R/#definir-la-problematique","title":"D\u00e9finir la probl\u00e9matique","text":"<p>A travers ce travail, nous cherchons \u00e0 identifier les conducteurs qui respectent les r\u00e8gles de conduite et \u00e0 \u00e9valuer leur s\u00e9curit\u00e9 sur la route, pour ce faire, nous nous concentrerons sur le calcul de la vitesse moyenne des conducteurs.</p>"},{"location":"projects/projet%20R/#resoudre-la-problematique","title":"R\u00e9soudre la probl\u00e9matique","text":"<p>Ce code R <code>length(unique(heetchPoints$driver_id))</code> calcule le nombre de valeurs uniques dans la colonne driver_id de l'objet heetchPoints.</p> <p>La fonction unique() est utilis\u00e9e pour extraire les valeurs uniques de la colonne driver_id. Ensuite, la fonction length() est utilis\u00e9e pour renvoyer le nombre d'\u00e9l\u00e9ments dans le vecteur r\u00e9sultant.</p> Nombre de chauffeurs<pre><code>length(unique(heetchPoints$driver_id))\n</code></pre> Output <p>[1] 1309</p> <p>Le code R pr\u00e9sent\u00e9 ci-dessous est une fonction appel\u00e9e <code>my_function</code>, qui prend un argument id_driver. La fonction effectue les op\u00e9rations suivantes:</p> <ol> <li> <p>Initialise une variable i \u00e0 z\u00e9ro.</p> </li> <li> <p>Affiche la valeur de i.</p> </li> <li> <p>Filtre la table heetchPoints en fonction de la valeur id_driver.</p> </li> <li> <p>Trier la table driver en fonction de la colonne location_at_local_time.</p> </li> <li> <p>Effectue une projection de la table driver_tri dans une projection cartographique sp\u00e9cifique (crs = 26191).</p> </li> <li> <p>Calcule les distances entre tous les points dans la table driver_tri \u00e0 l'aide de la fonction st_distance.</p> </li> <li> <p>Calcule la diff\u00e9rence de temps entre chaque deux points cons\u00e9cutifs dans la table driver_tri \u00e0 l'aide de la fonction difftime.</p> </li> <li> <p>Filtre la table driver_tri pour conserver uniquement les points ayant une diff\u00e9rence de temps entre 0.016 et 0.025 heures.</p> </li> <li> <p>Calcule la vitesse entre chaque deux points successifs en divisant la distance sur le temps.</p> </li> <li> <p>Filtre la table driver_tri_2 pour ne conserver que les points ayant une vitesse entre 6 et 120 km/h.</p> </li> <li> <p>Retourne la moyenne des vitesses de la table driver_tri_3.</p> </li> </ol> <p>D\u00e9fenir la fonction qui calcul la moyenne des vitesses d'un chauffeur sur un jour<pre><code>i = 0\nmy_function &lt;- function (id_driver){\n\ni=i+1\nprint(i)\ndriver &lt;- heetchPoints %&gt;% filter(driver_id == id_driver) # Prendre le premier jour + classer par location_at_local_time\n#  jour &lt;- driver %&gt;% \n#   filter(substr(driver$location_at_local_time, start = 9, stop = 10) == \"01\")\n\n#plot(driver$geometry, border = \"red\", lwd = 2)\n\n#  time_tri &lt;- order(jour$location_at_local_time)\n\n# jour_tri &lt;- jour[time_tri,]\n\n#Triage temporel de la table driver \n\ndriver_tri_index &lt;- order(driver$location_at_local_time)\ndriver_tri &lt;- driver[driver_tri_index,]\n\n# Projection des points\ndriver_tri &lt;- st_transform(x = driver_tri, crs = 26191)\n\n\n\n\n# Calculons les distances entres tous les points\nn &lt;- nrow(driver_tri)  n\nlist_distance &lt;- list()\nfor( i in 1:(n-1)){\ndistance &lt;- st_distance(x = driver_tri[i, ],\ny = driver_tri[i+1, ],\nby_element = TRUE)\nunits(distance) &lt;- \"km\"\nlist_distance &lt;- append (list_distance, list(distance))\n}\nlength (list_distance)\nlist_distance &lt;- c(0, list_distance)\n\ndriver_tri$distdiff &lt;- list_distance\n\n\n\n\nlist_time &lt;- list()\nfor( i in 1:(n-1)){\ndate_point1 &lt;- driver_tri$location_at_local_time[i]\ndate_point2 &lt;- driver_tri$location_at_local_time[i+1]\ndiff?rence &lt;- difftime(date_point2, date_point1, units = \"hours\")\nlist_time &lt;- append (list_time, list(diff?rence))\n}\n\nlist_time &lt;- c(0, list_time)\ndriver_tri$timediff &lt;- list_time\n#Calculons la liste des vitesse entre chaque deux points successifs en divisant la distance sur le temps\n\ndriver_tri_2 &lt;- driver_tri[driver_tri$timediff &gt; 0.016 &amp; driver_tri$timediff &lt; 0.025, ]\n\n\nclass(driver_tri_2$distdiff)\nclass(driver_tri_2$timediff)\n\ndriver_tri_2$distdiff &lt;- as.numeric(driver_tri_2$distdiff)\ndriver_tri_2$timediff &lt;- as.numeric(driver_tri_2$timediff)\n\ndriver_tri_2$vitesse &lt;- driver_tri_2$distdiff / driver_tri_2$timediff\ndriver_tri_3 &lt;- driver_tri_2[driver_tri_2$vitesse &gt;= 6 &amp; driver_tri_2$vitesse &lt;= 120, ]\n\nreturn (mean(driver_tri_3$vitesse))\n}\n</code></pre> Le code ci-dessous commence par cr\u00e9er un objet de type data.frame appel\u00e9 vitesse_table \u00e0 l'aide de la fonction data.frame().</p> <p>Ensuite, la boucle for est utilis\u00e9e pour it\u00e9rer sur une liste de trois valeurs de l'ID de conducteur driver_id comprises entre 10 et 12 inclusivement.</p> <p>\u00c0 chaque it\u00e9ration, le code cr\u00e9e une liste driver_list avec deux \u00e9l\u00e9ments : le premier est l'ID du conducteur et le deuxi\u00e8me est le r\u00e9sultat de la fonction my_function() avec l'ID du conducteur en argument.</p> <p>Enfin, la fonction rbind() est utilis\u00e9e pour ajouter la liste driver_list en tant que nouvelle ligne \u00e0 la fin du data.frame ***vitesse_table**.</p> <p>Ainsi, \u00e0 la fin de la boucle for, vitesse_table contiendra une liste de conducteurs avec leurs ID et la valeur de la vitesse obtenue \u00e0 l'aide de la fonction my_function().</p> Calculons la moyenne des vitesse de tous les chauffeurs<pre><code>vitesse_table &lt;- data.frame()\n\nfor (driver_id in unique(heetchPoints$driver_id)[10:12]){\ndriver_list &lt;- list(driver_id, my_function (driver_id))\nvitesse_table &lt;- rbind(vitesse_table, driver_list)\n}\n</code></pre>"},{"location":"projects/spam%20datasets/","title":"Spam Dataset","text":""},{"location":"projects/spam%20datasets/#introduction","title":"Introduction","text":"<p>L'objectif de ce projet \u00e9tait d'entra\u00eener un r\u00e9seau neuronal \u00e0 classer les courriels comme <code>spam</code> ou <code>non spam</code>. Ceci a \u00e9t\u00e9 fait sur le jeu de donn\u00e9es Spambase fourni par le r\u00e9f\u00e9rentiel d'apprentissage automatique de l'UCI, qui contient 57 features repr\u00e9sentant la fr\u00e9quence des mots dans 4601 emails.</p> <p>Pour notre label (Spam) ; <code>spam</code> a \u00e9t\u00e9 cod\u00e9 comme 1 pour la classe positive et <code>non spam</code> a \u00e9t\u00e9 a \u00e9t\u00e9 cod\u00e9 comme 0 pour la classe n\u00e9gative.</p>"},{"location":"projects/spam%20datasets/#preparation-des-donnees","title":"Pr\u00e9paration des donn\u00e9es","text":"<p><pre><code># Importer les biblioth\u00e8ques\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tensorflow import keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dropout\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.layers import Dense\n</code></pre> <pre><code># Importer le datasets \nspam = pd.read_csv(\"spam.csv\")\n</code></pre> <pre><code># Lire les 5 premi\u00e8re lignes\nspam.head(5)\n</code></pre></p>"},{"location":"projects/spam%20datasets/#etude-exploratoire-des-donnees","title":"\u00c9tude exploratoire des donn\u00e9es","text":"<pre><code># Afficher quelques informations du dataset\nspam.info()\n</code></pre> <p>D'apr\u00e8s le r\u00e9sultat de la m\u00e9thode <code>info()</code>, il appara\u00eet que tous les features sont de type float ce qui facilitera notre \u00e9tude ult\u00e9rieure (pas besoin de faire une feature engineering).</p> <pre><code># Afficher quelques statistiques du dataset\nspam.describe()\n</code></pre> <p>J'ai \u00e9galement fait une analyse des distributions des donn\u00e9es pour avoir une id\u00e9e sur les lois suivies par les diff\u00e9rents features, ainsi veuillez trouver ci-dessous le r\u00e9sultat obtenu et qui montre que la plupart des features ne suivent pas une distribution gaussienne.</p> <pre><code># Afficher quelques statistiques du dataset\nspam.describe()\n</code></pre> Output <p></p> <pre><code># Analyse des corr\u00e9lations\nmatriceCorr = spam.corr().round(1)\nsns.heatmap(data=matriceCorr, annot = True)\n</code></pre> Output <p></p>"},{"location":"projects/spam%20datasets/#implementation-dun-modele-de-reseau-de-neurones","title":"Impl\u00e9mentation d\u2019un mod\u00e8le de r\u00e9seau de neurones","text":"<p><pre><code># Division de donn\u00e9es en donn\u00e9es d'entrainement, du test et de validation\n\nspam = spam.sample(frac=1, axis=0)\n\ndata_train_valid = spam.sample(frac=0.85, axis=0)\ndata_test = spam.drop(data_train_valid.index)\ndata_train = data_train_valid.sample(frac=0.8, axis=0)\ndata_valid = data_train_valid.drop(data_train.index)\n\nx_train = data_train.drop('spam', axis=1)\ny_train = data_train['spam']\nprint('Dimensions de X train :', x_train.shape)\nprint('Dimensions de Y train :', y_train.shape)\n\nx_valid = data_valid.drop('spam', axis=1)\ny_valid = data_valid['spam']\nprint('Dimensions de X valid :', x_valid.shape)\nprint('Dimensions de Y valid :', y_valid.shape)\n\nx_test = data_test.drop('spam', axis=1)\ny_test = data_test['spam']\nprint('Dimensions de X test :', x_test.shape)\nprint('Dimensions de Y test :', y_test.shape)\n</code></pre> <pre><code># Normalisation des donn\u00e9es\n\nmin_x_train = x_train.min()\nmax_x_train = x_train.max()\n\nprint(\"Min de x_train :\", min_x_train)\nprint(\"Max de x_train :\", max_x_train)\n\nx_train_norm = (x_train-min_x_train)/(max_x_train-min_x_train)\nx_test_norm = (x_test-min_x_train)/(max_x_train-min_x_train)\nx_val_norm = (x_valid-min_x_train)/(max_x_train-min_x_train)\n</code></pre></p> <p>La structure du perceptron se compose d'une couche d'entr\u00e9e avec 57 neurones correspondant \u00e0 chacune des 57 features, d'une couche cach\u00e9e avec 12 neurones et d'une couche de sortie avec 2 neurones : le premier peut \u00eatre interpr\u00e9t\u00e9 comme la probabilit\u00e9 qu'un email soit \u00ab non-spam \u00bb et le second comme la probabilit\u00e9 de \"spam\". Le neurone de sortie ayant la probabilit\u00e9 la plus \u00e9lev\u00e9e d\u00e9termine la classification d'un email.</p> <p>La <code>fonction sigmo\u00efde</code> a \u00e9t\u00e9 choisie comme fonction d'activation pour chacune des trois couches, l'entropie crois\u00e9e binaire comme loss function, et l'algorithme <code>Adam optimizer</code> pour son adaptative learning rate and momentum.</p> <p></p> <p><pre><code>## Impl\u00e9mentation de mod\u00e8le DNN\n\nmodel = Sequential()\nmodel.add(Dense(57, input_dim=np.shape(x_train)[1], activation = 'sigmoid'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(12, activation = 'sigmoid'))\nmodel.add(Dropout(.5))\nmodel.add(Dense(1, activation = 'sigmoid'))\n\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n\nmodel.summary()\n</code></pre> <pre><code>callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=1000)\n\nhist = model.fit(x_train_norm, y_train, epochs = 10100, batch_size = 99999, callbacks = callback)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\n\npreds = model.predict(x_test_norm)\npreds = [1 if x[0] &gt; 0.5 else 0 for x in preds]\nscore_test_dnn = accuracy_score(y_test, preds)\nprint(score_test_dnn)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\n\npreds = model.predict(x_val_norm)\npreds = [1 if x[0] &gt; 0.5 else 0 for x in preds]\nscore_valid_dnn = accuracy_score(y_valid, preds)\nprint(score_valid_dnn)\n</code></pre> <pre><code>figure = plt.gcf()\nfigure.set_size_inches((20, 10))\nplt.title('Analyse des erreurs')\nplt.xlabel('Epoch')\nplt.ylabel('Entropie crois\u00e9e')\nplt.plot(range(1, len(hist.history['loss']) + 1), hist.history['loss'])\nplt.legend(['Entropie crois\u00e9e train'])\nplt.show()\n</code></pre></p> Output <p></p> <pre><code>figure = plt.gcf()\nfigure.set_size_inches((20, 10))\nplt.title('Analyse des erreurs')\nplt.xlabel('Epoch')\nplt.ylabel('Pr\u00e9cision')\nplt.plot(range(1, len(hist.history['accuracy']) + 1), hist.history['accuracy'])\nplt.legend([\"Pr\u00e9cision d'apprentissage\"])\nplt.show()\n</code></pre> Output <p></p> <p>Ce mod\u00e8le de r\u00e9seau neuronal a donn\u00e9 un score de 0,924 pour les donn\u00e9es de test et un score de 0,937 pour les donn\u00e9es de validation, ce qui est tr\u00e8s satisfaisant.</p>"},{"location":"projects/spam%20datasets/#implementation-dune-regression-logistique","title":"Impl\u00e9mentation d\u2019une R\u00e9gression Logistique","text":"<p><pre><code>from sklearn.linear_model import LogisticRegression\n\nlog_reg = LogisticRegression()\nlog_reg.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\n\nscore_test_log_reg = log_reg.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_log_reg)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\n\nscore_valid_log_reg = log_reg.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_log_reg)\n</code></pre></p> <p>J'ai \u00e9galement mis en \u0153uvre une r\u00e9gression logistique et j\u2019ai obtenu un score de 0,876 pour les donn\u00e9es de test et un score de 0,895 pour les donn\u00e9es de validation.</p>"},{"location":"projects/spam%20datasets/#implementation-dun-svm","title":"Impl\u00e9mentation d\u2019un SVM","text":"<p><pre><code>from sklearn import svm\n\nsvm = svm.SVC()\nsvm.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\n\nscore_test_svc = svm.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_svc)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\n\nscore_valid_svc = svm.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_svc)\n</code></pre></p> <p>Un SVC a \u00e9galement \u00e9t\u00e9 mis en place et a donn\u00e9 un score de 0,931 pour les donn\u00e9es de test et un score de 0,932 pour les donn\u00e9es de validation.</p>"},{"location":"projects/spam%20datasets/#implementation-dun-random-forest","title":"Impl\u00e9mentation d\u2019un Random Forest","text":"<p><pre><code>from sklearn.ensemble import RandomForestClassifier\n\nrdf = RandomForestClassifier(max_depth=2, random_state=0)\nrdf.fit(x_train_norm, y_train)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es du test\n\nscore_test_rdf = rdf.score(x_test_norm, y_test)\nprint(\"Test Accuracy Score\", score_test_rdf)\n</code></pre> <pre><code># Performance du mod\u00e8le sur les donn\u00e9es de validation\n\nscore_valid_rdf = rdf.score(x_val_norm, y_valid)\nprint(\"Test Accuracy Score\", score_valid_rdf)\n</code></pre></p> <p>Pour avoir une id\u00e9e de tous les mod\u00e8les de machine learning, j'ai mis en \u0153uvre un Random Forest qui a donn\u00e9 un score de 0,884 pour les donn\u00e9es de test et un score de 0,904 pour les donn\u00e9es de validation.</p>"},{"location":"projects/spam%20datasets/#conclusion","title":"Conclusion","text":"<p>Pour conclure, voici un tableau qui r\u00e9sume les diff\u00e9rents scores de tous les mod\u00e8les que j'ai mis en place :</p> Mod\u00e8le Score (test dataset) Score (validation dataset) R\u00e9seau de neurones (DNN) 0.9246376811594202 0.9246376811594202 R\u00e9gression Logistique 0.8768115942028986 0.8951406649616368 SVM (SVC) 0.9318840579710145 0.9322250639386189 Random Forest 0.8840579710144928 0.9040920716112532"},{"location":"projects/tp_gnn/","title":"TP: R\u00e9seaux de neurones graphiques","text":"<p>Dans ce TP, on va appliquer les concepts d'extraction de caract\u00e9ristiques et de node embedding sur un dataset classique Karate Club Network.</p>"},{"location":"projects/tp_gnn/#representation-graphique-avec-networkx","title":"Repr\u00e9sentation graphique avec networkx","text":"<pre><code>import networkx as nx\n</code></pre>"},{"location":"projects/tp_gnn/#zacharys-karate-club-network","title":"Zachary's karate club network","text":"<p>Zachary's karate club est un graphe d\u00e9crivant un r\u00e9seau social de 34 membres d'un club de karat\u00e9. Les liens repr\u00e9sentent les interactions entre les membres en dehors du club.</p> <pre><code>G = nx.karate_club_graph()\n\nnx.draw(G, with_labels = True)\n</code></pre> Output <p></p>"},{"location":"projects/tp_gnn/#question-1-quel-est-le-degre-moyen-du-karate-club","title":"Question 1 : quel est le degr\u00e9 moyen du karat\u00e9 club ?","text":"<pre><code>def average_degree(num_edges, num_nodes):\n  # Cette fonction retourne le degr\u00e9 moyen du graphe.\n\n    avg_degree = 0\n\n    avg_degree = round(2 * num_edges/num_nodes)\n\n    return avg_degree\n\nnum_edges = G.number_of_edges()\nnum_nodes = G.number_of_nodes()\nprint(\"Nombre d'ar\u00eates :\", num_edges, \"Nombre de noeuds :\", num_nodes)\navg_degree = average_degree(num_edges, num_nodes)\nprint(\"Le degr\u00e9 moyen du karat\u00e9 club est : {}\".format(avg_degree))\n</code></pre> Output <p>Nombre d'ar\u00eates : 78 Nombre de noeuds : 34 Le degr\u00e9 moyen du karat\u00e9 club est : 5</p>"},{"location":"projects/tp_gnn/#question-2-quel-est-le-coefficient-de-clustering-moyen-du-karate-club","title":"Question 2 : quel est le coefficient de clustering moyen du karat\u00e9 club ?","text":"<pre><code>def average_clust_coef(G):\n  # Cette fonction retourne le coefficient de clustring moyen du caract\u00e9 club \n\n  ####### Code ########\n    avg_cluster_coef = nx.algorithms.cluster.average_clustering(G)\n  #####################\n\n    return avg_cluster_coef\n\navg_cluster_coef = average_clust_coef(G)\nprint(\"Le coefficient de clustering moyen du karat\u00e9 club est : {}\".format(avg_cluster_coef))\n</code></pre> Output <p>Le coefficient de clustering moyen du karat\u00e9 club est : 0.5706384782076823</p>"},{"location":"projects/tp_gnn/#question-3-quelle-est-la-centralite-de-proximite-du-noeud-numero-5","title":"Question 3 : quelle est la centralit\u00e9 de proximit\u00e9 du noeud num\u00e9ro 5 ?","text":"Output <p>La centralit\u00e9 de proximit\u00e9 est d\u00e9finie par :  c(v) = \\frac{1}{\\sum_{u \\neq v}\\text{le chemin le plus court entre } u \\text{ and } v}</p> <pre><code>def closeness_centrality(G, node = 5):\n  # Cette fonction retourne la centralit\u00e9 de proximit\u00e9 d'un noeud donn\u00e9\n\n  ###### Code #######\n    degree_centrality = nx.algorithms.centrality.closeness_centrality(G)\n    closeness = degree_centrality[node]\n  ###################\n\n    return closeness\n\nnode = 5\ncloseness = closeness_centrality(G, node=node)\nprint(\"La centralit\u00e9 de proximit\u00e9 du noeud num\u00e9ro 5 est : {}\".format(closeness))\n</code></pre> Output <p>La centralit\u00e9 de proximit\u00e9 du noeud num\u00e9ro 5 est : 0.38372093023255816</p>"},{"location":"projects/tp_gnn/#question-4-quelle-est-la-centralite-intermediaire-associee-a-un-noeud-donne-du-karacte-club","title":"Question 4 : quelle est la centralit\u00e9 interm\u00e9diaire associ\u00e9e \u00e0 un noeud donn\u00e9 du karact\u00e9 club ?","text":"<pre><code>def betweeness_centrality(G, node = 5):\n  # Cette fonction retourne la centralit\u00e9 interm\u00e9diaire d'un noeud donn\u00e9\n\n  ####### Code ########\n    btw_centrality = nx.algorithms.centrality.betweenness_centrality(G)\n    betweeness = btw_centrality[node]\n  #####################\n\n    return betweeness\nnode = 5\nbetweeness = betweeness_centrality(G, node=node)\nprint(\"La centralit\u00e9 interm\u00e9diaire du noeud num\u00e9ro 5 est : {}\".format(closeness))\n</code></pre> Output <p>La centralit\u00e9 interm\u00e9diaire du noeud num\u00e9ro 5 est : 0.38372093023255816</p>"},{"location":"projects/tp_gnn/#graphe-en-tenseur","title":"Graphe en Tenseur","text":"<p>Nous allons transformer le graphe  G  en tenseur Pytorch.</p> <pre><code>import torch\n</code></pre>"},{"location":"projects/tp_gnn/#question-5-liste-des-aretes-du-karate-club-en-format-torchlongtensor-quel-le-nombe-daretes-positives","title":"Question 5 : Liste des ar\u00eates du Karat\u00e9 club en format torch.LongTensor. Quel le nombe d'ar\u00eates positives ?","text":"<pre><code>def graph_to_edge_list(G):\n\n  # Cette fonction retourne la liste des ar\u00eates d'un graphe sous forme\n  # de couplet compos\u00e9 de deux noeuds.\n\n    edge_list = []\n    lst1 = []\n    lst2 = []\n\n  ############# Code ############\n    edge_list = list(G.edges())\n  #########################################\n\n    return edge_list\n\ndef edge_list_to_tensor(edge_list):\n\n  # Cette fonction transforme un liste d'ar\u00eates en Tenseur Pytorch\n  # de dimension [2 x len(edge_list)]\n\n    edge_index = torch.tensor([])\n\n  ############# Code ############\n    edge_index = torch.tensor(edge_list, dtype = torch.long).permute((1,0))\n  #########################################\n\n    return edge_index\n\npos_edge_list = graph_to_edge_list(G)\n# print(pos_edge_list)\npos_edge_index = edge_list_to_tensor(pos_edge_list)\nprint(\"La dimension de pos_edge_index est : {}\".format(pos_edge_index.shape))\nprint(\"La somme des valeurs de pos_edge_index : {}\".format(torch.sum(pos_edge_index)))\n</code></pre> Output <p>La dimension de pos_edge_index est : torch.Size([2, 78]) La somme des valeurs de pos_edge_index : 2535</p>"},{"location":"projects/tp_gnn/#question-6-ecrire-une-fonction-qui-retourne-les-aretes-negatives","title":"Question 6 : Ecrire une fonction qui retourne les ar\u00eates n\u00e9gatives.","text":"<pre><code>import random\n\ndef sample_negative_edges(G, num_neg_samples):\n\n  # Cette fonction retourne la liste des ar\u00eates n\u00e9gatives. \n\n    neg_edge_list = []\n    pos_set = set(G.edges())\n    visited_set = set()\n\n\n  ############# Code ############\n    for n_i in G.nodes():\n        for n_j in G.nodes():\n            if n_i == n_j or (n_i,n_j) in pos_set or (n_j,n_i) in pos_set or (n_i,n_j) in visited_set or (n_j, n_i) is visited_set:\n                continue\n            neg_edge_list.append((n_i,n_j))\n            visited_set.add((n_i,n_j))\n            visited_set.add((n_j,n_i))\n            if len(neg_edge_list) == num_neg_samples:\n                break\n\n  ###############################\n\n    return neg_edge_list\n\n# Echantillon de 78 ar\u00eates n\u00e9gatives\nneg_edge_list = sample_negative_edges(G, len(pos_edge_list))\n\n# Convertir la liste des ar\u00eates n\u00e9gatives en tenseur\nneg_edge_index = edge_list_to_tensor(neg_edge_list)\nprint(\"Le tenseur neg_edge_index est de dimension {}\".format(neg_edge_index.shape))\n\n# Quelles sont les ar\u00eates n\u00e9gatives parmi les ar\u00eates suivantes ?\nedge_1 = (7, 1)\nedge_2 = (1, 33)\nedge_3 = (33, 22)\nedge_4 = (0, 4)\nedge_5 = (4, 2)\n</code></pre> Output <p>Le tenseur neg_edge_index est de dimension torch.Size([2, 483])</p> <pre><code>a = nx.negative_edge_cycle(G)\nprint(a)\n</code></pre> Output <p>False</p>"},{"location":"projects/tp_gnn/#node-embeddings","title":"Node Embeddings","text":"<pre><code>import torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\n</code></pre> <p>On va utiliser ici le module nn.Embedding de PyTorch.</p> <pre><code># Initialisation de la couche d'embeddings\n# avec, par exemple, 4 objets de dimension 8 chacun\n\nemb_sample = nn.Embedding(num_embeddings=4, embedding_dim=8)\nprint('Embedding layer: {}'.format(emb_sample))\n</code></pre> Output <p>Embedding layer: Embedding(4, 8)</p> <p>Info</p> <p>On peut s\u00e9lectionner l'embedding d'un objet en utilisant l'indice correspondant.</p> <pre><code># S\u00e9lectionner un seul embedding\nid = torch.LongTensor([1])\nprint(emb_sample(id))\n\n# S\u00e9lectionner plusieurs embeddings\nids = torch.LongTensor([1, 3])\nprint(emb_sample(ids))\n\n# Obtenir la dimension de la mtrice de poids de l'embedding\nshape = emb_sample.weight.data.shape\nprint(shape)\n\n# Affecter de nouvelles valeurs \u00e0 la matrice de poids (ici des 1)\nemb_sample.weight.data = torch.ones(shape)\n\n# V\u00e9rifier la nouvelle affectation\nids = torch.LongTensor([0, 3])\nprint(emb_sample(ids))\n</code></pre> Output <p>tensor([[-0.6316,  0.5919,  0.3717, -0.0679, -1.0768,  0.7879, -0.3337,  1.6544]],        grad_fn=) tensor([[-0.6316,  0.5919,  0.3717, -0.0679, -1.0768,  0.7879, -0.3337,  1.6544],         [ 1.4465,  0.5489, -0.5271, -1.6461,  0.5401, -0.8992,  0.6385,  0.8055]],        grad_fn=) torch.Size([4, 8]) tensor([[1., 1., 1., 1., 1., 1., 1., 1.],         [1., 1., 1., 1., 1., 1., 1., 1.]], grad_fn=) <p>On va appliquer \u00e0 cela au jeu de donn\u00e9es Zachary's karat\u00e9 club. On va associer un vecteur de dimension 16 \u00e0 chaque noeud du graphe. on va initialiser la matrice avec une distribution uniforme dans  [0,1]  en utilisant torch.rand.</p> <pre><code>torch.manual_seed(1)\n\ndef create_node_emb(num_node=34, embedding_dim=16):\n\n  # Ecrire une fonction qui impl\u00e9mente la matrice d'embeddings pour les noeuds.\n  # La fonction doit retourner un embedding de format torch.nn initalis\u00e9 selon\n  # une loi uniforme dans [0,1].\n\n    emb = None\n\n  ############# Code ############\n    emb = nn.Embedding(num_embeddings=num_nodes, embedding_dim=embedding_dim)\n    shape = emb.weight.data.shape\n    emb.weight.data = torch.rand(shape)\n  ###############################\n\n    return emb\n\nemb = create_node_emb()\nids = torch.LongTensor([0, 3])\n\nprint(\"Embedding: {}\".format(emb))\n\nprint(emb(ids))\n</code></pre> Output <p>Embedding: Embedding(34, 16) tensor([[0.2114, 0.7335, 0.1433, 0.9647, 0.2933, 0.7951, 0.5170, 0.2801, 0.8339,          0.1185, 0.2355, 0.5599, 0.8966, 0.2858, 0.1955, 0.1808],         [0.7486, 0.6546, 0.3843, 0.9820, 0.6012, 0.3710, 0.4929, 0.9915, 0.8358,          0.4629, 0.9902, 0.7196, 0.2338, 0.0450, 0.7906, 0.9689]],     grad_fn=)"},{"location":"projects/tp_gnn/#visualisation-des-embeddings","title":"Visualisation des embeddings","text":"<p>Nous allons projet les embeddings inialis\u00e9s ci-dessous en deux dimensions afin de les visualiser.</p> <pre><code>def visualize_emb(emb):\n    X = emb.weight.data.numpy()\n    pca = PCA(n_components=2)\n    components = pca.fit_transform(X)\n    plt.figure(figsize=(6, 6))\n    club1_x = []\n    club1_y = []\n    club2_x = []\n    club2_y = []\n    for node in G.nodes(data=True):\n        if node[1]['club'] == 'Mr. Hi':\n            club1_x.append(components[node[0]][0])\n            club1_y.append(components[node[0]][1])\n        else:\n            club2_x.append(components[node[0]][0])\n            club2_y.append(components[node[0]][1])\n    plt.scatter(club1_x, club1_y, color=\"red\", label=\"Mr. Hi\")\n    plt.scatter(club2_x, club2_y, color=\"blue\", label=\"Officer\")\n    plt.legend()\n    plt.show()\n\n# Visualize the initial random embeddding\nvisualize_emb(emb)\n</code></pre> Output <p></p>"},{"location":"projects/tp_gnn/#question-7-calcul-des-embeddings-par-descente-du-gradient","title":"Question 7 : calcul des embeddings par descente du gradient.","text":"<pre><code>from torch.optim import SGD\n\ndef accuracy(pred, label):\n  # Cette fonction prend les pr\u00e9dictions r\u00e9alis\u00e9es, \n  # les arrondit et calcul la pr\u00e9cision du mod\u00e8le.\n\n    accu = 0.0\n    accu = torch.sum(torch.round(pred) == label) / pred.shape[0]\n\n    return accu\n\ndef train(emb, loss_fn, sigmoid, train_label, train_edge):\n  # Cette fonction entra\u00eene les embeddings par SGD.\n  # A faire :\n  # 1 : r\u00e9cup\u00e9rer les embeddings respectifs des noeuds \u00e0 partir de train_edge\n  # 2 : Calculer le produit scalaire des embeddings de chaque paire de noeuds\n  # 3 : Appliquer une fonction sigmo\u00efde au produit scalaire calcul\u00e9\n  # 4 : Appliquer la loss_fn au r\u00e9sultat de la fonction sigmo\u00efde\n  # 5 : Imprimer la fonction loss et la pr\u00e9cision \u00e0 chaque epoch. \n  # (as a sanity check, the loss should decrease during training)\n\n\n\n    epochs = 500\n    learning_rate = 0.1\n\n    optimizer = SGD(emb.parameters(), lr=learning_rate, momentum=0.9)\n\n    for i in range(epochs):\n\n\n    ############# Code ###########\n        optimizer.zero_grad()  # Clear gradients.\n\n        product = torch.sum(torch.mul(emb(train_edge[0]),emb(train_edge[1])), axis = 1)\n        pred = torch.sigmoid(product)\n        loss = loss_fn(pred, train_label)\n        loss.backward()  # Derive gradients.\n        optimizer.step()  # Update parameters based on gradients.\n\n\n        with torch.no_grad():\n            accu = accuracy(pred, train_label)\n            if i % 100 == 0:\n                visualize_emb(emb)\n            print(\"loss: {}, accuracy: {}\".format(loss.item(), accu))\n\n    ##############################\n\nloss_fn = nn.BCELoss()\nsigmoid = nn.Sigmoid()\n\n# G\u00e9n\u00e9rer les labels positifs et n\u00e9gatifs\npos_label = torch.ones(pos_edge_index.shape[1], )\nneg_label = torch.zeros(neg_edge_index.shape[1], )\n\n# Concat\u00e9ner les labels positifs and n\u00e9gatifs dans le m\u00eame tenseur\ntrain_label = torch.cat([pos_label, neg_label], dim=0)\n\n\ntrain_edge = torch.cat([pos_edge_index, neg_edge_index], dim=1)\n\ntrain(emb, loss_fn, sigmoid, train_label, train_edge)\n</code></pre> Output <p>loss: 3.468411684036255, accuracy: 0.13903743028640747 loss: 3.43456768989563, accuracy: 0.13903743028640747 loss: 3.371028184890747, accuracy: 0.13903743028640747 loss: 3.282146453857422, accuracy: 0.13903743028640747 loss: 3.1723263263702393, accuracy: 0.13903743028640747 loss: 3.045901298522949, accuracy: 0.13903743028640747 loss: 2.907038450241089, accuracy: 0.13903743028640747 loss: 2.7596638202667236, accuracy: 0.13903743028640747 loss: 2.6074018478393555, accuracy: 0.13903743028640747 loss: 2.4535279273986816, accuracy: 0.13903743028640747 loss: 2.3009305000305176, accuracy: 0.13903743028640747 loss: 2.152082920074463, accuracy: 0.13903743028640747 loss: 2.009026050567627, accuracy: 0.13903743028640747 loss: 1.8733632564544678, accuracy: 0.13903743028640747 loss: 1.7462693452835083, accuracy: 0.13903743028640747 loss: 1.6285123825073242, accuracy: 0.13903743028640747 loss: 1.5204927921295166, accuracy: 0.14260248839855194 loss: 1.4222900867462158, accuracy: 0.14438502490520477 loss: 1.3337185382843018, accuracy: 0.14973261952400208 loss: 1.254386305809021, accuracy: 0.15508021414279938 loss: 1.183752417564392, accuracy: 0.16399286687374115 loss: 1.1211791038513184, accuracy: 0.17290551960468292 loss: 1.0659770965576172, accuracy: 0.18538324534893036 loss: 1.0174411535263062, accuracy: 0.20677362382411957 loss: 0.9748789668083191, accuracy: 0.22281639277935028 loss: 0.937629222869873, accuracy: 0.2442067712545395 loss: 0.9050756096839905, accuracy: 0.2549019753932953 loss: 0.8766528964042664, accuracy: 0.27807486057281494 loss: 0.8518502116203308, accuracy: 0.3030303120613098 loss: 0.8302105069160461, accuracy: 0.3333333432674408 loss: 0.8113287091255188, accuracy: 0.35650622844696045 loss: 0.7948473691940308, accuracy: 0.38324421644210815 loss: 0.7804537415504456, accuracy: 0.40463459491729736 loss: 0.7678741216659546, accuracy: 0.4153297543525696 loss: 0.7568702101707458, accuracy: 0.4367201328277588 loss: 0.7472350597381592, accuracy: 0.4474153220653534 loss: 0.7387885451316833, accuracy: 0.45989304780960083 loss: 0.731374979019165, accuracy: 0.4777183532714844 loss: 0.7248587012290955, accuracy: 0.48663100600242615 loss: 0.7191224098205566, accuracy: 0.5080214142799377 loss: 0.714064359664917, accuracy: 0.5222816467285156 loss: 0.7095963358879089, accuracy: 0.5204991102218628 loss: 0.7056415677070618, accuracy: 0.531194269657135 loss: 0.7021337151527405, accuracy: 0.5347593426704407 loss: 0.6990148425102234, accuracy: 0.5436720252037048 loss: 0.6962348818778992, accuracy: 0.5472370982170105 loss: 0.6937502026557922, accuracy: 0.5490196347236633 loss: 0.6915227174758911, accuracy: 0.554367184638977 loss: 0.689519464969635, accuracy: 0.5561497211456299 loss: 0.6877117156982422, accuracy: 0.5561497211456299 loss: 0.686074435710907, accuracy: 0.565062403678894 loss: 0.6845855712890625, accuracy: 0.5704099535942078 loss: 0.683226466178894, accuracy: 0.5739750266075134 loss: 0.6819803714752197, accuracy: 0.5757575631141663 loss: 0.68083256483078, accuracy: 0.5739750266075134 loss: 0.6797709465026855, accuracy: 0.5739750266075134 loss: 0.6787840723991394, accuracy: 0.5757575631141663 loss: 0.6778624653816223, accuracy: 0.5793226361274719 loss: 0.6769978404045105, accuracy: 0.5793226361274719 loss: 0.6761825680732727, accuracy: 0.5828877091407776 loss: 0.6754106283187866, accuracy: 0.5846702456474304 loss: 0.6746761202812195, accuracy: 0.5846702456474304 loss: 0.6739742159843445, accuracy: 0.5882353186607361 loss: 0.6733008027076721, accuracy: 0.5900177955627441 loss: 0.672652006149292, accuracy: 0.591800332069397 loss: 0.6720245480537415, accuracy: 0.5900177955627441 loss: 0.6714155673980713, accuracy: 0.5900177955627441 loss: 0.6708226799964905, accuracy: 0.5900177955627441 loss: 0.670243501663208, accuracy: 0.5900177955627441 loss: 0.6696761846542358, accuracy: 0.5935828685760498 loss: 0.6691192388534546, accuracy: 0.591800332069397 loss: 0.6685709357261658, accuracy: 0.5900177955627441 loss: 0.6680300831794739, accuracy: 0.5900177955627441 loss: 0.6674955487251282, accuracy: 0.5900177955627441 loss: 0.6669663190841675, accuracy: 0.591800332069397 loss: 0.6664415597915649, accuracy: 0.591800332069397 loss: 0.6659204363822937, accuracy: 0.5935828685760498 loss: 0.6654024720191956, accuracy: 0.5935828685760498 loss: 0.6648867726325989, accuracy: 0.5935828685760498 loss: 0.664372980594635, accuracy: 0.5971479415893555 loss: 0.6638606786727905, accuracy: 0.5989304780960083 loss: 0.6633493900299072, accuracy: 0.602495551109314 loss: 0.6628386974334717, accuracy: 0.6042780876159668 loss: 0.6623283624649048, accuracy: 0.6078431606292725 loss: 0.6618180274963379, accuracy: 0.6114081740379333 loss: 0.6613075137138367, accuracy: 0.6131907105445862 loss: 0.6607966423034668, accuracy: 0.614973247051239 loss: 0.6602851748466492, accuracy: 0.6167557835578918 loss: 0.6597728729248047, accuracy: 0.6167557835578918 loss: 0.6592594981193542, accuracy: 0.614973247051239 loss: 0.6587451696395874, accuracy: 0.6167557835578918 loss: 0.6582295298576355, accuracy: 0.6167557835578918 loss: 0.6577125191688538, accuracy: 0.6185383200645447 loss: 0.6571941375732422, accuracy: 0.6185383200645447 loss: 0.6566741466522217, accuracy: 0.6185383200645447 loss: 0.6561526656150818, accuracy: 0.6221033930778503 loss: 0.6556293368339539, accuracy: 0.6238859295845032 loss: 0.6551043391227722, accuracy: 0.625668466091156 loss: 0.6545774936676025, accuracy: 0.625668466091156 loss: 0.6540487408638, accuracy: 0.6274510025978088</p> <p></p> <p>loss: 0.65351802110672, accuracy: 0.6274510025978088 loss: 0.6529853940010071, accuracy: 0.6274510025978088 loss: 0.6524505615234375, accuracy: 0.6292335391044617 loss: 0.6519137620925903, accuracy: 0.6292335391044617 loss: 0.6513748168945312, accuracy: 0.6310160160064697 loss: 0.650833785533905, accuracy: 0.6345810890197754 loss: 0.6502905488014221, accuracy: 0.6327985525131226 loss: 0.6497451663017273, accuracy: 0.6345810890197754 loss: 0.6491974592208862, accuracy: 0.638146162033081 loss: 0.6486475467681885, accuracy: 0.638146162033081 loss: 0.6480953693389893, accuracy: 0.6434937715530396 loss: 0.6475409865379333, accuracy: 0.6434937715530396 loss: 0.6469841599464417, accuracy: 0.6417112350463867 loss: 0.6464250683784485, accuracy: 0.6434937715530396 loss: 0.6458637714385986, accuracy: 0.6452763080596924 loss: 0.645300030708313, accuracy: 0.6452763080596924 loss: 0.6447339057922363, accuracy: 0.6452763080596924 loss: 0.6441654562950134, accuracy: 0.6452763080596924 loss: 0.6435947418212891, accuracy: 0.6452763080596924 loss: 0.6430215835571289, accuracy: 0.6452763080596924 loss: 0.6424461603164673, accuracy: 0.648841381072998 loss: 0.6418682932853699, accuracy: 0.6524063944816589 loss: 0.6412880420684814, accuracy: 0.6541889309883118 loss: 0.6407055258750916, accuracy: 0.6541889309883118 loss: 0.6401206254959106, accuracy: 0.6524063944816589 loss: 0.6395334601402283, accuracy: 0.6524063944816589 loss: 0.6389438509941101, accuracy: 0.6524063944816589 loss: 0.6383520364761353, accuracy: 0.6559714674949646 loss: 0.6377577781677246, accuracy: 0.6559714674949646 loss: 0.6371612548828125, accuracy: 0.6559714674949646 loss: 0.6365625858306885, accuracy: 0.6559714674949646 loss: 0.6359614133834839, accuracy: 0.6595365405082703 loss: 0.6353582143783569, accuracy: 0.6595365405082703 loss: 0.6347528100013733, accuracy: 0.6595365405082703 loss: 0.6341450214385986, accuracy: 0.6595365405082703 loss: 0.6335352063179016, accuracy: 0.6613190770149231 loss: 0.6329231262207031, accuracy: 0.6631016135215759 loss: 0.6323089599609375, accuracy: 0.6613190770149231 loss: 0.6316927075386047, accuracy: 0.6631016135215759 loss: 0.6310743093490601, accuracy: 0.6631016135215759 loss: 0.6304540038108826, accuracy: 0.6648841500282288 loss: 0.6298316717147827, accuracy: 0.6666666865348816 loss: 0.6292073130607605, accuracy: 0.6648841500282288 loss: 0.6285809278488159, accuracy: 0.6648841500282288 loss: 0.6279527544975281, accuracy: 0.6648841500282288 loss: 0.6273227334022522, accuracy: 0.6648841500282288 loss: 0.6266907453536987, accuracy: 0.6666666865348816 loss: 0.6260570287704468, accuracy: 0.6666666865348816 loss: 0.6254215836524963, accuracy: 0.6702316999435425 loss: 0.624784529209137, accuracy: 0.6720142364501953 loss: 0.6241457462310791, accuracy: 0.6702316999435425 loss: 0.6235052347183228, accuracy: 0.6737967729568481 loss: 0.6228633522987366, accuracy: 0.675579309463501 loss: 0.6222198009490967, accuracy: 0.6773618459701538 loss: 0.6215748190879822, accuracy: 0.6809269189834595 loss: 0.6209284067153931, accuracy: 0.6809269189834595 loss: 0.6202806830406189, accuracy: 0.6809269189834595 loss: 0.6196316480636597, accuracy: 0.6827094554901123 loss: 0.6189813613891602, accuracy: 0.6827094554901123 loss: 0.6183297634124756, accuracy: 0.6827094554901123 loss: 0.6176772117614746, accuracy: 0.6844919919967651 loss: 0.6170234680175781, accuracy: 0.686274528503418 loss: 0.6163687109947205, accuracy: 0.6880570650100708 loss: 0.6157130002975464, accuracy: 0.6898396015167236 loss: 0.6150563955307007, accuracy: 0.6916220784187317 loss: 0.6143988966941833, accuracy: 0.6916220784187317 loss: 0.6137406826019287, accuracy: 0.6934046149253845 loss: 0.6130816340446472, accuracy: 0.6951871514320374 loss: 0.6124221086502075, accuracy: 0.6951871514320374 loss: 0.6117619276046753, accuracy: 0.6951871514320374 loss: 0.6111010909080505, accuracy: 0.6969696879386902 loss: 0.6104399561882019, accuracy: 0.6969696879386902 loss: 0.6097782850265503, accuracy: 0.7005347609519958 loss: 0.6091163754463196, accuracy: 0.698752224445343 loss: 0.6084542870521545, accuracy: 0.7005347609519958 loss: 0.6077919602394104, accuracy: 0.698752224445343 loss: 0.6071293950080872, accuracy: 0.7005347609519958 loss: 0.6064668297767639, accuracy: 0.7005347609519958 loss: 0.6058043241500854, accuracy: 0.7040998339653015 loss: 0.6051419377326965, accuracy: 0.7040998339653015 loss: 0.6044796109199524, accuracy: 0.7040998339653015 loss: 0.6038175225257874, accuracy: 0.7040998339653015 loss: 0.6031557321548462, accuracy: 0.7058823704719543 loss: 0.6024941802024841, accuracy: 0.7076649069786072 loss: 0.601833164691925, accuracy: 0.70944744348526 loss: 0.601172685623169, accuracy: 0.70944744348526 loss: 0.6005127429962158, accuracy: 0.7112299203872681 loss: 0.5998533368110657, accuracy: 0.70944744348526 loss: 0.5991947054862976, accuracy: 0.70944744348526 loss: 0.5985367298126221, accuracy: 0.70944744348526 loss: 0.5978797078132629, accuracy: 0.7112299203872681 loss: 0.5972235202789307, accuracy: 0.7112299203872681 loss: 0.5965683460235596, accuracy: 0.7112299203872681 loss: 0.5959141254425049, accuracy: 0.70944744348526 loss: 0.5952609777450562, accuracy: 0.7147949934005737 loss: 0.5946089625358582, accuracy: 0.7147949934005737 loss: 0.5939582586288452, accuracy: 0.7112299203872681 loss: 0.593308687210083, accuracy: 0.7147949934005737 loss: 0.5926604866981506, accuracy: 0.7130124568939209 loss: 0.5920137763023376, accuracy: 0.7130124568939209</p> <p></p> <p>loss: 0.5913684368133545, accuracy: 0.7130124568939209 loss: 0.5907245874404907, accuracy: 0.7130124568939209 loss: 0.5900822281837463, accuracy: 0.7147949934005737 loss: 0.58944171667099, accuracy: 0.7183600664138794 loss: 0.5888026356697083, accuracy: 0.7147949934005737 loss: 0.5881654024124146, accuracy: 0.7147949934005737 loss: 0.5875298976898193, accuracy: 0.7147949934005737 loss: 0.5868962407112122, accuracy: 0.7147949934005737 loss: 0.5862644910812378, accuracy: 0.7147949934005737 loss: 0.5856345891952515, accuracy: 0.7147949934005737 loss: 0.5850067138671875, accuracy: 0.7147949934005737 loss: 0.5843808054924011, accuracy: 0.7147949934005737 loss: 0.5837571024894714, accuracy: 0.7147949934005737 loss: 0.5831353068351746, accuracy: 0.7147949934005737 loss: 0.5825158357620239, accuracy: 0.7165775299072266 loss: 0.5818983912467957, accuracy: 0.7147949934005737 loss: 0.5812832713127136, accuracy: 0.7147949934005737 loss: 0.5806704163551331, accuracy: 0.7147949934005737 loss: 0.5800597667694092, accuracy: 0.7165775299072266 loss: 0.5794515609741211, accuracy: 0.7165775299072266 loss: 0.5788455605506897, accuracy: 0.7165775299072266 loss: 0.5782421231269836, accuracy: 0.7165775299072266 loss: 0.577640950679779, accuracy: 0.7147949934005737 loss: 0.577042281627655, accuracy: 0.7147949934005737 loss: 0.5764461755752563, accuracy: 0.7130124568939209 loss: 0.5758525133132935, accuracy: 0.7147949934005737 loss: 0.5752614140510559, accuracy: 0.7147949934005737 loss: 0.5746727585792542, accuracy: 0.7147949934005737 loss: 0.5740866661071777, accuracy: 0.7165775299072266 loss: 0.5735033750534058, accuracy: 0.7165775299072266 loss: 0.5729224681854248, accuracy: 0.7165775299072266 loss: 0.5723443031311035, accuracy: 0.7183600664138794 loss: 0.5717687606811523, accuracy: 0.7183600664138794 loss: 0.5711959004402161, accuracy: 0.7165775299072266 loss: 0.5706256031990051, accuracy: 0.7147949934005737 loss: 0.5700580477714539, accuracy: 0.7147949934005737 loss: 0.5694931745529175, accuracy: 0.7147949934005737 loss: 0.568930983543396, accuracy: 0.7147949934005737 loss: 0.5683714747428894, accuracy: 0.7147949934005737 loss: 0.5678147077560425, accuracy: 0.7130124568939209 loss: 0.5672606229782104, accuracy: 0.7130124568939209 loss: 0.5667092204093933, accuracy: 0.7130124568939209 loss: 0.5661605596542358, accuracy: 0.7183600664138794 loss: 0.5656147003173828, accuracy: 0.7183600664138794 loss: 0.5650715231895447, accuracy: 0.7183600664138794 loss: 0.5645310282707214, accuracy: 0.7183600664138794 loss: 0.5639932155609131, accuracy: 0.7165775299072266 loss: 0.5634582042694092, accuracy: 0.7165775299072266 loss: 0.5629258155822754, accuracy: 0.7165775299072266 loss: 0.562396228313446, accuracy: 0.7165775299072266 loss: 0.5618692636489868, accuracy: 0.7147949934005737 loss: 0.5613449811935425, accuracy: 0.7147949934005737 loss: 0.5608234405517578, accuracy: 0.7147949934005737 loss: 0.5603045225143433, accuracy: 0.7147949934005737 loss: 0.5597882866859436, accuracy: 0.7165775299072266 loss: 0.5592747330665588, accuracy: 0.7165775299072266 loss: 0.5587638020515442, accuracy: 0.7147949934005737 loss: 0.5582554936408997, accuracy: 0.7165775299072266 loss: 0.5577497482299805, accuracy: 0.7165775299072266 loss: 0.5572466850280762, accuracy: 0.7165775299072266 loss: 0.5567461848258972, accuracy: 0.7147949934005737 loss: 0.5562481880187988, accuracy: 0.7147949934005737 loss: 0.5557528138160706, accuracy: 0.7147949934005737 loss: 0.5552600026130676, accuracy: 0.7147949934005737 loss: 0.55476975440979, accuracy: 0.7147949934005737 loss: 0.5542818903923035, accuracy: 0.7183600664138794 loss: 0.5537965893745422, accuracy: 0.7165775299072266 loss: 0.5533138513565063, accuracy: 0.7201426029205322 loss: 0.5528334975242615, accuracy: 0.7201426029205322 loss: 0.5523555874824524, accuracy: 0.7254902124404907 loss: 0.5518800020217896, accuracy: 0.7254902124404907 loss: 0.551406979560852, accuracy: 0.7254902124404907 loss: 0.5509361624717712, accuracy: 0.7272727489471436 loss: 0.5504679083824158, accuracy: 0.7254902124404907 loss: 0.550001859664917, accuracy: 0.7254902124404907 loss: 0.5495381951332092, accuracy: 0.7254902124404907 loss: 0.5490767955780029, accuracy: 0.7254902124404907 loss: 0.5486176609992981, accuracy: 0.7254902124404907 loss: 0.5481607913970947, accuracy: 0.7272727489471436 loss: 0.5477061867713928, accuracy: 0.7272727489471436 loss: 0.5472538471221924, accuracy: 0.7272727489471436 loss: 0.5468035936355591, accuracy: 0.7272727489471436 loss: 0.5463555455207825, accuracy: 0.7272727489471436 loss: 0.5459097027778625, accuracy: 0.7272727489471436 loss: 0.545465886592865, accuracy: 0.7272727489471436 loss: 0.5450242757797241, accuracy: 0.7272727489471436 loss: 0.5445848107337952, accuracy: 0.7272727489471436 loss: 0.544147253036499, accuracy: 0.7272727489471436 loss: 0.54371178150177, accuracy: 0.7272727489471436 loss: 0.5432783365249634, accuracy: 0.7272727489471436 loss: 0.5428469777107239, accuracy: 0.7290552854537964 loss: 0.5424174666404724, accuracy: 0.7290552854537964 loss: 0.5419899821281433, accuracy: 0.7290552854537964 loss: 0.541564404964447, accuracy: 0.7308377623558044 loss: 0.5411407351493835, accuracy: 0.7326202988624573 loss: 0.5407189726829529, accuracy: 0.7326202988624573 loss: 0.5402990579605103, accuracy: 0.7326202988624573 loss: 0.5398810505867004, accuracy: 0.7326202988624573 loss: 0.5394647121429443, accuracy: 0.7326202988624573 loss: 0.5390503406524658, accuracy: 0.7326202988624573</p> <p></p> <p>loss: 0.5386376976966858, accuracy: 0.7344028353691101 loss: 0.538226842880249, accuracy: 0.7344028353691101 loss: 0.5378177165985107, accuracy: 0.7344028353691101 loss: 0.537410318851471, accuracy: 0.7344028353691101 loss: 0.5370044708251953, accuracy: 0.7344028353691101 loss: 0.5366004705429077, accuracy: 0.7344028353691101 loss: 0.536198079586029, accuracy: 0.7344028353691101 loss: 0.5357974171638489, accuracy: 0.7344028353691101 loss: 0.5353982448577881, accuracy: 0.7361853718757629 loss: 0.535000741481781, accuracy: 0.7361853718757629 loss: 0.5346047878265381, accuracy: 0.7361853718757629 loss: 0.5342103838920593, accuracy: 0.7361853718757629 loss: 0.5338175296783447, accuracy: 0.7361853718757629 loss: 0.5334262251853943, accuracy: 0.7361853718757629 loss: 0.5330364108085632, accuracy: 0.7361853718757629 loss: 0.532647967338562, accuracy: 0.7379679083824158 loss: 0.5322611331939697, accuracy: 0.7379679083824158 loss: 0.5318756699562073, accuracy: 0.7344028353691101 loss: 0.5314916968345642, accuracy: 0.7361853718757629 loss: 0.531109094619751, accuracy: 0.7361853718757629 loss: 0.5307279229164124, accuracy: 0.7361853718757629 loss: 0.5303480625152588, accuracy: 0.7361853718757629 loss: 0.5299695730209351, accuracy: 0.7361853718757629 loss: 0.5295924544334412, accuracy: 0.7361853718757629 loss: 0.5292166471481323, accuracy: 0.7361853718757629 loss: 0.5288420915603638, accuracy: 0.7361853718757629 loss: 0.528468906879425, accuracy: 0.7361853718757629 loss: 0.5280970335006714, accuracy: 0.7361853718757629 loss: 0.5277262926101685, accuracy: 0.7361853718757629 loss: 0.5273568630218506, accuracy: 0.7344028353691101 loss: 0.5269885659217834, accuracy: 0.7344028353691101 loss: 0.5266215801239014, accuracy: 0.7361853718757629 loss: 0.5262557864189148, accuracy: 0.7361853718757629 loss: 0.5258911848068237, accuracy: 0.7361853718757629 loss: 0.5255276560783386, accuracy: 0.7379679083824158 loss: 0.5251653790473938, accuracy: 0.7397504448890686 loss: 0.5248041749000549, accuracy: 0.7379679083824158 loss: 0.524444043636322, accuracy: 0.7379679083824158 loss: 0.5240850448608398, accuracy: 0.7379679083824158 loss: 0.5237272381782532, accuracy: 0.7379679083824158 loss: 0.5233704447746277, accuracy: 0.7379679083824158 loss: 0.5230147242546082, accuracy: 0.7379679083824158 loss: 0.5226598978042603, accuracy: 0.7397504448890686 loss: 0.5223063230514526, accuracy: 0.7397504448890686 loss: 0.5219537019729614, accuracy: 0.7397504448890686 loss: 0.5216020941734314, accuracy: 0.7397504448890686 loss: 0.5212514996528625, accuracy: 0.7397504448890686 loss: 0.5209018588066101, accuracy: 0.7397504448890686 loss: 0.5205531716346741, accuracy: 0.7397504448890686 loss: 0.5202054381370544, accuracy: 0.7397504448890686 loss: 0.519858717918396, accuracy: 0.7397504448890686 loss: 0.5195128917694092, accuracy: 0.7397504448890686 loss: 0.5191680192947388, accuracy: 0.7415329813957214 loss: 0.51882404088974, accuracy: 0.7450980544090271 loss: 0.5184809565544128, accuracy: 0.7433155179023743 loss: 0.5181388258934021, accuracy: 0.7433155179023743 loss: 0.5177974700927734, accuracy: 0.7433155179023743 loss: 0.5174570083618164, accuracy: 0.7433155179023743 loss: 0.5171175003051758, accuracy: 0.7433155179023743 loss: 0.5167787671089172, accuracy: 0.7433155179023743 loss: 0.5164408683776855, accuracy: 0.7433155179023743 loss: 0.5161037445068359, accuracy: 0.7433155179023743 loss: 0.515767514705658, accuracy: 0.7433155179023743 loss: 0.5154321193695068, accuracy: 0.7450980544090271 loss: 0.515097439289093, accuracy: 0.7468805909156799 loss: 0.5147635340690613, accuracy: 0.7486631274223328 loss: 0.514430582523346, accuracy: 0.7504456043243408 loss: 0.5140981674194336, accuracy: 0.7504456043243408 loss: 0.5137667059898376, accuracy: 0.7504456043243408 loss: 0.5134359002113342, accuracy: 0.7504456043243408 loss: 0.5131058096885681, accuracy: 0.7504456043243408 loss: 0.5127764940261841, accuracy: 0.7504456043243408 loss: 0.5124478936195374, accuracy: 0.7486631274223328 loss: 0.5121200680732727, accuracy: 0.7486631274223328 loss: 0.5117928385734558, accuracy: 0.7486631274223328 loss: 0.5114663243293762, accuracy: 0.7486631274223328 loss: 0.5111406445503235, accuracy: 0.7504456043243408 loss: 0.5108155012130737, accuracy: 0.7486631274223328 loss: 0.5104910731315613, accuracy: 0.7468805909156799 loss: 0.5101673603057861, accuracy: 0.7468805909156799 loss: 0.5098442435264587, accuracy: 0.7468805909156799 loss: 0.5095217823982239, accuracy: 0.7486631274223328 loss: 0.5092000365257263, accuracy: 0.7486631274223328 loss: 0.5088788866996765, accuracy: 0.7486631274223328 loss: 0.5085583329200745, accuracy: 0.7504456043243408 loss: 0.5082384943962097, accuracy: 0.7504456043243408 loss: 0.5079192519187927, accuracy: 0.7504456043243408 loss: 0.5076005458831787, accuracy: 0.7504456043243408 loss: 0.5072824954986572, accuracy: 0.7504456043243408 loss: 0.5069650411605835, accuracy: 0.7504456043243408 loss: 0.5066481828689575, accuracy: 0.7504456043243408 loss: 0.5063318610191345, accuracy: 0.7504456043243408 loss: 0.506016194820404, accuracy: 0.7504456043243408 loss: 0.5057010650634766, accuracy: 0.7504456043243408 loss: 0.505386471748352, accuracy: 0.7504456043243408 loss: 0.5050725340843201, accuracy: 0.7522281408309937 loss: 0.5047590732574463, accuracy: 0.7540106773376465 loss: 0.5044461488723755, accuracy: 0.7557932138442993 loss: 0.5041337609291077, accuracy: 0.7557932138442993 loss: 0.5038220286369324, accuracy: 0.7557932138442993</p> <p></p> <p>loss: 0.5035106539726257, accuracy: 0.7557932138442993 loss: 0.5031999349594116, accuracy: 0.7557932138442993 loss: 0.5028897523880005, accuracy: 0.7557932138442993 loss: 0.5025800466537476, accuracy: 0.7557932138442993 loss: 0.5022708773612976, accuracy: 0.7540106773376465 loss: 0.5019621849060059, accuracy: 0.7540106773376465 loss: 0.5016539096832275, accuracy: 0.7540106773376465 loss: 0.501346230506897, accuracy: 0.7522281408309937 loss: 0.5010391473770142, accuracy: 0.7522281408309937 loss: 0.5007324814796448, accuracy: 0.7522281408309937 loss: 0.5004262328147888, accuracy: 0.7522281408309937 loss: 0.5001205205917358, accuracy: 0.7522281408309937 loss: 0.4998152554035187, accuracy: 0.7540106773376465 loss: 0.4995104670524597, accuracy: 0.7540106773376465 loss: 0.49920615553855896, accuracy: 0.7540106773376465 loss: 0.498902291059494, accuracy: 0.7540106773376465 loss: 0.4985989034175873, accuracy: 0.7540106773376465 loss: 0.49829596281051636, accuracy: 0.7540106773376465 loss: 0.49799349904060364, accuracy: 0.7522281408309937 loss: 0.49769142270088196, accuracy: 0.7522281408309937 loss: 0.49738985300064087, accuracy: 0.7522281408309937 loss: 0.4970887005329132, accuracy: 0.7522281408309937 loss: 0.49678799510002136, accuracy: 0.7540106773376465 loss: 0.49648764729499817, accuracy: 0.7540106773376465 loss: 0.49618786573410034, accuracy: 0.7540106773376465 loss: 0.49588844180107117, accuracy: 0.7540106773376465 loss: 0.4955894351005554, accuracy: 0.7540106773376465 loss: 0.4952908158302307, accuracy: 0.7540106773376465 loss: 0.494992733001709, accuracy: 0.7540106773376465 loss: 0.49469494819641113, accuracy: 0.7540106773376465 loss: 0.4943976104259491, accuracy: 0.7540106773376465 loss: 0.4941006302833557, accuracy: 0.7540106773376465 loss: 0.4938041567802429, accuracy: 0.7540106773376465 loss: 0.493507981300354, accuracy: 0.7557932138442993 loss: 0.4932122528553009, accuracy: 0.7557932138442993 loss: 0.49291694164276123, accuracy: 0.7575757503509521 loss: 0.49262192845344543, accuracy: 0.7575757503509521 loss: 0.49232742190361023, accuracy: 0.7575757503509521 loss: 0.4920332133769989, accuracy: 0.7575757503509521 loss: 0.491739422082901, accuracy: 0.7575757503509521 loss: 0.49144604802131653, accuracy: 0.759358286857605 loss: 0.4911530017852783, accuracy: 0.759358286857605 loss: 0.49086034297943115, accuracy: 0.759358286857605 loss: 0.4905681610107422, accuracy: 0.759358286857605 loss: 0.49027615785598755, accuracy: 0.759358286857605 loss: 0.4899846315383911, accuracy: 0.7611408233642578 loss: 0.4896934926509857, accuracy: 0.7611408233642578 loss: 0.4894026219844818, accuracy: 0.7611408233642578 loss: 0.4891121983528137, accuracy: 0.7611408233642578 loss: 0.4888221323490143, accuracy: 0.7611408233642578 loss: 0.4885323941707611, accuracy: 0.7611408233642578 loss: 0.48824307322502136, accuracy: 0.7611408233642578 loss: 0.4879539906978607, accuracy: 0.759358286857605 loss: 0.4876653552055359, accuracy: 0.759358286857605 loss: 0.4873770475387573, accuracy: 0.759358286857605 loss: 0.48708903789520264, accuracy: 0.7629233598709106 loss: 0.48680150508880615, accuracy: 0.7629233598709106 loss: 0.4865141212940216, accuracy: 0.7647058963775635 loss: 0.4862271547317505, accuracy: 0.7647058963775635 loss: 0.4859405755996704, accuracy: 0.7647058963775635 loss: 0.485654354095459, accuracy: 0.7647058963775635 loss: 0.48536837100982666, accuracy: 0.7647058963775635 loss: 0.4850827753543854, accuracy: 0.7647058963775635 loss: 0.48479750752449036, accuracy: 0.7647058963775635 loss: 0.4845125079154968, accuracy: 0.7664884328842163 loss: 0.4842279553413391, accuracy: 0.7647058963775635 loss: 0.4839436113834381, accuracy: 0.7647058963775635 loss: 0.48365965485572815, accuracy: 0.7664884328842163 loss: 0.48337602615356445, accuracy: 0.7664884328842163 loss: 0.483092725276947, accuracy: 0.7664884328842163 loss: 0.48280972242355347, accuracy: 0.7664884328842163 loss: 0.4825270175933838, accuracy: 0.7664884328842163 loss: 0.48224470019340515, accuracy: 0.7682709693908691 loss: 0.481962651014328, accuracy: 0.7682709693908691 loss: 0.48168089985847473, accuracy: 0.7682709693908691 loss: 0.4813995063304901, accuracy: 0.7700534462928772 loss: 0.481118381023407, accuracy: 0.7700534462928772 loss: 0.4808375835418701, accuracy: 0.7682709693908691 loss: 0.48055708408355713, accuracy: 0.7682709693908691 loss: 0.48027682304382324, accuracy: 0.7700534462928772 loss: 0.4799969494342804, accuracy: 0.7700534462928772 loss: 0.47971734404563904, accuracy: 0.77183598279953 loss: 0.4794381260871887, accuracy: 0.7736185193061829 loss: 0.4791591167449951, accuracy: 0.7736185193061829 loss: 0.4788804352283478, accuracy: 0.7736185193061829 loss: 0.4786020517349243, accuracy: 0.7736185193061829 loss: 0.47832396626472473, accuracy: 0.7754010558128357 loss: 0.478046178817749, accuracy: 0.7754010558128357 loss: 0.4777686893939972, accuracy: 0.7754010558128357 loss: 0.4774914085865021, accuracy: 0.7754010558128357 loss: 0.4772144556045532, accuracy: 0.7754010558128357 loss: 0.4769378900527954, accuracy: 0.7736185193061829 loss: 0.4766616225242615, accuracy: 0.7754010558128357 loss: 0.4763854742050171, accuracy: 0.7754010558128357 loss: 0.4761098027229309, accuracy: 0.7754010558128357 loss: 0.47583428025245667, accuracy: 0.7754010558128357 loss: 0.4755590558052063, accuracy: 0.7754010558128357 loss: 0.4752841889858246, accuracy: 0.7754010558128357 loss: 0.47500959038734436, accuracy: 0.7754010558128357 loss: 0.4747351408004761, accuracy: 0.7754010558128357</p>"},{"location":"projects/tp_gnn/#visualisation-des-embeddings-calcules","title":"Visualisation des embeddings calcul\u00e9s","text":"<pre><code>visualize_emb(emb)\n</code></pre> Output"},{"location":"services/documentation/","title":"Services","text":"<p>Creation of professional documentation</p> <p>If you are a PhD student, researcher or scientist and you want to <code>document your projects in a professional way</code> then I congratulate you because you are in the right place, you just need to contact me and your documentations will be ready in 2 days :</p> <ul> <li><code>mouhihamohamed@gmail.com</code></li> <li>My phone number : (+212)6 81 42 35 36</li> </ul> <p>For those interested, please visit my latest documentations :</p> <ul> <li> </li> </ul>"}]}